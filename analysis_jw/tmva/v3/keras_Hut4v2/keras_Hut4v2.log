keras_full2.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  #!/usr/bin/env python
Train on 70000 samples, validate on 20000 samples
Epoch 1/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.7575 - acc: 0.6000Epoch 00000: val_loss improved from inf to 0.05367, saving model to keras_Hut4v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 25s - loss: 0.7571 - acc: 0.6002 - val_loss: 0.0537 - val_acc: 0.6468
Epoch 2/35
 9800/70000 [===>..........................] - ETA: 18s - loss: 0.6385 - acc: 0.6491
69800/70000 [============================>.] - ETA: 0s - loss: 0.6328 - acc: 0.6507Epoch 00001: val_loss improved from 0.05367 to 0.05290, saving model to keras_Hut4v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 22s - loss: 0.6327 - acc: 0.6508 - val_loss: 0.0529 - val_acc: 0.6484
Epoch 3/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.6189 - acc: 0.6605Epoch 00002: val_loss improved from 0.05290 to 0.05271, saving model to keras_Hut4v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 22s - loss: 0.6190 - acc: 0.6604 - val_loss: 0.0527 - val_acc: 0.6529
Epoch 4/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.6142 - acc: 0.6671Epoch 00003: val_loss improved from 0.05271 to 0.05250, saving model to keras_Hut4v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 22s - loss: 0.6142 - acc: 0.6672 - val_loss: 0.0525 - val_acc: 0.6548
Epoch 5/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.6105 - acc: 0.6705Epoch 00004: val_loss improved from 0.05250 to 0.05228, saving model to keras_Hut4v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 22s - loss: 0.6106 - acc: 0.6705 - val_loss: 0.0523 - val_acc: 0.6566
Epoch 6/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.6085 - acc: 0.6719Epoch 00005: val_loss improved from 0.05228 to 0.05225, saving model to keras_Hut4v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 22s - loss: 0.6086 - acc: 0.6718 - val_loss: 0.0523 - val_acc: 0.6579
Epoch 7/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.6053 - acc: 0.6763Epoch 00006: val_loss did not improve
70000/70000 [==============================] - 22s - loss: 0.6052 - acc: 0.6763 - val_loss: 0.0523 - val_acc: 0.6594
Epoch 8/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.6046 - acc: 0.6760Epoch 00007: val_loss did not improve
70000/70000 [==============================] - 22s - loss: 0.6045 - acc: 0.6760 - val_loss: 0.0524 - val_acc: 0.6573
Epoch 9/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.6004 - acc: 0.6796Epoch 00008: val_loss did not improve
70000/70000 [==============================] - 22s - loss: 0.6006 - acc: 0.6794 - val_loss: 0.0525 - val_acc: 0.6587
Epoch 10/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.6001 - acc: 0.6793Epoch 00009: val_loss did not improve
70000/70000 [==============================] - 22s - loss: 0.6002 - acc: 0.6791 - val_loss: 0.0524 - val_acc: 0.6600
Epoch 11/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5989 - acc: 0.6806Epoch 00010: val_loss did not improve
70000/70000 [==============================] - 22s - loss: 0.5989 - acc: 0.6806 - val_loss: 0.0524 - val_acc: 0.6591
Epoch 12/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5966 - acc: 0.6835Epoch 00011: val_loss did not improve
70000/70000 [==============================] - 22s - loss: 0.5966 - acc: 0.6834 - val_loss: 0.0523 - val_acc: 0.6602
Epoch 13/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5955 - acc: 0.6821Epoch 00012: val_loss improved from 0.05225 to 0.05203, saving model to keras_Hut4v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 22s - loss: 0.5955 - acc: 0.6820 - val_loss: 0.0520 - val_acc: 0.6625
Epoch 14/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5946 - acc: 0.6854Epoch 00013: val_loss improved from 0.05203 to 0.05203, saving model to keras_Hut4v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 21s - loss: 0.5947 - acc: 0.6854 - val_loss: 0.0520 - val_acc: 0.6630
Epoch 15/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5931 - acc: 0.6863Epoch 00014: val_loss did not improve
70000/70000 [==============================] - 21s - loss: 0.5931 - acc: 0.6862 - val_loss: 0.0522 - val_acc: 0.6630
Epoch 16/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5920 - acc: 0.6877Epoch 00015: val_loss improved from 0.05203 to 0.05187, saving model to keras_Hut4v2/weights/TrainedModel_PyKeras.h5
70000/70000 [==============================] - 21s - loss: 0.5921 - acc: 0.6876 - val_loss: 0.0519 - val_acc: 0.6638
Epoch 17/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5923 - acc: 0.6862Epoch 00016: val_loss did not improve
70000/70000 [==============================] - 21s - loss: 0.5924 - acc: 0.6861 - val_loss: 0.0520 - val_acc: 0.6647
Epoch 18/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5908 - acc: 0.6890Epoch 00017: val_loss did not improve
70000/70000 [==============================] - 21s - loss: 0.5909 - acc: 0.6889 - val_loss: 0.0520 - val_acc: 0.6635
Epoch 19/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5894 - acc: 0.6892Epoch 00018: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5895 - acc: 0.6891 - val_loss: 0.0519 - val_acc: 0.6640
Epoch 20/35
10400/70000 [===>..........................] - ETA: 16s - loss: 0.5875 - acc: 0.6881
69800/70000 [============================>.] - ETA: 0s - loss: 0.5887 - acc: 0.6890Epoch 00019: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5887 - acc: 0.6890 - val_loss: 0.0520 - val_acc: 0.6648
Epoch 21/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.6906Epoch 00020: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5871 - acc: 0.6906 - val_loss: 0.0523 - val_acc: 0.6648
Epoch 22/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5871 - acc: 0.6920Epoch 00021: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5871 - acc: 0.6919 - val_loss: 0.0521 - val_acc: 0.6656
Epoch 23/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5852 - acc: 0.6924Epoch 00022: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5851 - acc: 0.6925 - val_loss: 0.0522 - val_acc: 0.6650
Epoch 24/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5858 - acc: 0.6912Epoch 00023: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5858 - acc: 0.6912 - val_loss: 0.0522 - val_acc: 0.6655
Epoch 25/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5841 - acc: 0.6929Epoch 00024: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5842 - acc: 0.6929 - val_loss: 0.0521 - val_acc: 0.6657
Epoch 26/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5842 - acc: 0.6922Epoch 00025: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5842 - acc: 0.6922 - val_loss: 0.0521 - val_acc: 0.6666
Epoch 27/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5839 - acc: 0.6930Epoch 00026: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5838 - acc: 0.6930 - val_loss: 0.0521 - val_acc: 0.6652
Epoch 28/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5820 - acc: 0.6950Epoch 00027: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5819 - acc: 0.6950 - val_loss: 0.0521 - val_acc: 0.6651
Epoch 29/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5816 - acc: 0.6950Epoch 00028: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5817 - acc: 0.6950 - val_loss: 0.0522 - val_acc: 0.6661
Epoch 30/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5807 - acc: 0.6958Epoch 00029: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5807 - acc: 0.6958 - val_loss: 0.0522 - val_acc: 0.6662
Epoch 31/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5815 - acc: 0.6959Epoch 00030: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5816 - acc: 0.6958 - val_loss: 0.0522 - val_acc: 0.6663
Epoch 32/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5803 - acc: 0.6975Epoch 00031: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5803 - acc: 0.6976 - val_loss: 0.0522 - val_acc: 0.6657
Epoch 33/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5791 - acc: 0.6963Epoch 00032: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5792 - acc: 0.6962 - val_loss: 0.0522 - val_acc: 0.6660
Epoch 34/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5793 - acc: 0.6963Epoch 00033: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5794 - acc: 0.6962 - val_loss: 0.0520 - val_acc: 0.6671
Epoch 35/35
69800/70000 [============================>.] - ETA: 0s - loss: 0.5789 - acc: 0.6978Epoch 00034: val_loss did not improve
70000/70000 [==============================] - 20s - loss: 0.5789 - acc: 0.6978 - val_loss: 0.0522 - val_acc: 0.6665
                         : Elapsed time for training with 70000 events: 757 sec         
                         : Creating xml weight file: keras_Hut4v2/weights/TMVAClassification_PyKeras.weights.xml
                         : Creating standalone class: keras_Hut4v2/weights/TMVAClassification_PyKeras.class.C
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
BDT                      : Ranking result (top variable is best ranked)
                         : -------------------------------------------------
                         : Rank : Variable        : Variable Importance
                         : -------------------------------------------------
                         :    1 : DRjet2cvsb      : 2.497e-02
                         :    2 : DRjet2csv       : 2.347e-02
                         :    3 : DRjet31m        : 1.883e-02
                         :    4 : bjetmDR         : 1.809e-02
                         :    5 : dibjetsMass     : 1.730e-02
                         :    6 : DRjet0csv       : 1.727e-02
                         :    7 : DRjet0cvsb      : 1.725e-02
                         :    8 : DRjet3csv       : 1.689e-02
                         :    9 : DRjet3cvsb      : 1.672e-02
                         :   10 : DRjet23m        : 1.656e-02
                         :   11 : DRjet12m        : 1.608e-02
                         :   12 : jet2cvsb        : 1.589e-02
                         :   13 : DRjet3cvsl      : 1.573e-02
                         :   14 : jet1cvsb        : 1.525e-02
                         :   15 : jet1eta         : 1.513e-02
                         :   16 : DRjet2cvsl      : 1.510e-02
                         :   17 : lepDPhi         : 1.507e-02
                         :   18 : jet4cvsb        : 1.495e-02
                         :   19 : DRjet12DR       : 1.487e-02
                         :   20 : DRjet3eta       : 1.483e-02
                         :   21 : bjetmDEta       : 1.472e-02
                         :   22 : jet3cvsb        : 1.463e-02
                         :   23 : DRjet1cvsb      : 1.461e-02
                         :   24 : jet3eta         : 1.448e-02
                         :   25 : DRjet0eta       : 1.428e-02
                         :   26 : DRlepWm         : 1.411e-02
                         :   27 : DRjet2eta       : 1.408e-02
                         :   28 : DRlepTm         : 1.406e-02
                         :   29 : DRjet2m         : 1.384e-02
                         :   30 : DRjet3m         : 1.366e-02
                         :   31 : bjetmDPhi       : 1.357e-02
                         :   32 : jet4eta         : 1.351e-02
                         :   33 : DRjet1csv       : 1.327e-02
                         :   34 : jet1cvsl        : 1.325e-02
                         :   35 : DRjet0cvsl      : 1.319e-02
                         :   36 : DRlepTpt        : 1.316e-02
                         :   37 : DRjet1cvsl      : 1.315e-02
                         :   38 : DRjet1eta       : 1.312e-02
                         :   39 : jet4cvsl        : 1.284e-02
                         :   40 : DRjet1m         : 1.266e-02
                         :   41 : jet4csv         : 1.256e-02
                         :   42 : jet3cvsl        : 1.246e-02
                         :   43 : jet1pt          : 1.240e-02
                         :   44 : DRjet3pt        : 1.234e-02
                         :   45 : jet2eta         : 1.200e-02
                         :   46 : DRlepTeta       : 1.194e-02
                         :   47 : cjetPt          : 1.190e-02
                         :   48 : DRjet23pt       : 1.133e-02
                         :   49 : DRjet31pt       : 1.131e-02
                         :   50 : DRlepWeta       : 1.120e-02
                         :   51 : DRlepWpt        : 1.116e-02
                         :   52 : jet2csv         : 1.104e-02
                         :   53 : jet1csv         : 1.096e-02
                         :   54 : jet1m           : 1.080e-02
                         :   55 : DRhadTpt        : 1.072e-02
                         :   56 : DRjet0pt        : 1.065e-02
                         :   57 : jet4m           : 1.065e-02
                         :   58 : DRhadTm         : 1.064e-02
                         :   59 : DRjet23eta      : 1.043e-02
                         :   60 : missingET       : 1.030e-02
                         :   61 : DRjet0m         : 1.015e-02
                         :   62 : jet2cvsl        : 1.014e-02
                         :   63 : jet3csv         : 9.807e-03
                         :   64 : bjetPt_dibjetsm : 9.551e-03
                         :   65 : jet2m           : 9.530e-03
                         :   66 : ncjets_m        : 9.187e-03
                         :   67 : jet3m           : 9.123e-03
                         :   68 : DRhadTeta       : 9.100e-03
                         :   69 : DRjet2pt        : 9.041e-03
                         :   70 : DRjet12eta      : 8.947e-03
                         :   71 : DRjet31eta      : 8.622e-03
                         :   72 : DRjet12pt       : 8.564e-03
                         :   73 : njets           : 8.525e-03
                         :   74 : jet2pt          : 8.405e-03
                         :   75 : jet3pt          : 8.305e-03
                         :   76 : jet4pt          : 7.844e-03
                         :   77 : DRjet1pt        : 7.259e-03
                         :   78 : nbjets_m        : 6.668e-03
                         : -------------------------------------------------
                         : No variable ranking supplied by classifier: PyKeras
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : Test all methods
Factory                  : Test method: BDT for Classification performance
                         : 
BDT                      : [keras_Hut4v2] : Evaluation of BDT on testing sample (20000 events)
                         : Elapsed time for evaluation of 20000 events: 1.14 sec       
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: keras_Hut4v2/weights/TrainedModel_PyKeras.h5
Factory                  : Evaluate all methods
Factory                  : Evaluate classifier: BDT
                         : 
BDT                      : [keras_Hut4v2] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_BDT            :        Variable               Mean               RMS       [        Min               Max ]
                         : ----------------------------------------------------------------------------------------------
                         :           njets:           4.9780           1.1489   [           4.0000           14.000 ]
                         :        nbjets_m:           3.0529          0.23738   [           3.0000           6.0000 ]
                         :        ncjets_m:          0.66436          0.79101   [           0.0000           6.0000 ]
                         :         lepDPhi:         0.012856           1.6110   [          -3.1416           3.1411 ]
                         :       missingET:           68.962           50.107   [          0.41146           769.54 ]
                         :         bjetmDR:           1.3858          0.53572   [          0.40171           3.3124 ]
                         :       bjetmDEta:         0.013938          0.95362   [          -3.1368           3.0723 ]
                         :       bjetmDPhi:        -0.010166           1.1391   [          -3.1307           3.1019 ]
                         :     dibjetsMass:           102.96           51.931   [           17.490           877.96 ]
                         : bjetPt_dibjetsm:           108.23           66.714   [           30.256           1400.9 ]
                         :          cjetPt:           91.518           71.097   [           30.002           1054.4 ]
                         :          jet1pt:           145.21           88.811   [           37.762           1400.9 ]
                         :         jet1eta:        0.0084008           1.0668   [          -2.3999           2.3967 ]
                         :           jet1m:           249.19           212.14   [           40.703           2785.1 ]
                         :         jet1csv:          0.75466          0.32974   [         0.039414          0.99943 ]
                         :        jet1cvsl:          0.54889          0.48775   [         -0.64354          0.99685 ]
                         :        jet1cvsb:         -0.27665          0.52766   [         -0.98271          0.83928 ]
                         :          jet2pt:           98.253           52.828   [           32.085           1149.7 ]
                         :         jet2eta:        0.0028453           1.0693   [          -2.3997           2.3971 ]
                         :           jet2m:           167.15           129.46   [           34.238           2437.0 ]
                         :         jet2csv:          0.74693          0.33809   [         0.047415          0.99961 ]
                         :        jet2cvsl:          0.55448          0.49814   [         -0.65479          0.99712 ]
                         :        jet2cvsb:         -0.28059          0.53700   [         -0.98288          0.85085 ]
                         :          jet3pt:           70.678           32.869   [           30.225           597.83 ]
                         :         jet3eta:       -0.0012796           1.1048   [          -2.3990           2.3995 ]
                         :           jet3m:           124.33           91.195   [           30.917           1467.9 ]
                         :         jet3csv:          0.70373          0.35350   [         0.047237          0.99959 ]
                         :        jet3cvsl:          0.49922          0.52205   [         -0.76039          0.99709 ]
                         :        jet3cvsb:         -0.21699          0.54972   [         -0.98400          0.83794 ]
                         :          jet4pt:           52.294           21.872   [           30.002           451.44 ]
                         :         jet4eta:        0.0018596           1.1377   [          -2.4000           2.3997 ]
                         :           jet4m:           95.141           67.888   [           30.461           827.73 ]
                         :         jet4csv:          0.66666          0.35772   [         0.043435          0.99963 ]
                         :        jet4cvsl:          0.43859          0.53734   [         -0.69492          0.99627 ]
                         :        jet4cvsb:         -0.15661          0.54626   [         -0.98613          0.84578 ]
                         :        DRlepWpt:           116.01           77.384   [          0.13619           978.38 ]
                         :       DRlepWeta:         0.017931          0.88214   [          -6.1349           5.4076 ]
                         :         DRlepWm:           94.825           48.632   [          0.39319           525.05 ]
                         :        DRjet0pt:           113.30           86.434   [           30.011           1336.7 ]
                         :       DRjet0eta:         0.013115           1.1732   [          -2.3999           2.3995 ]
                         :         DRjet0m:           15.153           10.074   [           1.9269           177.82 ]
                         :       DRjet0csv:          0.67272          0.35900   [         0.039414          0.99956 ]
                         :      DRjet0cvsl:          0.44273          0.52677   [         -0.64354          0.99685 ]
                         :      DRjet0cvsb:         -0.17152          0.55083   [         -0.98152          0.85085 ]
                         :        DRjet1pt:           81.445           53.342   [           30.002           928.19 ]
                         :       DRjet1eta:        0.0093476          0.99167   [          -2.3977           2.3978 ]
                         :         DRjet1m:           11.895           7.0722   [           2.6340           145.40 ]
                         :       DRjet1csv:          0.97869         0.027827   [          0.85121          0.99963 ]
                         :      DRjet1cvsl:          0.87686          0.16677   [         -0.58671          0.99715 ]
                         :      DRjet1cvsb:         -0.72128          0.25293   [         -0.98613          0.67683 ]
                         :        DRjet2pt:           82.256           58.009   [           30.002           1264.4 ]
                         :       DRjet2eta:       -0.0090845           1.0535   [          -2.3980           2.3966 ]
                         :         DRjet2m:           12.062           7.9022   [           2.5847           174.23 ]
                         :       DRjet2csv:          0.93053         0.045574   [          0.84840          0.99942 ]
                         :      DRjet2cvsl:          0.80924          0.22783   [         -0.53934          0.99709 ]
                         :      DRjet2cvsb:         -0.42432          0.34388   [         -0.98530          0.73015 ]
                         :        DRjet3pt:           72.225           50.230   [           30.002           1400.9 ]
                         :       DRjet3eta:        0.0047362           1.0837   [          -2.4000           2.3994 ]
                         :         DRjet3m:           10.911           6.9640   [           1.7574           296.17 ]
                         :       DRjet3csv:          0.38973          0.31035   [         0.047237          0.99882 ]
                         :      DRjet3cvsl:         0.042226          0.45596   [         -0.82989          0.99619 ]
                         :      DRjet3cvsb:          0.25517          0.36840   [         -0.96286          0.84578 ]
                         :       DRjet12pt:           137.43           79.142   [           2.5115           1298.1 ]
                         :      DRjet12eta:       9.1585e-06           1.1361   [          -4.8967           4.6205 ]
                         :        DRjet12m:           110.22           57.817   [           18.699           877.96 ]
                         :       DRjet12DR:           1.5151          0.61336   [          0.40298           4.6346 ]
                         :       DRjet23pt:           124.06           77.945   [          0.73626           1450.4 ]
                         :      DRjet23eta:       0.00049535           1.2687   [          -5.0238           5.9117 ]
                         :        DRjet23m:           108.23           67.859   [           17.333           965.16 ]
                         :       DRjet31pt:           122.00           75.296   [          0.64226           1511.0 ]
                         :      DRjet31eta:         0.012402           1.2440   [          -6.0343           5.2014 ]
                         :        DRjet31m:           109.69           65.182   [           17.711           1274.5 ]
                         :        DRlepTpt:           162.08           98.972   [           1.1315           1459.7 ]
                         :       DRlepTeta:         0.020060           1.2327   [          -6.1058           5.6176 ]
                         :         DRlepTm:           254.66           157.27   [           39.864           2961.7 ]
                         :        DRhadTpt:           174.69           96.460   [           3.5177           1559.9 ]
                         :       DRhadTeta:        0.0068017           1.2522   [          -5.2776           6.4020 ]
                         :         DRhadTm:           197.95           91.326   [           38.780           1356.8 ]
                         : ----------------------------------------------------------------------------------------------
                         : 
                         : <PlotVariables> Will not produce scatter plots ==> 
                         : |  The number of 78 input variables and 0 target values would require 3003 two-dimensional
                         : |  histograms, which would occupy the computer's memory. Note that this
                         : |  suppression does not have any consequences for your analysis, other
                         : |  than not disposing of these scatter plots. You can modify the maximum
                         : |  number of input variables allowed to generate scatter plots in your
                         : |  script via the command line:
                         : |  "(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;"
                         : 
                         : Some more output
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :        Variable               Mean               RMS       [        Min               Max ]
                         : ----------------------------------------------------------------------------------------------
                         :           njets:        0.0031808          0.99818   [          -3.0211           5.7307 ]
                         :        nbjets_m:       -0.0075689           1.0012   [          -3.2000           3.9263 ]
                         :        ncjets_m:       0.00094347          0.99460   [          -5.7307           5.7307 ]
                         :         lepDPhi:         0.014419           1.0029   [          -3.0259           5.7307 ]
                         :       missingET:       -0.0061327          0.99579   [          -3.3833           4.0912 ]
                         :         bjetmDR:        0.0055084           1.0000   [          -3.3476           5.7307 ]
                         :       bjetmDEta:        0.0021072          0.99002   [          -3.2055           3.6367 ]
                         :       bjetmDPhi:       -0.0084290          0.99435   [          -3.1357           3.4004 ]
                         :     dibjetsMass:       -0.0080799          0.98978   [          -3.1571           5.7307 ]
                         : bjetPt_dibjetsm:        0.0050216          0.99620   [          -3.1130           5.7307 ]
                         :          cjetPt:        0.0058565          0.98807   [          -5.7307           5.7307 ]
                         :          jet1pt:        0.0088130          0.99152   [          -3.2414           4.0170 ]
                         :         jet1eta:        0.0048007          0.98958   [          -3.1821           5.7307 ]
                         :           jet1m:        0.0024950          0.98987   [          -3.2345           3.8245 ]
                         :         jet1csv:        0.0040256          0.99066   [          -3.1229           5.7307 ]
                         :        jet1cvsl:         0.015293          0.98918   [          -3.3901           5.7307 ]
                         :        jet1cvsb:       -0.0036161           1.0012   [          -3.1825           5.7307 ]
                         :          jet2pt:       -0.0018322          0.99011   [          -3.3404           5.7307 ]
                         :         jet2eta:      -0.00099996          0.98537   [          -3.4284           3.5991 ]
                         :           jet2m:       -0.0048820          0.98653   [          -3.9796           5.7307 ]
                         :         jet2csv:        0.0074353          0.98591   [          -3.1285           5.7307 ]
                         :        jet2cvsl:       -0.0047918          0.98875   [          -3.5715           5.7307 ]
                         :        jet2cvsb:       -0.0046016          0.99215   [          -3.0486           3.8114 ]
                         :          jet3pt:      -0.00073057           1.0069   [          -3.2703           5.7307 ]
                         :         jet3eta:       -0.0093656          0.99781   [          -3.2424           3.6327 ]
                         :           jet3m:         0.010821          0.99854   [          -3.2046           3.5689 ]
                         :         jet3csv:        0.0079944          0.99221   [          -3.1682           4.0314 ]
                         :        jet3cvsl:       -0.0027992          0.99266   [          -3.1107           3.6954 ]
                         :        jet3cvsb:        0.0060255           1.0011   [          -3.1693           5.7307 ]
                         :          jet4pt:       -0.0056843          0.98939   [          -3.1417           5.7307 ]
                         :         jet4eta:        0.0076753          0.99434   [          -3.0649           5.7307 ]
                         :           jet4m:        0.0019351          0.99197   [          -3.0329           3.5658 ]
                         :         jet4csv:        0.0049060          0.99545   [          -3.1278           5.7307 ]
                         :        jet4cvsl:        0.0030004          0.99689   [          -3.4464           3.4913 ]
                         :        jet4cvsb:      -0.00045999          0.98797   [          -3.1504           3.9382 ]
                         :        DRlepWpt:         0.011542           1.0037   [          -3.0799           5.7307 ]
                         :       DRlepWeta:         0.018681          0.99975   [          -5.7307           5.7307 ]
                         :         DRlepWm:         0.012650           1.0049   [          -3.0304           3.3784 ]
                         :        DRjet0pt:       -0.0074798          0.99756   [          -3.0990           5.7307 ]
                         :       DRjet0eta:         0.013481          0.99892   [          -3.0900           5.7307 ]
                         :         DRjet0m:      -0.00073571          0.98980   [          -4.2680           5.7307 ]
                         :       DRjet0csv:         0.021299          0.99274   [          -5.7307           5.7307 ]
                         :      DRjet0cvsl:         0.015829          0.99127   [          -3.2540           5.7307 ]
                         :      DRjet0cvsb:        0.0016891           1.0008   [          -3.1528           5.7307 ]
                         :        DRjet1pt:        0.0037213          0.99099   [          -3.1729           5.7307 ]
                         :       DRjet1eta:        0.0068599          0.98883   [          -3.2387           5.7307 ]
                         :         DRjet1m:        0.0018066           1.0024   [          -3.1790           3.9347 ]
                         :       DRjet1csv:        0.0071718          0.97969   [          -3.0576           3.6529 ]
                         :      DRjet1cvsl:       -0.0047369          0.98867   [          -3.1625           5.7307 ]
                         :      DRjet1cvsb:        -0.010606           1.0028   [          -3.0422           5.7307 ]
                         :        DRjet2pt:        0.0095798          0.99791   [          -5.7307           5.7307 ]
                         :       DRjet2eta:       -0.0065142          0.99396   [          -3.1043           3.4156 ]
                         :         DRjet2m:       -0.0099842           1.0014   [          -3.3274           5.7307 ]
                         :       DRjet2csv:        0.0088826          0.99590   [          -3.1461           5.7307 ]
                         :      DRjet2cvsl:        0.0085618          0.98588   [          -3.0484           3.3231 ]
                         :      DRjet2cvsb:        -0.018084           1.0000   [          -3.1997           3.5609 ]
                         :        DRjet3pt:        0.0017502           1.0001   [          -3.1932           5.7307 ]
                         :       DRjet3eta:      -2.7093e-05          0.99181   [          -3.2565           3.7153 ]
                         :         DRjet3m:       -0.0055240          0.99735   [          -3.0606           5.7307 ]
                         :       DRjet3csv:         0.012721          0.99206   [          -3.1512           3.2653 ]
                         :      DRjet3cvsl:        0.0085605          0.99128   [          -3.6117           4.1122 ]
                         :      DRjet3cvsb:       -0.0022805          0.98667   [          -3.3417           3.3236 ]
                         :       DRjet12pt:         0.012364           1.0053   [          -3.2222           3.3688 ]
                         :      DRjet12eta:       -0.0033845          0.99495   [          -3.0539           5.7307 ]
                         :        DRjet12m:       -0.0035024          0.99262   [          -3.0854           5.7307 ]
                         :       DRjet12DR:         0.010258          0.99859   [          -3.5555           5.7307 ]
                         :       DRjet23pt:         0.020022          0.98270   [          -3.0922           5.7307 ]
                         :      DRjet23eta:       0.00080977          0.98565   [          -3.1197           4.4530 ]
                         :        DRjet23m:       -0.0022129          0.99509   [          -3.8535           3.3964 ]
                         :       DRjet31pt:         0.017884           1.0023   [          -3.0749           3.5548 ]
                         :      DRjet31eta:        0.0040724          0.99844   [          -3.1308           5.7307 ]
                         :        DRjet31m:        0.0017776          0.98450   [          -3.0274           3.4996 ]
                         :        DRlepTpt:        0.0036019           1.0039   [          -3.0772           3.5180 ]
                         :       DRlepTeta:         0.011762          0.99626   [          -3.1569           5.7307 ]
                         :         DRlepTm:       -0.0024462          0.98779   [          -3.2583           5.7307 ]
                         :        DRhadTpt:        0.0055459           1.0031   [          -3.0955           5.7307 ]
                         :       DRhadTeta:        0.0069876          0.99606   [          -3.0630           5.7307 ]
                         :         DRhadTm:       0.00015128          0.99075   [          -5.7307           3.7347 ]
                         : ----------------------------------------------------------------------------------------------
PyKeras                  : [keras_Hut4v2] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :        Variable               Mean               RMS       [        Min               Max ]
                         : ----------------------------------------------------------------------------------------------
                         :           njets:        0.0031808          0.99818   [          -3.0211           5.7307 ]
                         :        nbjets_m:       -0.0075689           1.0012   [          -3.2000           3.9263 ]
                         :        ncjets_m:       0.00094347          0.99460   [          -5.7307           5.7307 ]
                         :         lepDPhi:         0.014419           1.0029   [          -3.0259           5.7307 ]
                         :       missingET:       -0.0061327          0.99579   [          -3.3833           4.0912 ]
                         :         bjetmDR:        0.0055084           1.0000   [          -3.3476           5.7307 ]
                         :       bjetmDEta:        0.0021072          0.99002   [          -3.2055           3.6367 ]
                         :       bjetmDPhi:       -0.0084290          0.99435   [          -3.1357           3.4004 ]
                         :     dibjetsMass:       -0.0080799          0.98978   [          -3.1571           5.7307 ]
                         : bjetPt_dibjetsm:        0.0050216          0.99620   [          -3.1130           5.7307 ]
                         :          cjetPt:        0.0058565          0.98807   [          -5.7307           5.7307 ]
                         :          jet1pt:        0.0088130          0.99152   [          -3.2414           4.0170 ]
                         :         jet1eta:        0.0048007          0.98958   [          -3.1821           5.7307 ]
                         :           jet1m:        0.0024950          0.98987   [          -3.2345           3.8245 ]
                         :         jet1csv:        0.0040256          0.99066   [          -3.1229           5.7307 ]
                         :        jet1cvsl:         0.015293          0.98918   [          -3.3901           5.7307 ]
                         :        jet1cvsb:       -0.0036161           1.0012   [          -3.1825           5.7307 ]
                         :          jet2pt:       -0.0018322          0.99011   [          -3.3404           5.7307 ]
                         :         jet2eta:      -0.00099996          0.98537   [          -3.4284           3.5991 ]
                         :           jet2m:       -0.0048820          0.98653   [          -3.9796           5.7307 ]
                         :         jet2csv:        0.0074353          0.98591   [          -3.1285           5.7307 ]
                         :        jet2cvsl:       -0.0047918          0.98875   [          -3.5715           5.7307 ]
                         :        jet2cvsb:       -0.0046016          0.99215   [          -3.0486           3.8114 ]
                         :          jet3pt:      -0.00073057           1.0069   [          -3.2703           5.7307 ]
                         :         jet3eta:       -0.0093656          0.99781   [          -3.2424           3.6327 ]
                         :           jet3m:         0.010821          0.99854   [          -3.2046           3.5689 ]
                         :         jet3csv:        0.0079944          0.99221   [          -3.1682           4.0314 ]
                         :        jet3cvsl:       -0.0027992          0.99266   [          -3.1107           3.6954 ]
                         :        jet3cvsb:        0.0060255           1.0011   [          -3.1693           5.7307 ]
                         :          jet4pt:       -0.0056843          0.98939   [          -3.1417           5.7307 ]
                         :         jet4eta:        0.0076753          0.99434   [          -3.0649           5.7307 ]
                         :           jet4m:        0.0019351          0.99197   [          -3.0329           3.5658 ]
                         :         jet4csv:        0.0049060          0.99545   [          -3.1278           5.7307 ]
                         :        jet4cvsl:        0.0030004          0.99689   [          -3.4464           3.4913 ]
                         :        jet4cvsb:      -0.00045999          0.98797   [          -3.1504           3.9382 ]
                         :        DRlepWpt:         0.011542           1.0037   [          -3.0799           5.7307 ]
                         :       DRlepWeta:         0.018681          0.99975   [          -5.7307           5.7307 ]
                         :         DRlepWm:         0.012650           1.0049   [          -3.0304           3.3784 ]
                         :        DRjet0pt:       -0.0074798          0.99756   [          -3.0990           5.7307 ]
                         :       DRjet0eta:         0.013481          0.99892   [          -3.0900           5.7307 ]
                         :         DRjet0m:      -0.00073571          0.98980   [          -4.2680           5.7307 ]
                         :       DRjet0csv:         0.021299          0.99274   [          -5.7307           5.7307 ]
                         :      DRjet0cvsl:         0.015829          0.99127   [          -3.2540           5.7307 ]
                         :      DRjet0cvsb:        0.0016891           1.0008   [          -3.1528           5.7307 ]
                         :        DRjet1pt:        0.0037213          0.99099   [          -3.1729           5.7307 ]
                         :       DRjet1eta:        0.0068599          0.98883   [          -3.2387           5.7307 ]
                         :         DRjet1m:        0.0018066           1.0024   [          -3.1790           3.9347 ]
                         :       DRjet1csv:        0.0071718          0.97969   [          -3.0576           3.6529 ]
                         :      DRjet1cvsl:       -0.0047369          0.98867   [          -3.1625           5.7307 ]
                         :      DRjet1cvsb:        -0.010606           1.0028   [          -3.0422           5.7307 ]
                         :        DRjet2pt:        0.0095798          0.99791   [          -5.7307           5.7307 ]
                         :       DRjet2eta:       -0.0065142          0.99396   [          -3.1043           3.4156 ]
                         :         DRjet2m:       -0.0099842           1.0014   [          -3.3274           5.7307 ]
                         :       DRjet2csv:        0.0088826          0.99590   [          -3.1461           5.7307 ]
                         :      DRjet2cvsl:        0.0085618          0.98588   [          -3.0484           3.3231 ]
                         :      DRjet2cvsb:        -0.018084           1.0000   [          -3.1997           3.5609 ]
                         :        DRjet3pt:        0.0017502           1.0001   [          -3.1932           5.7307 ]
                         :       DRjet3eta:      -2.7093e-05          0.99181   [          -3.2565           3.7153 ]
                         :         DRjet3m:       -0.0055240          0.99735   [          -3.0606           5.7307 ]
                         :       DRjet3csv:         0.012721          0.99206   [          -3.1512           3.2653 ]
                         :      DRjet3cvsl:        0.0085605          0.99128   [          -3.6117           4.1122 ]
                         :      DRjet3cvsb:       -0.0022805          0.98667   [          -3.3417           3.3236 ]
                         :       DRjet12pt:         0.012364           1.0053   [          -3.2222           3.3688 ]
                         :      DRjet12eta:       -0.0033845          0.99495   [          -3.0539           5.7307 ]
                         :        DRjet12m:       -0.0035024          0.99262   [          -3.0854           5.7307 ]
                         :       DRjet12DR:         0.010258          0.99859   [          -3.5555           5.7307 ]
                         :       DRjet23pt:         0.020022          0.98270   [          -3.0922           5.7307 ]
                         :      DRjet23eta:       0.00080977          0.98565   [          -3.1197           4.4530 ]
                         :        DRjet23m:       -0.0022129          0.99509   [          -3.8535           3.3964 ]
                         :       DRjet31pt:         0.017884           1.0023   [          -3.0749           3.5548 ]
                         :      DRjet31eta:        0.0040724          0.99844   [          -3.1308           5.7307 ]
                         :        DRjet31m:        0.0017776          0.98450   [          -3.0274           3.4996 ]
                         :        DRlepTpt:        0.0036019           1.0039   [          -3.0772           3.5180 ]
                         :       DRlepTeta:         0.011762          0.99626   [          -3.1569           5.7307 ]
                         :         DRlepTm:       -0.0024462          0.98779   [          -3.2583           5.7307 ]
                         :        DRhadTpt:        0.0055459           1.0031   [          -3.0955           5.7307 ]
                         :       DRhadTeta:        0.0069876          0.99606   [          -3.0630           5.7307 ]
                         :         DRhadTm:       0.00015128          0.99075   [          -5.7307           3.7347 ]
                         : ----------------------------------------------------------------------------------------------
                         : 
                         : <PlotVariables> Will not produce scatter plots ==> 
                         : |  The number of 78 input variables and 0 target values would require 3003 two-dimensional
                         : |  histograms, which would occupy the computer's memory. Note that this
                         : |  suppression does not have any consequences for your analysis, other
                         : |  than not disposing of these scatter plots. You can modify the maximum
                         : |  number of input variables allowed to generate scatter plots in your
                         : |  script via the command line:
                         : |  "(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;"
                         : 
                         : Some more output
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : keras_Hut4v2  BDT            : 0.730
                         : keras_Hut4v2  PyKeras        : 0.725
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : keras_Hut4v2         BDT            : 0.096 (0.108)       0.365 (0.392)      0.637 (0.660)
                         : keras_Hut4v2         PyKeras        : 0.091 (0.109)       0.364 (0.379)      0.629 (0.648)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:keras_Hut4v2     : Created tree 'TestTree' with 20000 events
                         : 
Dataset:keras_Hut4v2     : Created tree 'TrainTree' with 70000 events
                         : 
Factory                  : Thank you for using TMVA!

