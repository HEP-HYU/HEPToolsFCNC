Using TensorFlow backend.
2017-12-31 21:32:21.731722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: 
name: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:84:00.0
totalMemory: 11.90GiB freeMemory: 11.74GiB
2017-12-31 21:32:21.731797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
DataSetInfo              : [keras_Hut28] : Added class "Signal"
                         : Add Tree tmva_tree of type Signal with 22928 events
                         : Add Tree tmva_tree of type Signal with 23409 events
DataSetInfo              : [keras_Hut28] : Added class "Background"
                         : Add Tree tmva_tree of type Background with 6159 events
                         : Add Tree tmva_tree of type Background with 3768 events
                         : Add Tree tmva_tree of type Background with 4878 events
                         : Add Tree tmva_tree of type Background with 4877 events
                         : Add Tree tmva_tree of type Background with 46053 events
                         : Add Tree tmva_tree of type Background with 64226 events
                         : Add Tree tmva_tree of type Background with 19461 events
                         : Add Tree tmva_tree of type Background with 197132 events
                         : Add Tree tmva_tree of type Background with 278670 events
Factory                  : Booking method: [1mBDT[0m
                         : 
DataSetFactory           : [keras_Hut28] : Number of events in input trees
                         : Dataset[keras_Hut28] :     Signal     requirement: "nevt %5 != 0 && GenMatch == 2"
                         : Dataset[keras_Hut28] :     Signal          -- number of events passed: 18811  / sum of weights: 1102.97
                         : Dataset[keras_Hut28] :     Signal          -- efficiency             : 0.406268
                         : Dataset[keras_Hut28] :     Background requirement: "nevt %5 == 1 && nevt %6 == 0"
                         : Dataset[keras_Hut28] :     Background      -- number of events passed: 20843  / sum of weights: 1846.86
                         : Dataset[keras_Hut28] :     Background      -- efficiency             : 0.0332404
                         : Dataset[keras_Hut28] :  you have opted for interpreting the requested number of training/testing events
                         :  to be the number of events AFTER your preselection cuts
                         : 
                         : Dataset[keras_Hut28] :  you have opted for interpreting the requested number of training/testing events
                         :  to be the number of events AFTER your preselection cuts
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 14000
                         : Signal     -- testing events             : 4811
                         : Signal     -- training and testing events: 18811
                         : Dataset[keras_Hut28] : Signal     -- due to the preselection a scaling factor has been applied to the numbers of requested events: 0.405961
                         : Background -- training events            : 15000
                         : Background -- testing events             : 5843
                         : Background -- training and testing events: 20843
                         : Dataset[keras_Hut28] : Background -- due to the preselection a scaling factor has been applied to the numbers of requested events: 0.0333369
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                         :                 njets nbjets_m DRlepWpt DRlepWeta DRlepWdeta DRlepWdphi DRlepWm DRjet0pt DRjet0eta DRjet0m DRjet0csv DRjet0cvsl DRjet0cvsb DRjet1pt DRjet1eta DRjet1m DRjet1csv DRjet1cvsl DRjet1cvsb DRjet2pt DRjet2eta DRjet2m DRjet2csv DRjet2cvsl DRjet2cvsb DRjet3pt DRjet3eta DRjet3m DRjet3csv DRjet3cvsl DRjet3cvsb DRjet12pt DRjet12eta DRjet12deta DRjet12dphi DRjet12m DRjet12DR DRjet23pt DRjet23eta DRjet23deta DRjet23dphi DRjet23m DRjet31pt DRjet31eta DRjet31deta DRjet31dphi DRjet31m DRlepTpt DRlepTeta DRlepTdeta DRlepTdphi DRlepTm DRhadTpt DRhadTeta DRhadTHbdeta DRhadTWbdeta DRhadTHbdphi DRhadTWbdphi DRhadTm
                         :        njets:  +1.000   +0.127   +0.136    -0.004     +0.005     +0.013  +0.056   +0.095    -0.001  +0.077    +0.009     -0.019     +0.013   +0.065    +0.004  +0.051    -0.013     -0.023     +0.024   +0.093    -0.002  +0.083    -0.016     -0.016     +0.024   +0.086    +0.011  +0.085    +0.000     -0.069     +0.065    +0.121     -0.001      +0.016      -0.004   +0.009    -0.105    +0.176     +0.007      -0.022      +0.011   -0.056    +0.155     +0.004      -0.003      -0.012   -0.066   +0.175    -0.004     +0.002     +0.000  +0.063   +0.200    +0.004       +0.001       -0.003       +0.003       -0.004  -0.063
                         :     nbjets_m:  +0.127   +1.000   +0.015    +0.004     -0.006     -0.008  +0.017   +0.033    -0.003  +0.042    -0.007     -0.044     +0.013   +0.022    -0.006  +0.013    +0.002     -0.020     -0.009   +0.058    -0.007  +0.053    +0.010     -0.009     +0.009   +0.028    -0.007  +0.019    +0.031     +0.112     -0.100    +0.064     -0.004      +0.004      -0.006   +0.016    -0.071    +0.066     -0.008      +0.007      +0.005   +0.029    +0.037     -0.007      +0.000      -0.001   +0.007   +0.034    +0.000     -0.001     +0.007  +0.023   +0.069    -0.007       +0.002       -0.007       -0.006       +0.007  +0.022
                         :     DRlepWpt:  +0.136   +0.015   +1.000    -0.017     -0.004     -0.005  +0.234   -0.090    -0.000  -0.090    -0.009     +0.023     +0.011   +0.311    -0.003  +0.266    -0.042     -0.074     +0.073   +0.323    +0.002  +0.282    -0.040     -0.079     +0.050   +0.235    +0.000  +0.207    -0.003     -0.096     +0.091    +0.465     +0.003      +0.001      -0.004   +0.171    -0.358    +0.430     +0.004      +0.001      +0.006   +0.106    +0.413     -0.001      +0.007      -0.001   +0.092   +0.767    -0.009     -0.005     +0.005  +0.212   +0.552    +0.002       +0.009       -0.004       +0.012       -0.007  +0.129
                         :    DRlepWeta:  -0.004   +0.004   -0.017    +1.000     +0.822     +0.002  +0.005   +0.001    +0.626  +0.002    +0.018     +0.009     -0.012   -0.008    +0.134  -0.007    +0.012     +0.008     -0.012   -0.008    +0.124  -0.007    +0.014     -0.003     +0.002   +0.002    +0.170  -0.001    +0.005     +0.014     -0.011    -0.014     +0.117      -0.001      -0.001   +0.001    +0.015    -0.000     +0.154      -0.020      +0.013   -0.005    -0.005     +0.161      -0.024      -0.008   -0.002   -0.016    +0.850     +0.151     +0.003  +0.012   -0.007    +0.150       +0.059       +0.091       +0.007       +0.006  -0.004
                         :   DRlepWdeta:  +0.005   -0.006   -0.004    +0.822     +1.000     -0.004  -0.001   +0.004    +0.641  +0.000    +0.019     +0.010     -0.021   +0.001    +0.142  -0.002    +0.017     +0.008     -0.020   -0.003    +0.138  -0.004    +0.016     +0.001     +0.001   +0.009    +0.172  +0.004    -0.001     +0.006     -0.004    -0.003     +0.127      -0.007      -0.004   +0.002    +0.003    +0.007     +0.160      -0.008      +0.007   -0.002    +0.006     +0.161      -0.014      -0.003   -0.000   -0.005    +0.786     +0.166     +0.009  +0.008   +0.005    +0.154       +0.074       +0.088       -0.001       +0.008  -0.001
                         :   DRlepWdphi:  +0.013   -0.008   -0.005    +0.002     -0.004     +1.000  -0.006   +0.005    -0.002  -0.009    +0.015     -0.000     -0.017   +0.004    -0.008  +0.007    -0.004     -0.011     +0.007   -0.012    -0.009  -0.011    -0.005     -0.011     +0.011   +0.006    -0.007  +0.001    +0.007     -0.009     +0.007    -0.007     -0.011      +0.000      -0.021   +0.015    +0.006    -0.007     -0.010      -0.004      +0.036   +0.001    +0.002     -0.007      +0.002      +0.025   +0.003   +0.001    +0.000     -0.005     -0.390  -0.009   -0.006    -0.010       -0.009       -0.006       +0.039       -0.012  +0.006
                         :      DRlepWm:  +0.056   +0.017   +0.234    +0.005     -0.001     -0.006  +1.000   +0.013    +0.008  +0.027    -0.012     -0.027     +0.005   +0.090    +0.008  +0.081    -0.052     -0.024     +0.046   +0.094    +0.017  +0.080    -0.035     -0.023     +0.018   +0.084    +0.014  +0.071    +0.003     -0.018     +0.002    +0.136     +0.012      -0.013      -0.003   +0.003    -0.115    +0.135     +0.014      +0.004      +0.007   +0.025    +0.124     +0.011      -0.007      +0.004   +0.037   +0.169    +0.011     +0.001     -0.003  +0.782   +0.165    +0.013       +0.006       +0.012       +0.004       -0.002  +0.030
                         :     DRjet0pt:  +0.095   +0.033   -0.090    +0.001     +0.004     +0.005  +0.013   +1.000    +0.011  +0.791    -0.001     -0.141     +0.028   +0.196    +0.001  +0.154    -0.027     -0.040     +0.034   +0.252    -0.004  +0.210    -0.029     -0.043     +0.036   +0.167    +0.004  +0.135    -0.024     -0.112     +0.106    +0.329     -0.001      +0.004      +0.010   +0.107    -0.262    +0.295     +0.002      -0.005      -0.002   +0.127    +0.254     +0.002      -0.009      -0.003   +0.089   +0.505    +0.005     -0.013     +0.003  +0.282   +0.363    -0.000       -0.009       +0.004       -0.007       -0.008  +0.134
                         :    DRjet0eta:  -0.001   -0.003   -0.000    +0.626     +0.641     -0.002  +0.008   +0.011    +1.000  +0.011    +0.024     +0.010     -0.019   +0.005    +0.202  +0.007    +0.020     +0.002     -0.011   -0.007    +0.199  -0.010    +0.011     +0.006     +0.007   +0.003    +0.227  +0.000    +0.006     +0.014     -0.008    -0.008     +0.204      -0.010      +0.001   +0.003    +0.012    -0.002     +0.222      -0.009      +0.014   -0.011    +0.006     +0.230      -0.023      -0.000   -0.006   -0.001    +0.873     -0.457     +0.012  +0.015   -0.002    +0.225       +0.114       +0.121       +0.011       +0.009  -0.010
                         :      DRjet0m:  +0.077   +0.042   -0.090    +0.002     +0.000     -0.009  +0.027   +0.791    +0.011  +1.000    -0.047     -0.197     +0.080   +0.142    -0.006  +0.128    -0.006     -0.029     +0.018   +0.195    -0.013  +0.180    -0.017     -0.031     +0.030   +0.128    -0.004  +0.120    -0.021     -0.071     +0.070    +0.247     -0.012      +0.008      +0.007   +0.093    -0.195    +0.219     -0.007      -0.010      -0.003   +0.109    +0.183     -0.006      -0.002      -0.009   +0.071   +0.369    +0.005     -0.014     +0.010  +0.297   +0.267    -0.010       -0.013       -0.004       -0.013       -0.001  +0.111
                         :    DRjet0csv:  +0.009   -0.007   -0.009    +0.018     +0.019     +0.015  -0.012   -0.001    +0.024  -0.047    +1.000     +0.264     -0.747   -0.013    -0.005  -0.017    +0.033     +0.010     -0.034   -0.034    +0.017  -0.032    +0.031     +0.012     -0.035   -0.004    +0.012  -0.010    -0.018     -0.025     -0.006    -0.034     +0.008      -0.024      -0.008   -0.016    +0.023    -0.019     +0.011      +0.011      -0.003   -0.024    +0.002     +0.003      -0.021      -0.003   -0.021   -0.018    +0.021     -0.007     -0.022  -0.027   -0.019    +0.008       +0.011       +0.021       +0.001       +0.005  -0.026
                         :   DRjet0cvsl:  -0.019   -0.044   +0.023    +0.009     +0.010     -0.000  -0.027   -0.141    +0.010  -0.197    +0.264     +1.000     -0.287   -0.032    -0.001  -0.034    +0.022     +0.038     -0.025   -0.050    +0.010  -0.048    +0.014     +0.033     -0.018   -0.021    +0.005  -0.025    +0.003     +0.017     -0.005    -0.058     +0.008      -0.015      +0.003   -0.039    +0.048    -0.053     +0.010      +0.002      -0.000   -0.029    -0.036     +0.002      -0.004      +0.001   -0.007   -0.062    +0.009     +0.000     -0.006  -0.094   -0.062    +0.007       +0.004       +0.018       +0.001       -0.002  -0.024
                         :   DRjet0cvsb:  +0.013   +0.013   +0.011    -0.012     -0.021     -0.017  +0.005   +0.028    -0.019  +0.080    -0.747     -0.287     +1.000   +0.007    +0.010  +0.012    -0.028     +0.000     +0.033   +0.038    -0.009  +0.043    -0.025     -0.015     +0.041   +0.015    -0.000  +0.024    +0.012     +0.020     +0.029    +0.035     -0.001      +0.023      +0.001   +0.015    -0.030    +0.029     +0.000      -0.010      +0.004   +0.026    +0.000     +0.005      +0.018      +0.001   +0.020   +0.029    -0.015     -0.002     +0.020  +0.028   +0.025    +0.001       -0.006       -0.016       -0.002       +0.005  +0.026
                         :     DRjet1pt:  +0.065   +0.022   +0.311    -0.008     +0.001     +0.004  +0.090   +0.196    +0.005  +0.142    -0.013     -0.032     +0.007   +1.000    +0.002  +0.854    -0.054     -0.202     +0.124   -0.005    -0.002  +0.011    -0.038     -0.018     +0.044   +0.042    +0.006  +0.013    -0.015     -0.028     +0.027    +0.639     +0.004      -0.000      -0.002   +0.327    -0.442    -0.006     -0.002      -0.008      +0.009   +0.057    +0.727     +0.003      -0.009      -0.010   +0.374   +0.387    -0.003     -0.007     -0.010  +0.109   +0.550    +0.003       -0.002       +0.002       -0.003       +0.007  +0.282
                         :    DRjet1eta:  +0.004   -0.006   -0.003    +0.134     +0.142     -0.008  +0.008   +0.001    +0.202  -0.006    -0.005     -0.001     +0.010   +0.002    +1.000  -0.003    +0.018     +0.018     -0.015   -0.007    +0.623  -0.004    +0.021     +0.012     -0.000   -0.003    +0.623  +0.005    +0.016     +0.013     -0.003    -0.004     +0.853      +0.317      +0.000   -0.015    -0.004    -0.007     +0.678      +0.015      +0.001   -0.002    -0.003     +0.857      +0.359      -0.009   -0.003   -0.007    +0.171     -0.071     +0.010  +0.012   -0.005    +0.831       +0.635       +0.083       -0.005       -0.001  -0.007
                         :      DRjet1m:  +0.051   +0.013   +0.266    -0.007     -0.002     +0.007  +0.081   +0.154    +0.007  +0.128    -0.017     -0.034     +0.012   +0.854    -0.003  +1.000    -0.082     -0.218     +0.158   -0.000    -0.004  +0.015    -0.047     -0.021     +0.044   +0.022    +0.006  +0.017    +0.005     -0.013     +0.012    +0.540     +0.000      -0.003      -0.005   +0.353    -0.344    -0.021     -0.003      -0.007      +0.010   +0.069    +0.597     +0.000      -0.009      -0.013   +0.362   +0.320    -0.001     -0.010     -0.008  +0.099   +0.446    +0.000       -0.005       +0.002       -0.004       +0.011  +0.288
                         :    DRjet1csv:  -0.013   +0.002   -0.042    +0.012     +0.017     -0.004  -0.052   -0.027    +0.020  -0.006    +0.033     +0.022     -0.028   -0.054    +0.018  -0.082    +1.000     +0.162     -0.701   -0.003    +0.004  -0.012    +0.480     +0.115     -0.325   -0.000    +0.011  -0.000    +0.016     +0.075     -0.084    -0.044     +0.013      +0.010      +0.008   +0.021    +0.031    -0.011     +0.006      -0.004      -0.006   +0.012    -0.050     +0.017      +0.009      -0.003   -0.004   -0.054    +0.016     -0.004     +0.000  -0.043   -0.048    +0.012       +0.005       -0.005       -0.008       -0.001  +0.008
                         :   DRjet1cvsl:  -0.023   -0.020   -0.074    +0.008     +0.008     -0.011  -0.024   -0.040    +0.002  -0.029    +0.010     +0.038     +0.000   -0.202    +0.018  -0.218    +0.162     +1.000     -0.217   -0.016    +0.003  -0.024    +0.068     +0.042     -0.051   -0.010    +0.005  -0.009    -0.000     +0.004     -0.005    -0.141     +0.013      +0.013      +0.014   -0.088    +0.093    -0.014     +0.003      +0.006      -0.021   -0.018    -0.150     +0.013      +0.014      +0.003   -0.074   -0.089    +0.007     +0.002     -0.004  -0.028   -0.123    +0.011       +0.021       -0.008       -0.005       -0.008  -0.063
                         :   DRjet1cvsb:  +0.024   -0.009   +0.073    -0.012     -0.020     +0.007  +0.046   +0.034    -0.011  +0.018    -0.034     -0.025     +0.033   +0.124    -0.015  +0.158    -0.701     -0.217     +1.000   +0.009    -0.009  +0.015    -0.355     -0.092     +0.253   +0.014    -0.008  +0.016    -0.006     -0.060     +0.073    +0.093     -0.014      -0.005      -0.009   +0.010    -0.066    +0.017     -0.012      +0.001      +0.005   -0.004    +0.103     -0.014      -0.005      +0.002   +0.030   +0.085    -0.009     -0.002     -0.000  +0.042   +0.089    -0.014       -0.006       -0.002       +0.011       +0.000  +0.015
                         :     DRjet2pt:  +0.093   +0.058   +0.323    -0.008     -0.003     -0.012  +0.094   +0.252    -0.007  +0.195    -0.034     -0.050     +0.038   -0.005    -0.007  -0.000    -0.003     -0.016     +0.009   +1.000    +0.001  +0.876    -0.003     -0.180     +0.046   +0.062    -0.014  +0.044    -0.003     -0.031     +0.012    +0.722     -0.003      -0.006      -0.014   +0.407    -0.460    +0.763     -0.002      +0.010      +0.003   +0.438    -0.005     -0.010      +0.007      -0.004   +0.064   +0.428    -0.007     -0.008     +0.004  +0.145   +0.615    -0.005       -0.000       -0.001       -0.004       +0.012  +0.341
                         :    DRjet2eta:  -0.002   -0.007   +0.002    +0.124     +0.138     -0.009  +0.017   -0.004    +0.199  -0.013    +0.017     +0.010     -0.009   -0.002    +0.623  -0.004    +0.004     +0.003     -0.009   +0.001    +1.000  +0.009    +0.010     +0.003     +0.004   +0.007    +0.638  +0.011    +0.009     +0.004     +0.011    -0.002     +0.868      -0.399      +0.005   +0.001    +0.000    +0.005     +0.867      +0.393      +0.002   +0.005    +0.001     +0.689      -0.041      -0.002   +0.011   -0.007    +0.165     -0.072     +0.009  +0.026   +0.001    +0.846       +0.638       +0.614       +0.003       -0.003  +0.008
                         :      DRjet2m:  +0.083   +0.053   +0.282    -0.007     -0.004     -0.011  +0.080   +0.210    -0.010  +0.180    -0.032     -0.048     +0.043   +0.011    -0.004  +0.015    -0.012     -0.024     +0.015   +0.876    +0.009  +1.000    -0.021     -0.207     +0.067   +0.047    -0.008  +0.048    -0.002     -0.021     -0.002    +0.632     +0.003      -0.016      -0.017   +0.438    -0.371    +0.653     +0.006      +0.013      +0.004   +0.423    -0.004     -0.001      +0.003      -0.001   +0.078   +0.366    -0.008     -0.005     +0.004  +0.124   +0.528    +0.003       +0.003       +0.008       -0.004       +0.012  +0.346
                         :    DRjet2csv:  -0.016   +0.010   -0.040    +0.014     +0.016     -0.005  -0.035   -0.029    +0.011  -0.017    +0.031     +0.014     -0.025   -0.038    +0.021  -0.047    +0.480     +0.068     -0.355   -0.003    +0.010  -0.021    +1.000     +0.264     -0.677   +0.008    +0.015  +0.001    +0.050     +0.152     -0.170    -0.038     +0.018      +0.009      -0.008   +0.018    +0.039    -0.016     +0.014      +0.007      +0.016   +0.035    -0.044     +0.018      +0.018      +0.009   +0.022   -0.056    +0.014     +0.008     +0.005  -0.035   -0.048    +0.018       +0.019       -0.002       +0.013       +0.003  +0.033
                         :   DRjet2cvsl:  -0.016   -0.009   -0.079    -0.003     +0.001     -0.011  -0.023   -0.043    +0.006  -0.031    +0.012     +0.033     -0.015   -0.018    +0.012  -0.021    +0.115     +0.042     -0.092   -0.180    +0.003  -0.207    +0.264     +1.000     -0.269   -0.015    +0.007  -0.015    +0.008     +0.039     -0.039    -0.145     +0.005      +0.020      +0.003   -0.081    +0.090    -0.149     +0.001      -0.004      +0.003   -0.071    -0.021     +0.007      +0.010      +0.020   -0.026   -0.097    -0.000     -0.001     +0.014  -0.027   -0.131    +0.005       +0.004       -0.011       +0.015       -0.020  -0.070
                         :   DRjet2cvsb:  +0.024   +0.009   +0.050    +0.002     +0.001     +0.011  +0.018   +0.036    +0.007  +0.030    -0.035     -0.018     +0.041   +0.044    -0.000  +0.044    -0.325     -0.051     +0.253   +0.046    +0.004  +0.067    -0.677     -0.269     +1.000   -0.004    -0.004  +0.002    -0.043     -0.115     +0.118    +0.072     -0.002      -0.005      +0.002   +0.007    -0.056    +0.047     -0.004      -0.003      -0.007   -0.007    +0.044     +0.001      -0.011      -0.012   -0.002   +0.063    +0.006     -0.010     -0.026  +0.027   +0.073    -0.002       -0.004       +0.011       -0.020       +0.003  -0.001
                         :     DRjet3pt:  +0.086   +0.028   +0.235    +0.002     +0.009     +0.006  +0.084   +0.167    +0.003  +0.128    -0.004     -0.021     +0.015   +0.042    -0.003  +0.022    -0.000     -0.010     +0.014   +0.062    +0.007  +0.047    +0.008     -0.015     -0.004   +1.000    +0.007  +0.848    +0.050     +0.028     +0.003    +0.080     +0.004      -0.000      -0.008   +0.025    -0.071    +0.524     +0.009      +0.003      +0.005   +0.391    +0.553     +0.005      -0.005      -0.009   +0.387   +0.308    -0.003     +0.008     -0.004  +0.100   +0.409    +0.007       +0.005       +0.004       -0.014       +0.004  +0.405
                         :    DRjet3eta:  +0.011   -0.007   +0.000    +0.170     +0.172     -0.007  +0.014   +0.004    +0.227  -0.004    +0.012     +0.005     -0.000   +0.006    +0.623  +0.006    +0.011     +0.005     -0.008   -0.014    +0.638  -0.008    +0.015     +0.007     -0.004   +0.007    +1.000  +0.012    +0.030     +0.009     -0.002    -0.005     +0.686      -0.045      +0.005   -0.008    -0.001    -0.012     +0.860      -0.284      -0.007   -0.003    +0.007     +0.858      -0.339      -0.007   +0.005   -0.005    +0.206     -0.069     -0.006  +0.023   -0.005    +0.833       +0.184       +0.569       -0.006       -0.007  +0.001
                         :      DRjet3m:  +0.085   +0.019   +0.207    -0.001     +0.004     +0.001  +0.071   +0.135    +0.000  +0.120    -0.010     -0.025     +0.024   +0.013    +0.005  +0.017    -0.000     -0.009     +0.016   +0.044    +0.011  +0.048    +0.001     -0.015     +0.002   +0.848    +0.012  +1.000    +0.094     +0.048     -0.031    +0.049     +0.012      +0.001      -0.005   -0.003    -0.056    +0.435     +0.015      +0.001      +0.006   +0.345    +0.453     +0.012      -0.006      -0.010   +0.332   +0.260    -0.005     +0.009     -0.005  +0.092   +0.331    +0.015       +0.006       +0.009       -0.012       +0.005  +0.341
                         :    DRjet3csv:  +0.000   +0.031   -0.003    +0.005     -0.001     +0.007  +0.003   -0.024    +0.006  -0.021    -0.018     +0.003     +0.012   -0.015    +0.016  +0.005    +0.016     -0.000     -0.006   -0.003    +0.009  -0.002    +0.050     +0.008     -0.043   +0.050    +0.030  +0.094    +1.000     +0.118     -0.007    -0.016     +0.014      +0.000      +0.003   -0.009    +0.022    +0.001     +0.021      -0.008      +0.007   +0.045    -0.006     +0.022      -0.011      -0.007   +0.053   -0.028    +0.008     -0.008     -0.018  +0.003   -0.018    +0.022       -0.000       +0.018       -0.002       +0.007  +0.048
                         :   DRjet3cvsl:  -0.069   +0.112   -0.096    +0.014     +0.006     -0.009  -0.018   -0.112    +0.014  -0.071    -0.025     +0.017     +0.020   -0.028    +0.013  -0.013    +0.075     +0.004     -0.060   -0.031    +0.004  -0.021    +0.152     +0.039     -0.115   +0.028    +0.009  +0.048    +0.118     +1.000     -0.749    -0.067     +0.011      +0.016      +0.001   +0.020    +0.105    -0.101     +0.013      -0.005      +0.003   +0.187    -0.099     +0.017      +0.001      -0.007   +0.183   -0.176    +0.020     -0.009     +0.003  -0.036   -0.142    +0.016       +0.007       +0.003       -0.003       +0.002  +0.195
                         :   DRjet3cvsb:  +0.065   -0.100   +0.091    -0.011     -0.004     +0.007  +0.002   +0.106    -0.008  +0.070    -0.006     -0.005     +0.029   +0.027    -0.003  +0.012    -0.084     -0.005     +0.073   +0.012    +0.011  -0.002    -0.170     -0.039     +0.118   +0.003    -0.002  -0.031    -0.007     -0.749     +1.000    +0.049     +0.004      -0.016      -0.003   -0.032    -0.085    +0.097     +0.001      +0.005      +0.006   -0.172    +0.109     -0.009      -0.008      -0.005   -0.158   +0.168    -0.013     -0.001     +0.005  +0.019   +0.135    -0.002       -0.003       +0.010       +0.004       +0.007  -0.180
                         :    DRjet12pt:  +0.121   +0.064   +0.465    -0.014     -0.003     -0.007  +0.136   +0.329    -0.008  +0.247    -0.034     -0.058     +0.035   +0.639    -0.004  +0.540    -0.044     -0.141     +0.093   +0.722    -0.002  +0.632    -0.038     -0.145     +0.072   +0.080    -0.005  +0.049    -0.016     -0.067     +0.049    +1.000     -0.000      -0.004      -0.015   +0.386    -0.771    +0.575     -0.002      +0.001      +0.004   +0.327    +0.490     -0.005      +0.001      -0.014   +0.264   +0.600    -0.011     -0.002     -0.003  +0.193   +0.864    -0.001       -0.001       +0.000       -0.007       +0.012  +0.378
                         :   DRjet12eta:  -0.001   -0.004   +0.003    +0.117     +0.127     -0.011  +0.012   -0.001    +0.204  -0.012    +0.008     +0.008     -0.001   +0.004    +0.853  +0.000    +0.013     +0.013     -0.014   -0.003    +0.868  +0.003    +0.018     +0.005     -0.002   +0.004    +0.686  +0.012    +0.014     +0.011     +0.004    -0.000     +1.000      -0.053      +0.006   -0.005    -0.004    -0.000     +0.844      +0.193      -0.003   +0.002    +0.004     +0.839      +0.133      -0.005   +0.003   -0.006    +0.162     -0.085     +0.015  +0.019   +0.001    +0.938       +0.689       +0.380       -0.002       -0.006  +0.001
                         :  DRjet12deta:  +0.016   +0.004   +0.001    -0.001     -0.007     +0.000  -0.013   +0.004    -0.010  +0.008    -0.024     -0.015     +0.023   -0.000    +0.317  -0.003    +0.010     +0.013     -0.005   -0.006    -0.399  -0.016    +0.009     +0.020     -0.005   -0.000    -0.045  +0.001    +0.000     +0.016     -0.016    -0.004     -0.053      +1.000      -0.000   -0.022    -0.009    -0.003     -0.208      -0.475      +0.006   -0.008    -0.002     +0.114      +0.465      -0.002   -0.013   +0.003    -0.006     +0.004     -0.000  -0.017   -0.004    -0.054       -0.040       -0.711       -0.001       -0.005  -0.015
                         :  DRjet12dphi:  -0.004   -0.006   -0.004    -0.001     -0.004     -0.021  -0.003   +0.010    +0.001  +0.007    -0.008     +0.003     +0.001   -0.002    +0.000  -0.005    +0.008     +0.014     -0.009   -0.014    +0.005  -0.017    -0.008     +0.003     +0.002   -0.008    +0.005  -0.005    +0.003     +0.001     -0.003    -0.015     +0.006      -0.000      +1.000   -0.005    +0.022    -0.012     +0.005      +0.004      -0.382   -0.011    -0.004     +0.003      -0.000      +0.386   -0.006   +0.004    +0.003     +0.003     +0.000  +0.003   -0.013    +0.010       +0.004       -0.000       +0.004       -0.723  -0.009
                         :     DRjet12m:  +0.009   +0.016   +0.171    +0.001     +0.002     +0.015  +0.003   +0.107    +0.003  +0.093    -0.016     -0.039     +0.015   +0.327    -0.015  +0.353    +0.021     -0.088     +0.010   +0.407    +0.001  +0.438    +0.018     -0.081     +0.007   +0.025    -0.008  -0.003    -0.009     +0.020     -0.032    +0.386     -0.005      -0.022      -0.005   +1.000    +0.077    +0.251     -0.004      +0.007      +0.013   +0.328    +0.180     -0.011      -0.014      +0.005   +0.263   +0.212    +0.001     -0.009     -0.010  +0.019   +0.298    -0.004       -0.007       +0.009       -0.005       +0.009  +0.512
                         :    DRjet12DR:  -0.105   -0.071   -0.358    +0.015     +0.003     +0.006  -0.115   -0.262    +0.012  -0.195    +0.023     +0.048     -0.030   -0.442    -0.004  -0.344    +0.031     +0.093     -0.066   -0.460    +0.000  -0.371    +0.039     +0.090     -0.056   -0.071    -0.001  -0.056    +0.022     +0.105     -0.085    -0.771     -0.004      -0.009      +0.022   +0.077    +1.000    -0.425     -0.003      +0.005      +0.000   -0.123    -0.397     -0.003      -0.004      +0.017   -0.098   -0.471    +0.012     -0.007     +0.005  -0.175   -0.691    -0.003       -0.002       +0.002       +0.010       -0.012  -0.089
                         :    DRjet23pt:  +0.176   +0.066   +0.430    -0.000     +0.007     -0.007  +0.135   +0.295    -0.002  +0.219    -0.019     -0.053     +0.029   -0.006    -0.007  -0.021    -0.011     -0.014     +0.017   +0.763    +0.005  +0.653    -0.016     -0.149     +0.047   +0.524    -0.012  +0.435    +0.001     -0.101     +0.097    +0.575     -0.000      -0.003      -0.012   +0.251    -0.425    +1.000     -0.000      +0.010      -0.001   +0.270    +0.298     -0.008      +0.009      -0.005   +0.140   +0.550    -0.005     +0.002     +0.006  +0.182   +0.778    -0.003       +0.005       -0.006       -0.006       -0.000  +0.258
                         :   DRjet23eta:  +0.007   -0.008   +0.004    +0.154     +0.160     -0.010  +0.014   +0.002    +0.222  -0.007    +0.011     +0.010     +0.000   -0.002    +0.678  -0.003    +0.006     +0.003     -0.012   -0.002    +0.867  +0.006    +0.014     +0.001     -0.004   +0.009    +0.860  +0.015    +0.021     +0.013     +0.001    -0.002     +0.844      -0.208      +0.005   -0.004    -0.003    -0.000     +1.000      +0.050      -0.001   +0.006    +0.001     +0.832      -0.172      -0.000   +0.012   -0.005    +0.195     -0.074     -0.002  +0.027   -0.001    +0.935       +0.432       +0.639       +0.001       -0.007  +0.009
                         :  DRjet23deta:  -0.022   +0.007   +0.001    -0.020     -0.008     -0.004  +0.004   -0.005    -0.009  -0.010    +0.011     +0.002     -0.010   -0.008    +0.015  -0.007    -0.004     +0.006     +0.001   +0.010    +0.393  +0.013    +0.007     -0.004     -0.003   +0.003    -0.284  +0.001    -0.008     -0.005     +0.005    +0.001     +0.193      -0.475      +0.004   +0.007    +0.005    +0.010     +0.050      +1.000      +0.001   +0.011    -0.005     -0.118      +0.311      +0.004   +0.009   -0.002    -0.021     +0.005     +0.013  +0.007   +0.002    +0.049       +0.593       +0.104       +0.002       +0.001  +0.010
                         :  DRjet23dphi:  +0.011   +0.005   +0.006    +0.013     +0.007     +0.036  +0.007   -0.002    +0.014  -0.003    -0.003     -0.000     +0.004   +0.009    +0.001  +0.010    -0.006     -0.021     +0.005   +0.003    +0.002  +0.004    +0.016     +0.003     -0.007   +0.005    -0.007  +0.006    +0.007     +0.003     +0.006    +0.004     -0.003      +0.006      -0.382   +0.013    +0.000    -0.001     -0.001      +0.001      +1.000   +0.000    +0.018     -0.002      +0.001      +0.105   -0.008   +0.002    +0.011     -0.012     -0.010  +0.006   +0.005    -0.000       -0.003       -0.003       +0.560       +0.232  -0.002
                         :     DRjet23m:  -0.056   +0.029   +0.106    -0.005     -0.002     +0.001  +0.025   +0.127    -0.011  +0.109    -0.024     -0.029     +0.026   +0.057    -0.002  +0.069    +0.012     -0.018     -0.004   +0.438    +0.005  +0.423    +0.035     -0.071     -0.007   +0.391    -0.003  +0.345    +0.045     +0.187     -0.172    +0.327     +0.002      -0.008      -0.011   +0.328    -0.123    +0.270     +0.006      +0.011      +0.000   +1.000    +0.142     +0.004      -0.002      -0.009   +0.488   +0.166    -0.006     +0.006     -0.011  +0.055   +0.233    +0.007       +0.004       +0.010       -0.020       +0.015  +0.850
                         :    DRjet31pt:  +0.155   +0.037   +0.413    -0.005     +0.006     +0.002  +0.124   +0.254    +0.006  +0.183    +0.002     -0.036     +0.000   +0.727    -0.003  +0.597    -0.050     -0.150     +0.103   -0.005    +0.001  -0.004    -0.044     -0.021     +0.044   +0.553    +0.007  +0.453    -0.006     -0.099     +0.109    +0.490     +0.004      -0.002      -0.004   +0.180    -0.397    +0.298     +0.001      -0.005      +0.018   +0.142    +1.000     +0.001      -0.009      -0.011   +0.214   +0.515    -0.004     -0.003     -0.010  +0.147   +0.721    +0.003       +0.001       +0.002       +0.003       -0.000  +0.212
                         :   DRjet31eta:  +0.004   -0.007   -0.001    +0.161     +0.161     -0.007  +0.011   +0.002    +0.230  -0.006    +0.003     +0.002     +0.005   +0.003    +0.857  +0.000    +0.017     +0.013     -0.014   -0.010    +0.689  -0.001    +0.018     +0.007     +0.001   +0.005    +0.858  +0.012    +0.022     +0.017     -0.009    -0.005     +0.839      +0.114      +0.003   -0.011    -0.003    -0.008     +0.832      -0.118      -0.002   +0.004    +0.001     +1.000      -0.004      -0.019   +0.011   -0.006    +0.202     -0.079     +0.001  +0.018   -0.006    +0.931       +0.427       +0.357       -0.006       -0.004  +0.006
                         :  DRjet31deta:  -0.003   +0.000   +0.007    -0.024     -0.014     +0.002  -0.007   -0.009    -0.023  -0.002    -0.021     -0.004     +0.018   -0.009    +0.359  -0.009    +0.009     +0.014     -0.005   +0.007    -0.041  +0.003    +0.018     +0.010     -0.011   -0.005    -0.339  -0.006    -0.011     +0.001     -0.008    +0.001     +0.133      +0.465      -0.000   -0.014    -0.004    +0.009     -0.172      +0.311      +0.001   -0.002    -0.009     -0.004      +1.000      +0.001   -0.010   +0.003    -0.027     +0.013     +0.006  -0.009   +0.001    -0.013       +0.544       -0.644       +0.005       -0.001  -0.010
                         :  DRjet31dphi:  -0.012   -0.001   -0.001    -0.008     -0.003     +0.025  +0.004   -0.003    -0.000  -0.009    -0.003     +0.001     +0.001   -0.010    -0.009  -0.013    -0.003     +0.003     +0.002   -0.004    -0.002  -0.001    +0.009     +0.020     -0.012   -0.009    -0.007  -0.010    -0.007     -0.007     -0.005    -0.014     -0.005      -0.002      +0.386   +0.005    +0.017    -0.005     -0.000      +0.004      +0.105   -0.009    -0.011     -0.019      +0.001      +1.000   -0.010   -0.003    -0.004     -0.002     +0.001  -0.003   -0.013    -0.008       -0.003       -0.004       +0.560       -0.653  -0.009
                         :     DRjet31m:  -0.066   +0.007   +0.092    -0.002     -0.000     +0.003  +0.037   +0.089    -0.006  +0.071    -0.021     -0.007     +0.020   +0.374    -0.003  +0.362    -0.004     -0.074     +0.030   +0.064    +0.011  +0.078    +0.022     -0.026     -0.002   +0.387    +0.005  +0.332    +0.053     +0.183     -0.158    +0.264     +0.003      -0.013      -0.006   +0.263    -0.098    +0.140     +0.012      +0.009      -0.008   +0.488    +0.214     +0.011      -0.010      -0.010   +1.000   +0.129    -0.003     +0.012     -0.007  +0.054   +0.183    +0.014       -0.003       +0.018       -0.022       +0.013  +0.834
                         :     DRlepTpt:  +0.175   +0.034   +0.767    -0.016     -0.005     +0.001  +0.169   +0.505    -0.001  +0.369    -0.018     -0.062     +0.029   +0.387    -0.007  +0.320    -0.054     -0.089     +0.085   +0.428    -0.007  +0.366    -0.056     -0.097     +0.063   +0.308    -0.005  +0.260    -0.028     -0.176     +0.168    +0.600     -0.006      +0.003      +0.004   +0.212    -0.471    +0.550     -0.005      -0.002      +0.002   +0.166    +0.515     -0.006      +0.003      -0.003   +0.129   +1.000    -0.013     -0.009     +0.008  +0.229   +0.699    -0.006       -0.001       -0.006       +0.004       -0.010  +0.188
                         :    DRlepTeta:  -0.004   +0.000   -0.009    +0.850     +0.786     +0.000  +0.011   +0.005    +0.873  +0.005    +0.021     +0.009     -0.015   -0.003    +0.171  -0.001    +0.016     +0.007     -0.009   -0.007    +0.165  -0.008    +0.014     -0.000     +0.006   -0.003    +0.206  -0.005    +0.008     +0.020     -0.013    -0.011     +0.162      -0.006      +0.003   +0.001    +0.012    -0.005     +0.195      -0.021      +0.011   -0.006    -0.004     +0.202      -0.027      -0.004   -0.003   -0.013    +1.000     -0.174     +0.010  +0.019   -0.008    +0.192       +0.084       +0.111       +0.008       +0.010  -0.005
                         :   DRlepTdeta:  +0.002   -0.001   -0.005    +0.151     +0.166     -0.005  +0.001   -0.013    -0.457  -0.014    -0.007     +0.000     -0.002   -0.007    -0.071  -0.010    -0.004     +0.002     -0.002   -0.008    -0.072  -0.005    +0.008     -0.001     -0.010   +0.008    -0.069  +0.009    -0.008     -0.009     -0.001    -0.002     -0.085      +0.004      +0.003   -0.009    -0.007    +0.002     -0.074      +0.005      -0.012   +0.006    -0.003     -0.079      +0.013      -0.002   +0.012   -0.009    -0.174     +1.000     -0.002  -0.001   +0.001    -0.081       -0.042       -0.044       -0.006       -0.002  +0.010
                         :   DRlepTdphi:  +0.000   +0.007   +0.005    +0.003     +0.009     -0.390  -0.003   +0.003    +0.012  +0.010    -0.022     -0.006     +0.020   -0.010    +0.010  -0.008    +0.000     -0.004     -0.000   +0.004    +0.009  +0.004    +0.005     +0.014     -0.026   -0.004    -0.006  -0.005    -0.018     +0.003     +0.005    -0.003     +0.015      -0.000      +0.000   -0.010    +0.005    +0.006     -0.002      +0.013      -0.010   -0.011    -0.010     +0.001      +0.006      +0.001   -0.007   +0.008    +0.010     -0.002     +1.000  -0.003   -0.002    +0.003       +0.012       -0.004       -0.024       -0.004  -0.012
                         :      DRlepTm:  +0.063   +0.023   +0.212    +0.012     +0.008     -0.009  +0.782   +0.282    +0.015  +0.297    -0.027     -0.094     +0.028   +0.109    +0.012  +0.099    -0.043     -0.028     +0.042   +0.145    +0.026  +0.124    -0.035     -0.027     +0.027   +0.100    +0.023  +0.092    +0.003     -0.036     +0.019    +0.193     +0.019      -0.017      +0.003   +0.019    -0.175    +0.182     +0.027      +0.007      +0.006   +0.055    +0.147     +0.018      -0.009      -0.003   +0.054   +0.229    +0.019     -0.001     -0.003  +1.000   +0.220    +0.022       +0.009       +0.023       -0.001       -0.004  +0.057
                         :     DRhadTpt:  +0.200   +0.069   +0.552    -0.007     +0.005     -0.006  +0.165   +0.363    -0.002  +0.267    -0.019     -0.062     +0.025   +0.550    -0.005  +0.446    -0.048     -0.123     +0.089   +0.615    +0.001  +0.528    -0.048     -0.131     +0.073   +0.409    -0.005  +0.331    -0.018     -0.142     +0.135    +0.864     +0.001      -0.004      -0.013   +0.298    -0.691    +0.778     -0.001      +0.002      +0.005   +0.233    +0.721     -0.006      +0.001      -0.013   +0.183   +0.699    -0.008     +0.001     -0.002  +0.220   +1.000    -0.002       +0.002       -0.002       -0.004       +0.003  +0.263
                         :    DRhadTeta:  +0.004   -0.007   +0.002    +0.150     +0.154     -0.010  +0.013   -0.000    +0.225  -0.010    +0.008     +0.007     +0.001   +0.003    +0.831  +0.000    +0.012     +0.011     -0.014   -0.005    +0.846  +0.003    +0.018     +0.005     -0.002   +0.007    +0.833  +0.015    +0.022     +0.016     -0.002    -0.001     +0.938      -0.054      +0.010   -0.004    -0.003    -0.003     +0.935      +0.049      -0.000   +0.007    +0.003     +0.931      -0.013      -0.008   +0.014   -0.006    +0.192     -0.081     +0.003  +0.022   -0.002    +1.000       +0.539       +0.481       -0.002       -0.006  +0.010
                         : DRhadTHbdeta:  +0.001   +0.002   +0.009    +0.059     +0.074     -0.009  +0.006   -0.009    +0.114  -0.013    +0.011     +0.004     -0.006   -0.002    +0.635  -0.005    +0.005     +0.021     -0.006   -0.000    +0.638  +0.003    +0.019     +0.004     -0.004   +0.005    +0.184  +0.006    -0.000     +0.007     -0.003    -0.001     +0.689      -0.040      +0.004   -0.007    -0.002    +0.005     +0.432      +0.593      -0.003   +0.004    +0.001     +0.427      +0.544      -0.003   -0.003   -0.001    +0.084     -0.042     +0.012  +0.009   +0.002    +0.539       +1.000       +0.011       +0.001       -0.001  -0.002
                         : DRhadTWbdeta:  -0.003   -0.007   -0.004    +0.091     +0.088     -0.006  +0.012   +0.004    +0.121  -0.004    +0.021     +0.018     -0.016   +0.002    +0.083  +0.002    -0.005     -0.008     -0.002   -0.001    +0.614  +0.008    -0.002     -0.011     +0.011   +0.004    +0.569  +0.009    +0.018     +0.003     +0.010    +0.000     +0.380      -0.711      -0.000   +0.009    +0.002    -0.006     +0.639      +0.104      -0.003   +0.010    +0.002     +0.357      -0.644      -0.004   +0.018   -0.006    +0.111     -0.044     -0.004  +0.023   -0.002    +0.481       +0.011       +1.000       -0.006       +0.005  +0.017
                         : DRhadTHbdphi:  +0.003   -0.006   +0.012    +0.007     -0.001     +0.039  +0.004   -0.007    +0.011  -0.013    +0.001     +0.001     -0.002   -0.003    -0.005  -0.004    -0.008     -0.005     +0.011   -0.004    +0.003  -0.004    +0.013     +0.015     -0.020   -0.014    -0.006  -0.012    -0.002     -0.003     +0.004    -0.007     -0.002      -0.001      +0.004   -0.005    +0.010    -0.006     +0.001      +0.002      +0.560   -0.020    +0.003     -0.006      +0.005      +0.560   -0.022   +0.004    +0.008     -0.006     -0.024  -0.001   -0.004    -0.002       +0.001       -0.006       +1.000       -0.318  -0.023
                         : DRhadTWbdphi:  -0.004   +0.007   -0.007    +0.006     +0.008     -0.012  -0.002   -0.008    +0.009  -0.001    +0.005     -0.002     +0.005   +0.007    -0.001  +0.011    -0.001     -0.008     +0.000   +0.012    -0.003  +0.012    +0.003     -0.020     +0.003   +0.004    -0.007  +0.005    +0.007     +0.002     +0.007    +0.012     -0.006      -0.005      -0.723   +0.009    -0.012    -0.000     -0.007      +0.001      +0.232   +0.015    -0.000     -0.004      -0.001      -0.653   +0.013   -0.010    +0.010     -0.002     -0.004  -0.004   +0.003    -0.006       -0.001       +0.005       -0.318       +1.000  +0.015
                         :      DRhadTm:  -0.063   +0.022   +0.129    -0.004     -0.001     +0.006  +0.030   +0.134    -0.010  +0.111    -0.026     -0.024     +0.026   +0.282    -0.007  +0.288    +0.008     -0.063     +0.015   +0.341    +0.008  +0.346    +0.033     -0.070     -0.001   +0.405    +0.001  +0.341    +0.048     +0.195     -0.180    +0.378     +0.001      -0.015      -0.009   +0.512    -0.089    +0.258     +0.009      +0.010      -0.002   +0.850    +0.212     +0.006      -0.010      -0.009   +0.834   +0.188    -0.005     +0.010     -0.012  +0.057   +0.263    +0.010       -0.002       +0.017       -0.023       +0.015  +1.000
                         : ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                         :                 njets nbjets_m DRlepWpt DRlepWeta DRlepWdeta DRlepWdphi DRlepWm DRjet0pt DRjet0eta DRjet0m DRjet0csv DRjet0cvsl DRjet0cvsb DRjet1pt DRjet1eta DRjet1m DRjet1csv DRjet1cvsl DRjet1cvsb DRjet2pt DRjet2eta DRjet2m DRjet2csv DRjet2cvsl DRjet2cvsb DRjet3pt DRjet3eta DRjet3m DRjet3csv DRjet3cvsl DRjet3cvsb DRjet12pt DRjet12eta DRjet12deta DRjet12dphi DRjet12m DRjet12DR DRjet23pt DRjet23eta DRjet23deta DRjet23dphi DRjet23m DRjet31pt DRjet31eta DRjet31deta DRjet31dphi DRjet31m DRlepTpt DRlepTeta DRlepTdeta DRlepTdphi DRlepTm DRhadTpt DRhadTeta DRhadTHbdeta DRhadTWbdeta DRhadTHbdphi DRhadTWbdphi DRhadTm
                         :        njets:  +1.000   +0.150   +0.154    -0.010     +0.002     -0.003  +0.066   +0.141    -0.004  +0.136    +0.013     -0.025     -0.014   +0.084    -0.011  +0.090    -0.007     -0.041     +0.010   +0.105    -0.007  +0.104    +0.002     -0.038     -0.009   +0.085    -0.004  +0.095    -0.010     -0.093     +0.076    +0.134     -0.006      -0.006      +0.011   +0.097    +0.013    +0.178     -0.004      +0.007      -0.007   -0.009    +0.169     -0.007      -0.014      +0.000   -0.014   +0.209    -0.012     +0.004     +0.008  +0.093   +0.227    -0.006       -0.007       +0.007       +0.000       -0.005  +0.051
                         :     nbjets_m:  +0.150   +1.000   +0.020    +0.001     +0.002     -0.004  +0.014   +0.034    +0.002  +0.017    +0.003     -0.023     -0.014   +0.030    -0.012  +0.031    +0.046     -0.011     -0.027   +0.019    +0.001  +0.014    +0.071     -0.018     -0.053   +0.020    +0.007  +0.018    +0.028     +0.106     -0.102    +0.087     -0.005      -0.014      +0.001   -0.069    -0.126    +0.038     +0.003      -0.008      -0.006   -0.018    +0.056     -0.004      -0.018      -0.009   -0.011   +0.042    -0.001     -0.000     +0.003  +0.014   +0.090    -0.002       -0.004       +0.011       -0.009       +0.002  -0.046
                         :     DRlepWpt:  +0.154   +0.020   +1.000    +0.001     -0.001     -0.007  +0.254   +0.034    -0.014  +0.019    +0.025     +0.013     -0.027   +0.254    -0.015  +0.226    -0.044     -0.072     +0.060   +0.237    -0.010  +0.206    -0.063     -0.081     +0.060   +0.270    -0.009  +0.235    -0.007     -0.082     +0.064    +0.389     -0.016      -0.003      -0.005   +0.104    -0.129    +0.381     -0.013      -0.000      +0.004   +0.088    +0.399     -0.012      -0.002      -0.010   +0.093   +0.786    -0.005     +0.011     -0.004  +0.299   +0.521    -0.014       -0.007       -0.005       -0.001       +0.004  +0.125
                         :    DRlepWeta:  -0.010   +0.001   +0.001    +1.000     +0.812     -0.005  +0.015   -0.004    +0.562  -0.002    -0.001     -0.011     -0.006   +0.001    +0.180  +0.002    +0.016     -0.003     -0.012   +0.002    +0.129  -0.003    +0.004     -0.002     -0.008   +0.006    +0.166  +0.006    -0.001     -0.010     +0.010    +0.004     +0.173      +0.024      +0.001   +0.007    +0.004    -0.002     +0.167      -0.011      +0.009   +0.014    +0.003     +0.192      +0.024      +0.005   +0.000   +0.002    +0.821     +0.224     +0.002  +0.001   +0.001    +0.194       +0.093       +0.061       +0.008       -0.002  +0.010
                         :   DRlepWdeta:  +0.002   +0.002   -0.001    +0.812     +1.000     -0.003  +0.013   -0.002    +0.575  -0.002    +0.006     +0.003     -0.012   -0.003    +0.183  -0.004    +0.012     -0.010     -0.004   +0.003    +0.130  -0.001    -0.003     -0.004     -0.013   +0.008    +0.166  +0.008    -0.007     -0.016     +0.016    +0.004     +0.172      +0.027      +0.004   -0.001    -0.003    +0.001     +0.162      -0.012      +0.010   +0.012    +0.007     +0.190      +0.026      +0.003   -0.013   +0.002    +0.754     +0.226     -0.002  -0.001   +0.005    +0.188       +0.094       +0.056       +0.010       -0.007  -0.001
                         :   DRlepWdphi:  -0.003   -0.004   -0.007    -0.005     -0.003     +1.000  -0.001   +0.006    +0.001  +0.002    -0.012     +0.006     +0.008   +0.004    -0.009  +0.000    -0.001     +0.009     +0.007   -0.004    -0.008  -0.007    +0.003     +0.009     -0.003   -0.003    +0.001  -0.009    -0.002     -0.002     +0.010    -0.001     -0.009      +0.001      +0.002   +0.002    -0.003    -0.001     -0.008      -0.009      +0.049   -0.009    +0.001     -0.009      -0.008      +0.023   +0.000   -0.001    +0.001     -0.013     -0.381  +0.003   -0.000    -0.007       -0.006       -0.001       +0.042       -0.020  -0.002
                         :      DRlepWm:  +0.066   +0.014   +0.254    +0.015     +0.013     -0.001  +1.000   +0.047    +0.001  +0.047    +0.003     -0.018     -0.011   +0.085    -0.009  +0.067    -0.031     -0.021     +0.037   +0.082    -0.013  +0.072    -0.018     -0.022     +0.010   +0.086    -0.000  +0.086    +0.014     -0.012     -0.008    +0.120     -0.016      +0.001      -0.001   +0.034    -0.032    +0.119     -0.005      -0.005      +0.010   +0.034    +0.128     -0.004      -0.004      -0.000   +0.028   +0.184    +0.009     +0.016     +0.003  +0.716   +0.158    -0.008       -0.016       +0.001       -0.000       +0.006  +0.042
                         :     DRjet0pt:  +0.141   +0.034   +0.034    -0.004     -0.002     +0.006  +0.047   +1.000    -0.008  +0.822    +0.074     -0.078     -0.055   +0.215    -0.002  +0.166    -0.044     -0.059     +0.052   +0.228    -0.002  +0.200    -0.063     -0.061     +0.064   +0.228    -0.011  +0.200    -0.008     -0.085     +0.083    +0.328     -0.004      -0.001      +0.003   +0.119    -0.077    +0.318     -0.010      +0.015      +0.004   +0.121    +0.308     -0.009      +0.008      +0.004   +0.119   +0.542    -0.005     +0.001     +0.010  +0.388   +0.409    -0.008       +0.012       -0.009       -0.002       -0.001  +0.150
                         :    DRjet0eta:  -0.004   +0.002   -0.014    +0.562     +0.575     +0.001  +0.001   -0.008    +1.000  -0.012    +0.019     +0.005     -0.021   -0.007    +0.224  -0.001    +0.014     -0.007     -0.008   -0.008    +0.200  -0.011    +0.005     -0.002     -0.003   +0.004    +0.275  +0.003    +0.006     +0.006     -0.001    -0.012     +0.236      -0.001      +0.002   -0.001    +0.003    -0.009     +0.264      -0.038      +0.007   +0.010    -0.002     +0.280      -0.027      -0.001   -0.012   -0.014    +0.855     -0.469     +0.005  -0.006   -0.011    +0.278       +0.095       +0.134       +0.007       -0.008  -0.002
                         :      DRjet0m:  +0.136   +0.017   +0.019    -0.002     -0.002     +0.002  +0.047   +0.822    -0.012  +1.000    +0.041     -0.121     -0.022   +0.174    -0.003  +0.154    -0.039     -0.057     +0.050   +0.188    -0.003  +0.185    -0.046     -0.049     +0.056   +0.184    -0.015  +0.186    -0.005     -0.079     +0.063    +0.270     -0.006      +0.002      +0.001   +0.104    -0.054    +0.256     -0.012      +0.018      +0.002   +0.114    +0.245     -0.013      +0.013      +0.006   +0.105   +0.422    -0.007     +0.005     +0.007  +0.373   +0.330    -0.010       +0.013       -0.015       +0.006       -0.004  +0.135
                         :    DRjet0csv:  +0.013   +0.003   +0.025    -0.001     +0.006     -0.012  +0.003   +0.074    +0.019  +0.041    +1.000     +0.311     -0.770   -0.000    -0.002  -0.015    +0.003     -0.014     -0.003   +0.008    +0.012  +0.005    +0.004     -0.014     +0.016   +0.016    +0.013  +0.015    +0.004     -0.032     +0.007    +0.005     +0.009      -0.015      +0.001   -0.011    -0.015    +0.034     +0.012      -0.000      +0.005   -0.001    +0.018     +0.010      -0.021      +0.018   -0.004   +0.057    +0.007     -0.011     -0.011  +0.013   +0.030    +0.010       -0.002       +0.024       +0.009       -0.006  -0.007
                         :   DRjet0cvsl:  -0.025   -0.023   +0.013    -0.011     +0.003     +0.006  -0.018   -0.078    +0.005  -0.121    +0.311     +1.000     -0.301   -0.017    -0.017  -0.017    -0.023     +0.060     +0.009   -0.032    -0.011  -0.033    -0.021     +0.065     +0.019   -0.014    +0.001  -0.019    -0.012     +0.043     +0.007    -0.037     -0.011      -0.015      +0.008   -0.024    +0.004    -0.028     -0.002      -0.008      +0.002   -0.016    -0.016     -0.006      -0.020      +0.011   -0.014   -0.034    -0.005     -0.005     -0.016  -0.050   -0.032    -0.007       -0.016       +0.009       +0.007       -0.015  -0.024
                         :   DRjet0cvsb:  -0.014   -0.014   -0.027    -0.006     -0.012     +0.008  -0.011   -0.055    -0.021  -0.022    -0.770     -0.301     +1.000   -0.003    +0.006  +0.010    +0.018     +0.010     +0.004   -0.010    -0.008  -0.002    +0.015     +0.009     -0.005   -0.019    -0.010  -0.015    +0.015     +0.024     +0.030    -0.005     -0.006      +0.011      +0.009   +0.008    +0.006    -0.031     -0.010      +0.004      -0.018   -0.003    -0.022     -0.004      +0.013      -0.019   +0.006   -0.054    -0.012     +0.014     +0.012  -0.010   -0.029    -0.008       +0.002       -0.020       -0.016       +0.003  +0.006
                         :     DRjet1pt:  +0.084   +0.030   +0.254    +0.001     -0.003     +0.004  +0.085   +0.215    -0.007  +0.174    -0.000     -0.017     -0.003   +1.000    -0.019  +0.862    -0.022     -0.175     +0.062   +0.026    -0.015  +0.027    -0.034     -0.046     +0.022   +0.039    -0.008  +0.022    -0.001     -0.038     +0.023    +0.591     -0.014      -0.012      -0.015   +0.373    -0.044    -0.003     -0.016      -0.009      -0.003   +0.084    +0.709     -0.015      -0.013      -0.017   +0.341   +0.334    -0.005     +0.008     +0.007  +0.127   +0.495    -0.015       -0.014       +0.007       -0.013       +0.015  +0.360
                         :    DRjet1eta:  -0.011   -0.012   -0.015    +0.180     +0.183     -0.009  -0.009   -0.002    +0.224  -0.003    -0.002     -0.017     +0.006   -0.019    +1.000  -0.016    +0.029     +0.028     -0.019   +0.005    +0.312  +0.006    +0.015     -0.002     -0.004   -0.015    +0.465  -0.019    -0.001     -0.004     +0.009    -0.004     +0.724      +0.471      -0.007   -0.005    -0.002    -0.010     +0.433      -0.106      +0.006   -0.002    -0.028     +0.801      +0.460      +0.008   -0.006   -0.014    +0.220     -0.043     +0.021  -0.007   -0.019    +0.695       +0.518       -0.149       +0.009       -0.009  -0.007
                         :      DRjet1m:  +0.090   +0.031   +0.226    +0.002     -0.004     +0.000  +0.067   +0.166    -0.001  +0.154    -0.015     -0.017     +0.010   +0.862    -0.016  +1.000    -0.031     -0.189     +0.081   +0.022    -0.018  +0.030    -0.027     -0.045     +0.014   +0.022    -0.007  +0.017    +0.006     -0.036     +0.020    +0.510     -0.012      -0.009      -0.015   +0.334    -0.035    -0.013     -0.017      -0.013      +0.011   +0.068    +0.611     -0.011      -0.014      -0.011   +0.283   +0.282    -0.001     -0.001     +0.012  +0.107   +0.424    -0.012       -0.014       +0.008       -0.009       +0.016  +0.311
                         :    DRjet1csv:  -0.007   +0.046   -0.044    +0.016     +0.012     -0.001  -0.031   -0.044    +0.014  -0.039    +0.003     -0.023     +0.018   -0.022    +0.029  -0.031    +1.000     +0.247     -0.742   -0.011    +0.012  -0.006    +0.475     +0.110     -0.289   -0.013    +0.019  -0.008    +0.052     +0.152     -0.141    -0.044     +0.026      +0.013      +0.009   -0.005    +0.009    -0.030     +0.013      -0.004      -0.020   +0.005    -0.046     +0.026      +0.005      -0.007   +0.028   -0.067    +0.015     +0.003     -0.002  -0.039   -0.062    +0.025       +0.016       +0.003       -0.002       -0.003  +0.007
                         :   DRjet1cvsl:  -0.041   -0.011   -0.072    -0.003     -0.010     +0.009  -0.021   -0.059    -0.007  -0.057    -0.014     +0.060     +0.010   -0.175    +0.028  -0.189    +0.247     +1.000     -0.283   -0.010    +0.007  -0.017    +0.116     +0.064     -0.063   -0.025    +0.005  -0.021    +0.022     +0.034     -0.015    -0.121     +0.018      +0.015      +0.001   -0.077    +0.008    -0.016     +0.007      +0.012      -0.010   -0.022    -0.143     +0.018      +0.009      -0.006   -0.068   -0.092    -0.006     +0.001     -0.007  -0.039   -0.115    +0.017       +0.018       -0.008       +0.000       -0.000  -0.078
                         :   DRjet1cvsb:  +0.010   -0.027   +0.060    -0.012     -0.004     +0.007  +0.037   +0.052    -0.008  +0.050    -0.003     +0.009     +0.004   +0.062    -0.019  +0.081    -0.742     -0.283     +1.000   +0.019    -0.011  +0.022    -0.361     -0.092     +0.219   +0.007    -0.021  +0.006    -0.043     -0.127     +0.118    +0.072     -0.019      -0.009      -0.011   +0.028    -0.015    +0.027     -0.017      +0.006      +0.023   -0.006    +0.079     -0.023      +0.005      +0.008   -0.022   +0.085    -0.008     -0.005     +0.003  +0.049   +0.084    -0.022       -0.007       -0.007       +0.006       +0.003  +0.009
                         :     DRjet2pt:  +0.105   +0.019   +0.237    +0.002     +0.003     -0.004  +0.082   +0.228    -0.008  +0.188    +0.008     -0.032     -0.010   +0.026    +0.005  +0.022    -0.011     -0.010     +0.019   +1.000    -0.006  +0.867    -0.008     -0.112     +0.023   +0.051    -0.005  +0.032    -0.002     -0.033     +0.023    +0.622     -0.005      +0.007      -0.005   +0.445    -0.009    +0.720     -0.010      -0.002      +0.013   +0.393    -0.002     +0.004      -0.002      -0.023   +0.084   +0.335    -0.002     +0.011     -0.007  +0.109   +0.499    -0.009       -0.007       -0.008       +0.010       +0.014  +0.428
                         :    DRjet2eta:  -0.007   +0.001   -0.010    +0.129     +0.130     -0.008  -0.013   -0.002    +0.200  -0.003    +0.012     -0.011     -0.008   -0.015    +0.312  -0.018    +0.012     +0.007     -0.011   -0.006    +1.000  -0.001    +0.014     +0.009     +0.000   -0.005    +0.493  -0.008    +0.011     +0.004     -0.005    -0.010     +0.771      -0.527      +0.001   -0.008    -0.004    -0.012     +0.825      +0.479      +0.001   -0.008    -0.024     +0.455      -0.142      +0.002   +0.003   -0.013    +0.174     -0.063     +0.000  -0.005   -0.022    +0.737       +0.536       +0.637       +0.010       -0.008  -0.007
                         :      DRjet2m:  +0.104   +0.014   +0.206    -0.003     -0.001     -0.007  +0.072   +0.200    -0.011  +0.185    +0.005     -0.033     -0.002   +0.027    +0.006  +0.030    -0.006     -0.017     +0.022   +0.867    -0.001  +1.000    -0.000     -0.125     +0.013   +0.047    -0.000  +0.040    +0.006     -0.021     +0.008    +0.535     +0.000      +0.004      -0.006   +0.399    +0.003    +0.616     -0.004      -0.000      +0.015   +0.362    +0.000     +0.010      -0.004      -0.015   +0.082   +0.291    -0.007     +0.010     -0.006  +0.099   +0.423    -0.002       -0.003       -0.006       +0.015       +0.020  +0.389
                         :    DRjet2csv:  +0.002   +0.071   -0.063    +0.004     -0.003     +0.003  -0.018   -0.063    +0.005  -0.046    +0.004     -0.021     +0.015   -0.034    +0.015  -0.027    +0.475     +0.116     -0.361   -0.008    +0.014  -0.000    +1.000     +0.272     -0.661   -0.014    +0.018  -0.008    +0.101     +0.303     -0.296    -0.058     +0.018      +0.003      -0.003   -0.005    +0.018    -0.054     +0.019      -0.003      -0.014   +0.044    -0.063     +0.022      -0.005      -0.010   +0.044   -0.103    +0.004     +0.001     +0.000  -0.022   -0.096    +0.019       +0.004       +0.010       +0.002       +0.010  +0.030
                         :   DRjet2cvsl:  -0.038   -0.018   -0.081    -0.002     -0.004     +0.009  -0.022   -0.061    -0.002  -0.049    -0.014     +0.065     +0.009   -0.046    -0.002  -0.045    +0.110     +0.064     -0.092   -0.112    +0.009  -0.125    +0.272     +1.000     -0.239   -0.039    +0.007  -0.048    +0.033     +0.085     -0.077    -0.114     +0.003      +0.001      -0.009   -0.092    -0.018    -0.112     +0.007      +0.000      -0.001   -0.053    -0.064     +0.006      -0.003      -0.005   -0.022   -0.105    -0.003     +0.009     +0.005  -0.038   -0.123    +0.004       -0.002       +0.005       +0.001       +0.003  -0.083
                         :   DRjet2cvsb:  -0.009   -0.053   +0.060    -0.008     -0.013     -0.003  +0.010   +0.064    -0.003  +0.056    +0.016     +0.019     -0.005   +0.022    -0.004  +0.014    -0.289     -0.063     +0.219   +0.023    +0.000  +0.013    -0.661     -0.239     +1.000   +0.022    -0.009  +0.016    -0.081     -0.240     +0.228    +0.058     -0.003      -0.004      +0.005   -0.009    -0.036    +0.067     -0.006      +0.016      -0.002   -0.044    +0.054     -0.010      +0.009      +0.003   -0.037   +0.100    -0.003     -0.011     -0.003  +0.011   +0.095    -0.006       +0.011       -0.006       -0.010       -0.010  -0.035
                         :     DRjet3pt:  +0.085   +0.020   +0.270    +0.006     +0.008     -0.003  +0.086   +0.228    +0.004  +0.184    +0.016     -0.014     -0.019   +0.039    -0.015  +0.022    -0.013     -0.025     +0.007   +0.051    -0.005  +0.047    -0.014     -0.039     +0.022   +1.000    -0.014  +0.858    +0.043     +0.000     +0.019    +0.044     -0.015      -0.011      +0.004   +0.040    +0.018    +0.572     -0.007      +0.021      +0.007   +0.408    +0.576     -0.007      +0.012      +0.008   +0.438   +0.351    +0.004     -0.009     +0.006  +0.139   +0.471    -0.006       +0.009       -0.008       +0.006       -0.006  +0.329
                         :    DRjet3eta:  -0.004   +0.007   -0.009    +0.166     +0.166     +0.001  -0.000   -0.011    +0.275  -0.015    +0.013     +0.001     -0.010   -0.008    +0.465  -0.007    +0.019     +0.005     -0.021   -0.005    +0.493  -0.000    +0.018     +0.007     -0.009   -0.014    +1.000  -0.016    +0.016     +0.006     -0.008    -0.004     +0.599      -0.052      +0.005   -0.013    -0.014    -0.015     +0.804      -0.352      -0.003   +0.008    -0.021     +0.805      -0.404      -0.007   -0.003   -0.012    +0.237     -0.098     +0.003  -0.003   -0.018    +0.794       +0.023       +0.530       -0.001       -0.001  -0.005
                         :      DRjet3m:  +0.095   +0.018   +0.235    +0.006     +0.008     -0.009  +0.086   +0.200    +0.003  +0.186    +0.015     -0.019     -0.015   +0.022    -0.019  +0.017    -0.008     -0.021     +0.006   +0.032    -0.008  +0.040    -0.008     -0.048     +0.016   +0.858    -0.016  +1.000    +0.076     +0.012     -0.015    +0.024     -0.018      -0.008      -0.000   +0.021    +0.013    +0.488     -0.011      +0.023      +0.009   +0.338    +0.496     -0.011      +0.011      +0.011   +0.368   +0.304    +0.002     -0.011     +0.008  +0.133   +0.403    -0.011       +0.011       -0.010       +0.009       -0.007  +0.266
                         :    DRjet3csv:  -0.010   +0.028   -0.007    -0.001     -0.007     -0.002  +0.014   -0.008    +0.006  -0.005    +0.004     -0.012     +0.015   -0.001    -0.001  +0.006    +0.052     +0.022     -0.043   -0.002    +0.011  +0.006    +0.101     +0.033     -0.081   +0.043    +0.016  +0.076    +1.000     +0.194     -0.074    -0.008     +0.008      +0.001      +0.007   -0.002    +0.002    +0.003     +0.016      +0.010      +0.006   +0.042    +0.007     +0.003      -0.013      +0.013   +0.056   -0.029    +0.001     -0.019     +0.002  +0.019   -0.009    +0.011       +0.010       +0.012       +0.009       -0.009  +0.035
                         :   DRjet3cvsl:  -0.093   +0.106   -0.082    -0.010     -0.016     -0.002  -0.012   -0.085    +0.006  -0.079    -0.032     +0.043     +0.024   -0.038    -0.004  -0.036    +0.152     +0.034     -0.127   -0.033    +0.004  -0.021    +0.303     +0.085     -0.240   +0.000    +0.006  +0.012    +0.194     +1.000     -0.717    -0.074     -0.001      -0.006      -0.011   -0.029    +0.010    -0.084     +0.002      +0.004      -0.002   +0.083    -0.082     +0.006      -0.005      -0.006   +0.099   -0.154    -0.002     -0.017     +0.007  -0.016   -0.129    +0.003       +0.003       +0.004       +0.001       -0.003  +0.052
                         :   DRjet3cvsb:  +0.076   -0.102   +0.064    +0.010     +0.016     +0.010  -0.008   +0.083    -0.001  +0.063    +0.007     +0.007     +0.030   +0.023    +0.009  +0.020    -0.141     -0.015     +0.118   +0.023    -0.005  +0.008    -0.296     -0.077     +0.228   +0.019    -0.008  -0.015    -0.074     -0.717     +1.000    +0.052     +0.004      +0.010      +0.015   +0.021    -0.004    +0.081     -0.005      -0.009      -0.003   -0.071    +0.079     -0.004      +0.010      +0.005   -0.086   +0.136    +0.008     +0.007     -0.021  +0.003   +0.118    -0.001       -0.001       -0.014       -0.003       +0.010  -0.049
                         :    DRjet12pt:  +0.134   +0.087   +0.389    +0.004     +0.004     -0.001  +0.120   +0.328    -0.012  +0.270    +0.005     -0.037     -0.005   +0.591    -0.004  +0.510    -0.044     -0.121     +0.072   +0.622    -0.010  +0.535    -0.058     -0.114     +0.058   +0.044    -0.004  +0.024    -0.008     -0.074     +0.052    +1.000     -0.010      +0.001      +0.002   +0.250    -0.389    +0.462     -0.010      -0.012      -0.010   +0.235    +0.440     -0.001      -0.014      -0.022   +0.194   +0.510    -0.003     +0.019     +0.004  +0.192   +0.804    -0.009       -0.013       +0.001       -0.010       +0.011  +0.301
                         :   DRjet12eta:  -0.006   -0.005   -0.016    +0.173     +0.172     -0.009  -0.016   -0.004    +0.236  -0.006    +0.009     -0.011     -0.006   -0.014    +0.724  -0.012    +0.026     +0.018     -0.019   -0.005    +0.771  +0.000    +0.018     +0.003     -0.003   -0.015    +0.599  -0.018    +0.008     -0.001     +0.004    -0.010     +1.000      -0.065      -0.003   -0.014    -0.002    -0.017     +0.771      +0.210      +0.002   -0.010    -0.028     +0.745      +0.131      +0.003   +0.001   -0.016    +0.217     -0.063     +0.008  -0.007   -0.025    +0.918       +0.662       +0.311       +0.004       -0.006  -0.012
                         :  DRjet12deta:  -0.006   -0.014   -0.003    +0.024     +0.027     +0.001  +0.001   -0.001    -0.001  +0.002    -0.015     -0.015     +0.011   -0.012    +0.471  -0.009    +0.013     +0.015     -0.009   +0.007    -0.527  +0.004    +0.003     +0.001     -0.004   -0.011    -0.052  -0.008    +0.001     -0.006     +0.010    +0.001     -0.065      +1.000      -0.005   -0.003    -0.003    +0.001     -0.308      -0.491      +0.001   +0.004    -0.012     +0.209      +0.506      +0.006   -0.020   -0.002    +0.018     +0.023     +0.017  +0.000   -0.004    -0.065       -0.027       -0.737       +0.001       -0.006  -0.008
                         :  DRjet12dphi:  +0.011   +0.001   -0.005    +0.001     +0.004     +0.002  -0.001   +0.003    +0.002  +0.001    +0.001     +0.008     +0.009   -0.015    -0.007  -0.015    +0.009     +0.001     -0.011   -0.005    +0.001  -0.006    -0.003     -0.009     +0.005   +0.004    +0.005  -0.000    +0.007     -0.011     +0.015    +0.002     -0.003      -0.005      +1.000   -0.014    -0.014    +0.011     +0.011      -0.000      -0.276   -0.018    -0.014     +0.001      -0.006      +0.297   -0.001   +0.000    -0.002     -0.004     -0.005  -0.003   +0.007    -0.001       -0.006       +0.007       +0.031       -0.663  -0.017
                         :     DRjet12m:  +0.097   -0.069   +0.104    +0.007     -0.001     +0.002  +0.034   +0.119    -0.001  +0.104    -0.011     -0.024     +0.008   +0.373    -0.005  +0.334    -0.005     -0.077     +0.028   +0.445    -0.008  +0.399    -0.005     -0.092     -0.009   +0.040    -0.013  +0.021    -0.002     -0.029     +0.021    +0.250     -0.014      -0.003      -0.014   +1.000    +0.639    +0.284     -0.015      +0.009      +0.019   +0.402    +0.222     -0.011      +0.005      -0.017   +0.349   +0.160    +0.003     +0.001     -0.005  +0.058   +0.208    -0.020       -0.011       -0.006       +0.014       +0.010  +0.843
                         :    DRjet12DR:  +0.013   -0.126   -0.129    +0.004     -0.003     -0.003  -0.032   -0.077    +0.003  -0.054    -0.015     +0.004     +0.006   -0.044    -0.002  -0.035    +0.009     +0.008     -0.015   -0.009    -0.004  +0.003    +0.018     -0.018     -0.036   +0.018    -0.014  +0.013    +0.002     +0.010     -0.004    -0.389     -0.002      -0.003      -0.014   +0.639    +1.000    -0.047     -0.012      +0.020      +0.016   +0.203    -0.065     -0.009      +0.017      +0.003   +0.173   -0.146    +0.002     -0.008     -0.012  -0.059   -0.291    -0.009       +0.005       -0.011       +0.019       -0.005  +0.489
                         :    DRjet23pt:  +0.178   +0.038   +0.381    -0.002     +0.001     -0.001  +0.119   +0.318    -0.009  +0.256    +0.034     -0.028     -0.031   -0.003    -0.010  -0.013    -0.030     -0.016     +0.027   +0.720    -0.012  +0.616    -0.054     -0.112     +0.067   +0.572    -0.015  +0.488    +0.003     -0.084     +0.081    +0.462     -0.017      +0.001      +0.011   +0.284    -0.047    +1.000     -0.015      +0.006      -0.007   +0.273    +0.291     -0.006      +0.004      -0.014   +0.260   +0.503    -0.007     +0.002     -0.005  +0.175   +0.724    -0.016       -0.003       -0.013       -0.002       +0.003  +0.353
                         :   DRjet23eta:  -0.004   +0.003   -0.013    +0.167     +0.162     -0.008  -0.005   -0.010    +0.264  -0.012    +0.012     -0.002     -0.010   -0.016    +0.433  -0.017    +0.013     +0.007     -0.017   -0.010    +0.825  -0.004    +0.019     +0.007     -0.006   -0.007    +0.804  -0.011    +0.016     +0.002     -0.005    -0.010     +0.771      -0.308      +0.011   -0.015    -0.012    -0.015     +1.000      +0.081      -0.008   -0.003    -0.027     +0.686      -0.286      -0.002   +0.003   -0.016    +0.230     -0.093     +0.002  -0.002   -0.023    +0.886       +0.313       +0.672       -0.002       -0.009  -0.009
                         :  DRjet23deta:  +0.007   -0.008   -0.000    -0.011     -0.012     -0.009  -0.005   +0.015    -0.038  +0.018    -0.000     -0.008     +0.004   -0.009    -0.106  -0.013    -0.004     +0.012     +0.006   -0.002    +0.479  -0.000    -0.003     +0.000     +0.016   +0.021    -0.352  +0.023    +0.010     +0.004     -0.009    -0.012     +0.210      -0.491      -0.000   +0.009    +0.020    +0.006     +0.081      +1.000      -0.002   -0.001    +0.002     -0.246      +0.238      -0.004   +0.012   +0.002    -0.027     +0.015     -0.003  +0.008   -0.002    +0.025       +0.616       +0.142       +0.002       -0.004  +0.008
                         :  DRjet23dphi:  -0.007   -0.006   +0.004    +0.009     +0.010     +0.049  +0.010   +0.004    +0.007  +0.002    +0.005     +0.002     -0.018   -0.003    +0.006  +0.011    -0.020     -0.010     +0.023   +0.013    +0.001  +0.015    -0.014     -0.001     -0.002   +0.007    -0.003  +0.009    +0.006     -0.002     -0.003    -0.010     +0.002      +0.001      -0.276   +0.019    +0.016    -0.007     -0.008      -0.002      +1.000   +0.029    +0.008     +0.007      +0.002      +0.173   -0.017   -0.000    +0.010     +0.003     -0.016  +0.013   -0.010    -0.001       +0.001       +0.001       +0.567       +0.100  +0.016
                         :     DRjet23m:  -0.009   -0.018   +0.088    +0.014     +0.012     -0.009  +0.034   +0.121    +0.010  +0.114    -0.001     -0.016     -0.003   +0.084    -0.002  +0.068    +0.005     -0.022     -0.006   +0.393    -0.008  +0.362    +0.044     -0.053     -0.044   +0.408    +0.008  +0.338    +0.042     +0.083     -0.071    +0.235     -0.010      +0.004      -0.018   +0.402    +0.203    +0.273     -0.003      -0.001      +0.029   +1.000    +0.247     +0.006      -0.005      -0.003   +0.307   +0.143    +0.012     -0.001     -0.001  +0.063   +0.218    -0.003       -0.011       -0.002       +0.021       +0.004  +0.720
                         :    DRjet31pt:  +0.169   +0.056   +0.399    +0.003     +0.007     +0.001  +0.128   +0.308    -0.002  +0.245    +0.018     -0.016     -0.022   +0.709    -0.028  +0.611    -0.046     -0.143     +0.079   -0.002    -0.024  +0.000    -0.063     -0.064     +0.054   +0.576    -0.021  +0.496    +0.007     -0.082     +0.079    +0.440     -0.028      -0.012      -0.014   +0.222    -0.065    +0.291     -0.027      +0.002      +0.008   +0.247    +1.000     -0.027      +0.003      +0.001   +0.260   +0.502    -0.002     -0.001     +0.006  +0.198   +0.721    -0.026       -0.007       -0.008       -0.001       +0.012  +0.309
                         :   DRjet31eta:  -0.007   -0.004   -0.012    +0.192     +0.190     -0.009  -0.004   -0.009    +0.280  -0.013    +0.010     -0.006     -0.004   -0.015    +0.801  -0.011    +0.026     +0.018     -0.023   +0.004    +0.455  +0.010    +0.022     +0.006     -0.010   -0.007    +0.805  -0.011    +0.003     +0.006     -0.004    -0.001     +0.745      +0.209      +0.001   -0.011    -0.009    -0.006     +0.686      -0.246      +0.007   +0.006    -0.027     +1.000      +0.019      +0.002   -0.000   -0.013    +0.255     -0.083     +0.016  -0.007   -0.017    +0.868       +0.284       +0.214       +0.010       -0.009  -0.004
                         :  DRjet31deta:  -0.014   -0.018   -0.002    +0.024     +0.026     -0.008  -0.004   +0.008    -0.027  +0.013    -0.021     -0.020     +0.013   -0.013    +0.460  -0.014    +0.005     +0.009     +0.005   -0.002    -0.142  -0.004    -0.005     -0.003     +0.009   +0.012    -0.404  +0.011    -0.013     -0.005     +0.010    -0.014     +0.131      +0.506      -0.006   +0.005    +0.017    +0.004     -0.286      +0.238      +0.002   -0.005    +0.003     +0.019      +1.000      +0.012   -0.001   +0.002    +0.001     +0.038     +0.013  -0.002   -0.002    -0.050       +0.569       -0.711       +0.009       -0.012  -0.001
                         :  DRjet31dphi:  +0.000   -0.009   -0.010    +0.005     +0.003     +0.023  -0.000   +0.004    -0.001  +0.006    +0.018     +0.011     -0.019   -0.017    +0.008  -0.011    -0.007     -0.006     +0.008   -0.023    +0.002  -0.015    -0.010     -0.005     +0.003   +0.008    -0.007  +0.011    +0.013     -0.006     +0.005    -0.022     +0.003      +0.006      +0.297   -0.017    +0.003    -0.014     -0.002      -0.004      +0.173   -0.003    +0.001     +0.002      +0.012      +1.000   -0.009   -0.009    +0.006     +0.002     -0.011  -0.000   -0.014    +0.003       +0.004       -0.004       +0.580       -0.610  -0.014
                         :     DRjet31m:  -0.014   -0.011   +0.093    +0.000     -0.013     +0.000  +0.028   +0.119    -0.012  +0.105    -0.004     -0.014     +0.006   +0.341    -0.006  +0.283    +0.028     -0.068     -0.022   +0.084    +0.003  +0.082    +0.044     -0.022     -0.037   +0.438    -0.003  +0.368    +0.056     +0.099     -0.086    +0.194     +0.001      -0.020      -0.001   +0.349    +0.173    +0.260     +0.003      +0.012      -0.017   +0.307    +0.260     -0.000      -0.001      -0.009   +1.000   +0.144    -0.009     +0.001     +0.008  +0.064   +0.214    +0.003       +0.005       +0.013       -0.017       -0.005  +0.670
                         :     DRlepTpt:  +0.209   +0.042   +0.786    +0.002     +0.002     -0.001  +0.184   +0.542    -0.014  +0.422    +0.057     -0.034     -0.054   +0.334    -0.014  +0.282    -0.067     -0.092     +0.085   +0.335    -0.013  +0.291    -0.103     -0.105     +0.100   +0.351    -0.012  +0.304    -0.029     -0.154     +0.136    +0.510     -0.016      -0.002      +0.000   +0.160    -0.146    +0.503     -0.016      +0.002      -0.000   +0.143    +0.502     -0.013      +0.002      -0.009   +0.144   +1.000    -0.004     +0.011     -0.002  +0.283   +0.666    -0.015       +0.000       -0.010       -0.005       +0.002  +0.192
                         :    DRlepTeta:  -0.012   -0.001   -0.005    +0.821     +0.754     +0.001  +0.009   -0.005    +0.855  -0.007    +0.007     -0.005     -0.012   -0.005    +0.220  -0.001    +0.015     -0.006     -0.008   -0.002    +0.174  -0.007    +0.004     -0.003     -0.003   +0.004    +0.237  +0.002    +0.001     -0.002     +0.008    -0.003     +0.217      +0.018      -0.002   +0.003    +0.002    -0.007     +0.230      -0.027      +0.010   +0.012    -0.002     +0.255      +0.001      +0.006   -0.009   -0.004    +1.000     -0.150     +0.002  -0.001   -0.007    +0.253       +0.099       +0.101       +0.010       -0.004  +0.003
                         :   DRlepTdeta:  +0.004   -0.000   +0.011    +0.224     +0.226     -0.013  +0.016   +0.001    -0.469  +0.005    -0.011     -0.005     +0.014   +0.008    -0.043  -0.001    +0.003     +0.001     -0.005   +0.011    -0.063  +0.010    +0.001     +0.009     -0.011   -0.009    -0.098  -0.011    -0.019     -0.017     +0.007    +0.019     -0.063      +0.023      -0.004   +0.001    -0.008    +0.002     -0.093      +0.015      +0.003   -0.001    -0.001     -0.083      +0.038      +0.002   +0.001   +0.011    -0.150     +1.000     -0.001  +0.011   +0.009    -0.084       -0.011       -0.064       +0.005       +0.007  +0.000
                         :   DRlepTdphi:  +0.008   +0.003   -0.004    +0.002     -0.002     -0.381  +0.003   +0.010    +0.005  +0.007    -0.011     -0.016     +0.012   +0.007    +0.021  +0.012    -0.002     -0.007     +0.003   -0.007    +0.000  -0.006    +0.000     +0.005     -0.003   +0.006    +0.003  +0.008    +0.002     +0.007     -0.021    +0.004     +0.008      +0.017      -0.005   -0.005    -0.012    -0.005     +0.002      -0.003      -0.016   -0.001    +0.006     +0.016      +0.013      -0.011   +0.008   -0.002    +0.002     -0.001     +1.000  +0.005   +0.000    +0.009       +0.000       -0.006       -0.029       +0.013  +0.001
                         :      DRlepTm:  +0.093   +0.014   +0.299    +0.001     -0.001     +0.003  +0.716   +0.388    -0.006  +0.373    +0.013     -0.050     -0.010   +0.127    -0.007  +0.107    -0.039     -0.039     +0.049   +0.109    -0.005  +0.099    -0.022     -0.038     +0.011   +0.139    -0.003  +0.133    +0.019     -0.016     +0.003    +0.192     -0.007      +0.000      -0.003   +0.058    -0.059    +0.175     -0.002      +0.008      +0.013   +0.063    +0.198     -0.007      -0.002      -0.000   +0.064   +0.283    -0.001     +0.011     +0.005  +1.000   +0.246    -0.004       -0.005       +0.001       -0.002       +0.006  +0.078
                         :     DRhadTpt:  +0.227   +0.090   +0.521    +0.001     +0.005     -0.000  +0.158   +0.409    -0.011  +0.330    +0.030     -0.032     -0.029   +0.495    -0.019  +0.424    -0.062     -0.115     +0.084   +0.499    -0.022  +0.423    -0.096     -0.123     +0.095   +0.471    -0.018  +0.403    -0.009     -0.129     +0.118    +0.804     -0.025      -0.004      +0.007   +0.208    -0.291    +0.724     -0.023      -0.002      -0.010   +0.218    +0.721     -0.017      -0.002      -0.014   +0.214   +0.666    -0.007     +0.009     +0.000  +0.246   +1.000    -0.023       -0.008       -0.010       -0.012       +0.007  +0.273
                         :    DRhadTeta:  -0.006   -0.002   -0.014    +0.194     +0.188     -0.007  -0.008   -0.008    +0.278  -0.010    +0.010     -0.007     -0.008   -0.015    +0.695  -0.012    +0.025     +0.017     -0.022   -0.009    +0.737  -0.002    +0.019     +0.004     -0.006   -0.006    +0.794  -0.011    +0.011     +0.003     -0.001    -0.009     +0.918      -0.065      -0.001   -0.020    -0.009    -0.016     +0.886      +0.025      -0.001   -0.003    -0.026     +0.868      -0.050      +0.003   +0.003   -0.015    +0.253     -0.084     +0.009  -0.004   -0.023    +1.000       +0.465       +0.432       +0.006       -0.008  -0.011
                         : DRhadTHbdeta:  -0.007   -0.004   -0.007    +0.093     +0.094     -0.006  -0.016   +0.012    +0.095  +0.013    -0.002     -0.016     +0.002   -0.014    +0.518  -0.014    +0.016     +0.018     -0.007   -0.007    +0.536  -0.003    +0.004     -0.002     +0.011   +0.009    +0.023  +0.011    +0.010     +0.003     -0.001    -0.013     +0.662      -0.027      -0.006   -0.011    +0.005    -0.003     +0.313      +0.616      +0.001   -0.011    -0.007     +0.284      +0.569      +0.004   +0.005   +0.000    +0.099     -0.011     +0.000  -0.005   -0.008    +0.465       +1.000       -0.082       +0.008       -0.009  -0.010
                         : DRhadTWbdeta:  +0.007   +0.011   -0.005    +0.061     +0.056     -0.001  +0.001   -0.009    +0.134  -0.015    +0.024     +0.009     -0.020   +0.007    -0.149  +0.008    +0.003     -0.008     -0.007   -0.008    +0.637  -0.006    +0.010     +0.005     -0.006   -0.008    +0.530  -0.010    +0.012     +0.004     -0.014    +0.001     +0.311      -0.737      +0.007   -0.006    -0.011    -0.013     +0.672      +0.142      +0.001   -0.002    -0.008     +0.214      -0.711      -0.004   +0.013   -0.010    +0.101     -0.064     -0.006  +0.001   -0.010    +0.432       -0.082       +1.000       -0.003       +0.006  +0.002
                         : DRhadTHbdphi:  +0.000   -0.009   -0.001    +0.008     +0.010     +0.042  -0.000   -0.002    +0.007  +0.006    +0.009     +0.007     -0.016   -0.013    +0.009  -0.009    -0.002     +0.000     +0.006   +0.010    +0.010  +0.015    +0.002     +0.001     -0.010   +0.006    -0.001  +0.009    +0.009     +0.001     -0.003    -0.010     +0.004      +0.001      +0.031   +0.014    +0.019    -0.002     -0.002      +0.002      +0.567   +0.021    -0.001     +0.010      +0.009      +0.580   -0.017   -0.005    +0.010     +0.005     -0.029  -0.002   -0.012    +0.006       +0.008       -0.003       +1.000       -0.375  +0.010
                         : DRhadTWbdphi:  -0.005   +0.002   +0.004    -0.002     -0.007     -0.020  +0.006   -0.001    -0.008  -0.004    -0.006     -0.015     +0.003   +0.015    -0.009  +0.016    -0.003     -0.000     +0.003   +0.014    -0.008  +0.020    +0.010     +0.003     -0.010   -0.006    -0.001  -0.007    -0.009     -0.003     +0.010    +0.011     -0.006      -0.006      -0.663   +0.010    -0.005    +0.003     -0.009      -0.004      +0.100   +0.004    +0.012     -0.009      -0.012      -0.610   -0.005   +0.002    -0.004     +0.007     +0.013  +0.006   +0.007    -0.008       -0.009       +0.006       -0.375       +1.000  +0.007
                         :      DRhadTm:  +0.051   -0.046   +0.125    +0.010     -0.001     -0.002  +0.042   +0.150    -0.002  +0.135    -0.007     -0.024     +0.006   +0.360    -0.007  +0.311    +0.007     -0.078     +0.009   +0.428    -0.007  +0.389    +0.030     -0.083     -0.035   +0.329    -0.005  +0.266    +0.035     +0.052     -0.049    +0.301     -0.012      -0.008      -0.017   +0.843    +0.489    +0.353     -0.009      +0.008      +0.016   +0.720    +0.309     -0.004      -0.001      -0.014   +0.670   +0.192    +0.003     +0.000     +0.001  +0.078   +0.273    -0.011       -0.010       +0.002       +0.010       +0.007  +1.000
                         : ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [keras_Hut28] :  
                         : 
2017-12-31 21:32:28.991408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:84:00.0, compute capability: 6.1)
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 59)           0                                            
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1000)         60000       input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 1000)         4000        dense_1[0][0]                    
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 1000)         1001000     batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 1000)         0           dense_2[0][0]                    
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 1000)         4000        dropout_1[0][0]                  
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 1000)         1001000     batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 1000)         0           dense_3[0][0]                    
__________________________________________________________________________________________________
branch_point1 (Dense)           (None, 1000)         1001000     batch_normalization_1[0][0]      
__________________________________________________________________________________________________
add_1 (Add)                     (None, 1000)         0           dropout_2[0][0]                  
                                                                 branch_point1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 1000)         4000        add_1[0][0]                      
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 1000)         1001000     batch_normalization_3[0][0]      
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 1000)         0           dense_4[0][0]                    
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 1000)         4000        dropout_3[0][0]                  
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 1000)         1001000     batch_normalization_4[0][0]      
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 1000)         0           dense_5[0][0]                    
__________________________________________________________________________________________________
branch_point2 (Dense)           (None, 1000)         1001000     batch_normalization_3[0][0]      
__________________________________________________________________________________________________
add_2 (Add)                     (None, 1000)         0           dropout_4[0][0]                  
                                                                 branch_point2[0][0]              
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 1000)         4000        add_2[0][0]                      
__________________________________________________________________________________________________
dense_6 (Dense)                 (None, 1000)         1001000     batch_normalization_5[0][0]      
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 1000)         0           dense_6[0][0]                    
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 1000)         4000        dropout_5[0][0]                  
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 1000)         1001000     batch_normalization_6[0][0]      
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 1000)         0           dense_7[0][0]                    
__________________________________________________________________________________________________
branch_point3 (Dense)           (None, 1000)         1001000     batch_normalization_5[0][0]      
__________________________________________________________________________________________________
add_3 (Add)                     (None, 1000)         0           dropout_6[0][0]                  
                                                                 branch_point3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 1000)         4000        add_3[0][0]                      
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1000)         1001000     batch_normalization_7[0][0]      
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 1000)         0           dense_8[0][0]                    
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 1000)         4000        dropout_7[0][0]                  
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 1000)         1001000     batch_normalization_8[0][0]      
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 1000)         0           dense_9[0][0]                    
__________________________________________________________________________________________________
branch_point4 (Dense)           (None, 1000)         1001000     batch_normalization_7[0][0]      
__________________________________________________________________________________________________
add_4 (Add)                     (None, 1000)         0           dropout_8[0][0]                  
                                                                 branch_point4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 1000)         4000        add_4[0][0]                      
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 1000)         1001000     batch_normalization_9[0][0]      
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 1000)         0           dense_10[0][0]                   
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 1000)         4000        dropout_9[0][0]                  
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 1000)         1001000     batch_normalization_10[0][0]     
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 1000)         0           dense_11[0][0]                   
__________________________________________________________________________________________________
branch_point5 (Dense)           (None, 1000)         1001000     batch_normalization_9[0][0]      
__________________________________________________________________________________________________
add_5 (Add)                     (None, 1000)         0           dropout_10[0][0]                 
                                                                 branch_point5[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 1000)         4000        add_5[0][0]                      
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 1000)         1001000     batch_normalization_11[0][0]     
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 1000)         0           dense_12[0][0]                   
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 1000)         4000        dropout_11[0][0]                 
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 1000)         1001000     batch_normalization_12[0][0]     
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 1000)         0           dense_13[0][0]                   
__________________________________________________________________________________________________
branch_point6 (Dense)           (None, 1000)         1001000     batch_normalization_11[0][0]     
__________________________________________________________________________________________________
add_6 (Add)                     (None, 1000)         0           dropout_12[0][0]                 
                                                                 branch_point6[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 1000)         4000        add_6[0][0]                      
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 1000)         1001000     batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 1000)         0           dense_14[0][0]                   
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 2)            2002        dropout_13[0][0]                 
==================================================================================================
Total params: 19,133,002
Trainable params: 19,107,002
Non-trainable params: 26,000
__________________________________________________________________________________________________
Factory                  : Booking method: [1mKeras_TF[0m
                         : 
Keras_TF                 : [keras_Hut28] : Create Transformation "G" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'njets' <---> Output : variable 'njets'
                         : Input : variable 'nbjets_m' <---> Output : variable 'nbjets_m'
                         : Input : variable 'DRlepWpt' <---> Output : variable 'DRlepWpt'
                         : Input : variable 'DRlepWeta' <---> Output : variable 'DRlepWeta'
                         : Input : variable 'DRlepWdeta' <---> Output : variable 'DRlepWdeta'
                         : Input : variable 'DRlepWdphi' <---> Output : variable 'DRlepWdphi'
                         : Input : variable 'DRlepWm' <---> Output : variable 'DRlepWm'
                         : Input : variable 'DRjet0pt' <---> Output : variable 'DRjet0pt'
                         : Input : variable 'DRjet0eta' <---> Output : variable 'DRjet0eta'
                         : Input : variable 'DRjet0m' <---> Output : variable 'DRjet0m'
                         : Input : variable 'DRjet0csv' <---> Output : variable 'DRjet0csv'
                         : Input : variable 'DRjet0cvsl' <---> Output : variable 'DRjet0cvsl'
                         : Input : variable 'DRjet0cvsb' <---> Output : variable 'DRjet0cvsb'
                         : Input : variable 'DRjet1pt' <---> Output : variable 'DRjet1pt'
                         : Input : variable 'DRjet1eta' <---> Output : variable 'DRjet1eta'
                         : Input : variable 'DRjet1m' <---> Output : variable 'DRjet1m'
                         : Input : variable 'DRjet1csv' <---> Output : variable 'DRjet1csv'
                         : Input : variable 'DRjet1cvsl' <---> Output : variable 'DRjet1cvsl'
                         : Input : variable 'DRjet1cvsb' <---> Output : variable 'DRjet1cvsb'
                         : Input : variable 'DRjet2pt' <---> Output : variable 'DRjet2pt'
                         : Input : variable 'DRjet2eta' <---> Output : variable 'DRjet2eta'
                         : Input : variable 'DRjet2m' <---> Output : variable 'DRjet2m'
                         : Input : variable 'DRjet2csv' <---> Output : variable 'DRjet2csv'
                         : Input : variable 'DRjet2cvsl' <---> Output : variable 'DRjet2cvsl'
                         : Input : variable 'DRjet2cvsb' <---> Output : variable 'DRjet2cvsb'
                         : Input : variable 'DRjet3pt' <---> Output : variable 'DRjet3pt'
                         : Input : variable 'DRjet3eta' <---> Output : variable 'DRjet3eta'
                         : Input : variable 'DRjet3m' <---> Output : variable 'DRjet3m'
                         : Input : variable 'DRjet3csv' <---> Output : variable 'DRjet3csv'
                         : Input : variable 'DRjet3cvsl' <---> Output : variable 'DRjet3cvsl'
                         : Input : variable 'DRjet3cvsb' <---> Output : variable 'DRjet3cvsb'
                         : Input : variable 'DRjet12pt' <---> Output : variable 'DRjet12pt'
                         : Input : variable 'DRjet12eta' <---> Output : variable 'DRjet12eta'
                         : Input : variable 'DRjet12deta' <---> Output : variable 'DRjet12deta'
                         : Input : variable 'DRjet12dphi' <---> Output : variable 'DRjet12dphi'
                         : Input : variable 'DRjet12m' <---> Output : variable 'DRjet12m'
                         : Input : variable 'DRjet12DR' <---> Output : variable 'DRjet12DR'
                         : Input : variable 'DRjet23pt' <---> Output : variable 'DRjet23pt'
                         : Input : variable 'DRjet23eta' <---> Output : variable 'DRjet23eta'
                         : Input : variable 'DRjet23deta' <---> Output : variable 'DRjet23deta'
                         : Input : variable 'DRjet23dphi' <---> Output : variable 'DRjet23dphi'
                         : Input : variable 'DRjet23m' <---> Output : variable 'DRjet23m'
                         : Input : variable 'DRjet31pt' <---> Output : variable 'DRjet31pt'
                         : Input : variable 'DRjet31eta' <---> Output : variable 'DRjet31eta'
                         : Input : variable 'DRjet31deta' <---> Output : variable 'DRjet31deta'
                         : Input : variable 'DRjet31dphi' <---> Output : variable 'DRjet31dphi'
                         : Input : variable 'DRjet31m' <---> Output : variable 'DRjet31m'
                         : Input : variable 'DRlepTpt' <---> Output : variable 'DRlepTpt'
                         : Input : variable 'DRlepTeta' <---> Output : variable 'DRlepTeta'
                         : Input : variable 'DRlepTdeta' <---> Output : variable 'DRlepTdeta'
                         : Input : variable 'DRlepTdphi' <---> Output : variable 'DRlepTdphi'
                         : Input : variable 'DRlepTm' <---> Output : variable 'DRlepTm'
                         : Input : variable 'DRhadTpt' <---> Output : variable 'DRhadTpt'
                         : Input : variable 'DRhadTeta' <---> Output : variable 'DRhadTeta'
                         : Input : variable 'DRhadTHbdeta' <---> Output : variable 'DRhadTHbdeta'
                         : Input : variable 'DRhadTWbdeta' <---> Output : variable 'DRhadTWbdeta'
                         : Input : variable 'DRhadTHbdphi' <---> Output : variable 'DRhadTHbdphi'
                         : Input : variable 'DRhadTWbdphi' <---> Output : variable 'DRhadTWbdphi'
                         : Input : variable 'DRhadTm' <---> Output : variable 'DRhadTm'
Keras_TF                 : [keras_Hut28] : Create Transformation "D" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'njets' <---> Output : variable 'njets'
                         : Input : variable 'nbjets_m' <---> Output : variable 'nbjets_m'
                         : Input : variable 'DRlepWpt' <---> Output : variable 'DRlepWpt'
                         : Input : variable 'DRlepWeta' <---> Output : variable 'DRlepWeta'
                         : Input : variable 'DRlepWdeta' <---> Output : variable 'DRlepWdeta'
                         : Input : variable 'DRlepWdphi' <---> Output : variable 'DRlepWdphi'
                         : Input : variable 'DRlepWm' <---> Output : variable 'DRlepWm'
                         : Input : variable 'DRjet0pt' <---> Output : variable 'DRjet0pt'
                         : Input : variable 'DRjet0eta' <---> Output : variable 'DRjet0eta'
                         : Input : variable 'DRjet0m' <---> Output : variable 'DRjet0m'
                         : Input : variable 'DRjet0csv' <---> Output : variable 'DRjet0csv'
                         : Input : variable 'DRjet0cvsl' <---> Output : variable 'DRjet0cvsl'
                         : Input : variable 'DRjet0cvsb' <---> Output : variable 'DRjet0cvsb'
                         : Input : variable 'DRjet1pt' <---> Output : variable 'DRjet1pt'
                         : Input : variable 'DRjet1eta' <---> Output : variable 'DRjet1eta'
                         : Input : variable 'DRjet1m' <---> Output : variable 'DRjet1m'
                         : Input : variable 'DRjet1csv' <---> Output : variable 'DRjet1csv'
                         : Input : variable 'DRjet1cvsl' <---> Output : variable 'DRjet1cvsl'
                         : Input : variable 'DRjet1cvsb' <---> Output : variable 'DRjet1cvsb'
                         : Input : variable 'DRjet2pt' <---> Output : variable 'DRjet2pt'
                         : Input : variable 'DRjet2eta' <---> Output : variable 'DRjet2eta'
                         : Input : variable 'DRjet2m' <---> Output : variable 'DRjet2m'
                         : Input : variable 'DRjet2csv' <---> Output : variable 'DRjet2csv'
                         : Input : variable 'DRjet2cvsl' <---> Output : variable 'DRjet2cvsl'
                         : Input : variable 'DRjet2cvsb' <---> Output : variable 'DRjet2cvsb'
                         : Input : variable 'DRjet3pt' <---> Output : variable 'DRjet3pt'
                         : Input : variable 'DRjet3eta' <---> Output : variable 'DRjet3eta'
                         : Input : variable 'DRjet3m' <---> Output : variable 'DRjet3m'
                         : Input : variable 'DRjet3csv' <---> Output : variable 'DRjet3csv'
                         : Input : variable 'DRjet3cvsl' <---> Output : variable 'DRjet3cvsl'
                         : Input : variable 'DRjet3cvsb' <---> Output : variable 'DRjet3cvsb'
                         : Input : variable 'DRjet12pt' <---> Output : variable 'DRjet12pt'
                         : Input : variable 'DRjet12eta' <---> Output : variable 'DRjet12eta'
                         : Input : variable 'DRjet12deta' <---> Output : variable 'DRjet12deta'
                         : Input : variable 'DRjet12dphi' <---> Output : variable 'DRjet12dphi'
                         : Input : variable 'DRjet12m' <---> Output : variable 'DRjet12m'
                         : Input : variable 'DRjet12DR' <---> Output : variable 'DRjet12DR'
                         : Input : variable 'DRjet23pt' <---> Output : variable 'DRjet23pt'
                         : Input : variable 'DRjet23eta' <---> Output : variable 'DRjet23eta'
                         : Input : variable 'DRjet23deta' <---> Output : variable 'DRjet23deta'
                         : Input : variable 'DRjet23dphi' <---> Output : variable 'DRjet23dphi'
                         : Input : variable 'DRjet23m' <---> Output : variable 'DRjet23m'
                         : Input : variable 'DRjet31pt' <---> Output : variable 'DRjet31pt'
                         : Input : variable 'DRjet31eta' <---> Output : variable 'DRjet31eta'
                         : Input : variable 'DRjet31deta' <---> Output : variable 'DRjet31deta'
                         : Input : variable 'DRjet31dphi' <---> Output : variable 'DRjet31dphi'
                         : Input : variable 'DRjet31m' <---> Output : variable 'DRjet31m'
                         : Input : variable 'DRlepTpt' <---> Output : variable 'DRlepTpt'
                         : Input : variable 'DRlepTeta' <---> Output : variable 'DRlepTeta'
                         : Input : variable 'DRlepTdeta' <---> Output : variable 'DRlepTdeta'
                         : Input : variable 'DRlepTdphi' <---> Output : variable 'DRlepTdphi'
                         : Input : variable 'DRlepTm' <---> Output : variable 'DRlepTm'
                         : Input : variable 'DRhadTpt' <---> Output : variable 'DRhadTpt'
                         : Input : variable 'DRhadTeta' <---> Output : variable 'DRhadTeta'
                         : Input : variable 'DRhadTHbdeta' <---> Output : variable 'DRhadTHbdeta'
                         : Input : variable 'DRhadTWbdeta' <---> Output : variable 'DRhadTWbdeta'
                         : Input : variable 'DRhadTHbdphi' <---> Output : variable 'DRhadTHbdphi'
                         : Input : variable 'DRhadTWbdphi' <---> Output : variable 'DRhadTWbdphi'
                         : Input : variable 'DRhadTm' <---> Output : variable 'DRhadTm'
Keras_TF                 : [keras_Hut28] : Create Transformation "P" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'njets' <---> Output : variable 'njets'
                         : Input : variable 'nbjets_m' <---> Output : variable 'nbjets_m'
                         : Input : variable 'DRlepWpt' <---> Output : variable 'DRlepWpt'
                         : Input : variable 'DRlepWeta' <---> Output : variable 'DRlepWeta'
                         : Input : variable 'DRlepWdeta' <---> Output : variable 'DRlepWdeta'
                         : Input : variable 'DRlepWdphi' <---> Output : variable 'DRlepWdphi'
                         : Input : variable 'DRlepWm' <---> Output : variable 'DRlepWm'
                         : Input : variable 'DRjet0pt' <---> Output : variable 'DRjet0pt'
                         : Input : variable 'DRjet0eta' <---> Output : variable 'DRjet0eta'
                         : Input : variable 'DRjet0m' <---> Output : variable 'DRjet0m'
                         : Input : variable 'DRjet0csv' <---> Output : variable 'DRjet0csv'
                         : Input : variable 'DRjet0cvsl' <---> Output : variable 'DRjet0cvsl'
                         : Input : variable 'DRjet0cvsb' <---> Output : variable 'DRjet0cvsb'
                         : Input : variable 'DRjet1pt' <---> Output : variable 'DRjet1pt'
                         : Input : variable 'DRjet1eta' <---> Output : variable 'DRjet1eta'
                         : Input : variable 'DRjet1m' <---> Output : variable 'DRjet1m'
                         : Input : variable 'DRjet1csv' <---> Output : variable 'DRjet1csv'
                         : Input : variable 'DRjet1cvsl' <---> Output : variable 'DRjet1cvsl'
                         : Input : variable 'DRjet1cvsb' <---> Output : variable 'DRjet1cvsb'
                         : Input : variable 'DRjet2pt' <---> Output : variable 'DRjet2pt'
                         : Input : variable 'DRjet2eta' <---> Output : variable 'DRjet2eta'
                         : Input : variable 'DRjet2m' <---> Output : variable 'DRjet2m'
                         : Input : variable 'DRjet2csv' <---> Output : variable 'DRjet2csv'
                         : Input : variable 'DRjet2cvsl' <---> Output : variable 'DRjet2cvsl'
                         : Input : variable 'DRjet2cvsb' <---> Output : variable 'DRjet2cvsb'
                         : Input : variable 'DRjet3pt' <---> Output : variable 'DRjet3pt'
                         : Input : variable 'DRjet3eta' <---> Output : variable 'DRjet3eta'
                         : Input : variable 'DRjet3m' <---> Output : variable 'DRjet3m'
                         : Input : variable 'DRjet3csv' <---> Output : variable 'DRjet3csv'
                         : Input : variable 'DRjet3cvsl' <---> Output : variable 'DRjet3cvsl'
                         : Input : variable 'DRjet3cvsb' <---> Output : variable 'DRjet3cvsb'
                         : Input : variable 'DRjet12pt' <---> Output : variable 'DRjet12pt'
                         : Input : variable 'DRjet12eta' <---> Output : variable 'DRjet12eta'
                         : Input : variable 'DRjet12deta' <---> Output : variable 'DRjet12deta'
                         : Input : variable 'DRjet12dphi' <---> Output : variable 'DRjet12dphi'
                         : Input : variable 'DRjet12m' <---> Output : variable 'DRjet12m'
                         : Input : variable 'DRjet12DR' <---> Output : variable 'DRjet12DR'
                         : Input : variable 'DRjet23pt' <---> Output : variable 'DRjet23pt'
                         : Input : variable 'DRjet23eta' <---> Output : variable 'DRjet23eta'
                         : Input : variable 'DRjet23deta' <---> Output : variable 'DRjet23deta'
                         : Input : variable 'DRjet23dphi' <---> Output : variable 'DRjet23dphi'
                         : Input : variable 'DRjet23m' <---> Output : variable 'DRjet23m'
                         : Input : variable 'DRjet31pt' <---> Output : variable 'DRjet31pt'
                         : Input : variable 'DRjet31eta' <---> Output : variable 'DRjet31eta'
                         : Input : variable 'DRjet31deta' <---> Output : variable 'DRjet31deta'
                         : Input : variable 'DRjet31dphi' <---> Output : variable 'DRjet31dphi'
                         : Input : variable 'DRjet31m' <---> Output : variable 'DRjet31m'
                         : Input : variable 'DRlepTpt' <---> Output : variable 'DRlepTpt'
                         : Input : variable 'DRlepTeta' <---> Output : variable 'DRlepTeta'
                         : Input : variable 'DRlepTdeta' <---> Output : variable 'DRlepTdeta'
                         : Input : variable 'DRlepTdphi' <---> Output : variable 'DRlepTdphi'
                         : Input : variable 'DRlepTm' <---> Output : variable 'DRlepTm'
                         : Input : variable 'DRhadTpt' <---> Output : variable 'DRhadTpt'
                         : Input : variable 'DRhadTeta' <---> Output : variable 'DRhadTeta'
                         : Input : variable 'DRhadTHbdeta' <---> Output : variable 'DRhadTHbdeta'
                         : Input : variable 'DRhadTWbdeta' <---> Output : variable 'DRhadTWbdeta'
                         : Input : variable 'DRhadTHbdphi' <---> Output : variable 'DRhadTHbdphi'
                         : Input : variable 'DRhadTWbdphi' <---> Output : variable 'DRhadTWbdphi'
                         : Input : variable 'DRhadTm' <---> Output : variable 'DRhadTm'
                         : Load model from file: model_Hut.h5
Factory                  : [1mTrain all methods[0m
Factory                  : [keras_Hut28] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'njets' <---> Output : variable 'njets'
                         : Input : variable 'nbjets_m' <---> Output : variable 'nbjets_m'
                         : Input : variable 'DRlepWpt' <---> Output : variable 'DRlepWpt'
                         : Input : variable 'DRlepWeta' <---> Output : variable 'DRlepWeta'
                         : Input : variable 'DRlepWdeta' <---> Output : variable 'DRlepWdeta'
                         : Input : variable 'DRlepWdphi' <---> Output : variable 'DRlepWdphi'
                         : Input : variable 'DRlepWm' <---> Output : variable 'DRlepWm'
                         : Input : variable 'DRjet0pt' <---> Output : variable 'DRjet0pt'
                         : Input : variable 'DRjet0eta' <---> Output : variable 'DRjet0eta'
                         : Input : variable 'DRjet0m' <---> Output : variable 'DRjet0m'
                         : Input : variable 'DRjet0csv' <---> Output : variable 'DRjet0csv'
                         : Input : variable 'DRjet0cvsl' <---> Output : variable 'DRjet0cvsl'
                         : Input : variable 'DRjet0cvsb' <---> Output : variable 'DRjet0cvsb'
                         : Input : variable 'DRjet1pt' <---> Output : variable 'DRjet1pt'
                         : Input : variable 'DRjet1eta' <---> Output : variable 'DRjet1eta'
                         : Input : variable 'DRjet1m' <---> Output : variable 'DRjet1m'
                         : Input : variable 'DRjet1csv' <---> Output : variable 'DRjet1csv'
                         : Input : variable 'DRjet1cvsl' <---> Output : variable 'DRjet1cvsl'
                         : Input : variable 'DRjet1cvsb' <---> Output : variable 'DRjet1cvsb'
                         : Input : variable 'DRjet2pt' <---> Output : variable 'DRjet2pt'
                         : Input : variable 'DRjet2eta' <---> Output : variable 'DRjet2eta'
                         : Input : variable 'DRjet2m' <---> Output : variable 'DRjet2m'
                         : Input : variable 'DRjet2csv' <---> Output : variable 'DRjet2csv'
                         : Input : variable 'DRjet2cvsl' <---> Output : variable 'DRjet2cvsl'
                         : Input : variable 'DRjet2cvsb' <---> Output : variable 'DRjet2cvsb'
                         : Input : variable 'DRjet3pt' <---> Output : variable 'DRjet3pt'
                         : Input : variable 'DRjet3eta' <---> Output : variable 'DRjet3eta'
                         : Input : variable 'DRjet3m' <---> Output : variable 'DRjet3m'
                         : Input : variable 'DRjet3csv' <---> Output : variable 'DRjet3csv'
                         : Input : variable 'DRjet3cvsl' <---> Output : variable 'DRjet3cvsl'
                         : Input : variable 'DRjet3cvsb' <---> Output : variable 'DRjet3cvsb'
                         : Input : variable 'DRjet12pt' <---> Output : variable 'DRjet12pt'
                         : Input : variable 'DRjet12eta' <---> Output : variable 'DRjet12eta'
                         : Input : variable 'DRjet12deta' <---> Output : variable 'DRjet12deta'
                         : Input : variable 'DRjet12dphi' <---> Output : variable 'DRjet12dphi'
                         : Input : variable 'DRjet12m' <---> Output : variable 'DRjet12m'
                         : Input : variable 'DRjet12DR' <---> Output : variable 'DRjet12DR'
                         : Input : variable 'DRjet23pt' <---> Output : variable 'DRjet23pt'
                         : Input : variable 'DRjet23eta' <---> Output : variable 'DRjet23eta'
                         : Input : variable 'DRjet23deta' <---> Output : variable 'DRjet23deta'
                         : Input : variable 'DRjet23dphi' <---> Output : variable 'DRjet23dphi'
                         : Input : variable 'DRjet23m' <---> Output : variable 'DRjet23m'
                         : Input : variable 'DRjet31pt' <---> Output : variable 'DRjet31pt'
                         : Input : variable 'DRjet31eta' <---> Output : variable 'DRjet31eta'
                         : Input : variable 'DRjet31deta' <---> Output : variable 'DRjet31deta'
                         : Input : variable 'DRjet31dphi' <---> Output : variable 'DRjet31dphi'
                         : Input : variable 'DRjet31m' <---> Output : variable 'DRjet31m'
                         : Input : variable 'DRlepTpt' <---> Output : variable 'DRlepTpt'
                         : Input : variable 'DRlepTeta' <---> Output : variable 'DRlepTeta'
                         : Input : variable 'DRlepTdeta' <---> Output : variable 'DRlepTdeta'
                         : Input : variable 'DRlepTdphi' <---> Output : variable 'DRlepTdphi'
                         : Input : variable 'DRlepTm' <---> Output : variable 'DRlepTm'
                         : Input : variable 'DRhadTpt' <---> Output : variable 'DRhadTpt'
                         : Input : variable 'DRhadTeta' <---> Output : variable 'DRhadTeta'
                         : Input : variable 'DRhadTHbdeta' <---> Output : variable 'DRhadTHbdeta'
                         : Input : variable 'DRhadTWbdeta' <---> Output : variable 'DRhadTWbdeta'
                         : Input : variable 'DRhadTHbdphi' <---> Output : variable 'DRhadTHbdphi'
                         : Input : variable 'DRhadTWbdphi' <---> Output : variable 'DRhadTWbdphi'
                         : Input : variable 'DRhadTm' <---> Output : variable 'DRhadTm'
TFHandler_Factory        :     Variable            Mean            RMS    [        Min            Max ]
                         : -------------------------------------------------------------------------------
                         :        njets:        4.9954        1.1435   [        4.0000        12.000 ]
                         :     nbjets_m:        3.0426       0.20997   [        3.0000        6.0000 ]
                         :     DRlepWpt:        121.33        78.580   [       0.26225        858.72 ]
                         :    DRlepWeta:     0.0096121       0.87181   [       -4.5179        5.9629 ]
                         :   DRlepWdeta:     0.0095308        1.0020   [       -5.6059        7.1252 ]
                         :   DRlepWdphi:      0.013463        1.5735   [       -3.1415        3.1415 ]
                         :      DRlepWm:        95.854        50.261   [       0.97815        678.06 ]
                         :     DRjet0pt:        90.735        54.442   [        30.004        600.61 ]
                         :    DRjet0eta:     0.0091809       0.99364   [       -2.3996        2.3996 ]
                         :      DRjet0m:        12.242        5.8982   [        2.5196        104.81 ]
                         :    DRjet0csv:       0.95465      0.045009   [       0.84843       0.99959 ]
                         :   DRjet0cvsl:       0.84478       0.20085   [      -0.56366       0.99701 ]
                         :   DRjet0cvsb:      -0.58803       0.32468   [      -0.98560       0.78436 ]
                         :     DRjet1pt:        85.339        57.133   [        30.001        1254.0 ]
                         :    DRjet1eta:    0.00090796        1.0247   [       -2.3966        2.3989 ]
                         :      DRjet1m:        12.245        7.5339   [        2.2847        172.61 ]
                         :    DRjet1csv:       0.97832      0.028340   [       0.85098       0.99963 ]
                         :   DRjet1cvsl:       0.87786       0.16414   [      -0.55156       0.99761 ]
                         :   DRjet1cvsb:      -0.72017       0.25345   [      -0.98770       0.66139 ]
                         :     DRjet2pt:        86.841        63.098   [        30.000        929.86 ]
                         :    DRjet2eta:     -0.018459        1.0839   [       -2.3994        2.3996 ]
                         :      DRjet2m:        12.614        8.7482   [        2.0058        155.06 ]
                         :    DRjet2csv:       0.93023      0.045457   [       0.84840       0.99941 ]
                         :   DRjet2cvsl:       0.80799       0.23007   [      -0.63700       0.99711 ]
                         :   DRjet2cvsb:      -0.42504       0.34177   [      -0.98314       0.74980 ]
                         :     DRjet3pt:        73.350        48.333   [        30.001        796.07 ]
                         :    DRjet3eta:     0.0035384        1.0879   [       -2.3993        2.3994 ]
                         :      DRjet3m:        10.966        6.4264   [        1.7577        125.48 ]
                         :    DRjet3csv:       0.25475        1.1524   [       -10.000       0.99813 ]
                         :   DRjet3cvsl:      0.022031       0.44169   [      -0.81541       0.99619 ]
                         :   DRjet3cvsb:       0.26634       0.35940   [      -0.97505       0.86836 ]
                         :    DRjet12pt:        135.44        88.287   [       0.86975        1328.6 ]
                         :   DRjet12eta:     -0.012053        1.2709   [       -5.9789        5.1144 ]
                         :  DRjet12deta:      0.017041        1.1421   [       -5.6505        5.4884 ]
                         :  DRjet12dphi:    -0.0078175        1.5985   [       -3.1413        3.1415 ]
                         :     DRjet12m:        129.04        77.842   [        20.412        1597.4 ]
                         :    DRjet12DR:        1.7868       0.76337   [       0.40298        5.2314 ]
                         :    DRjet23pt:        132.74        80.238   [        1.0938        948.79 ]
                         :   DRjet23eta:    -0.0085524        1.2617   [       -5.2429        4.7488 ]
                         :  DRjet23deta:     -0.026033        1.1848   [       -5.5733        5.1187 ]
                         :  DRjet23dphi:      0.012484        1.4058   [       -3.1408        3.1412 ]
                         :     DRjet23m:        107.86        73.323   [        18.708        1421.5 ]
                         :    DRjet31pt:        130.62        76.814   [       0.35309        1258.6 ]
                         :   DRjet31eta:     0.0051226        1.2328   [       -5.8428        5.7518 ]
                         :  DRjet31deta:    0.00084041        1.1747   [       -6.4807        5.6959 ]
                         :  DRjet31dphi:     0.0080811        1.4187   [       -3.1414        3.1412 ]
                         :     DRjet31m:        108.23        69.768   [        18.091        2093.8 ]
                         :     DRlepTpt:        182.57        100.74   [        2.4091        1027.7 ]
                         :    DRlepTeta:      0.012001        1.0049   [       -4.7807        4.6940 ]
                         :   DRlepTdeta:    0.00099032       0.94012   [       -5.1871        5.3182 ]
                         :   DRlepTdphi:     0.0048885        1.3431   [       -3.1408        3.1411 ]
                         :      DRlepTm:        185.49        67.728   [        32.679        1098.7 ]
                         :     DRhadTpt:        183.44        98.596   [        4.4772        1336.0 ]
                         :    DRhadTeta:    -0.0044914        1.2590   [       -4.5325        5.2521 ]
                         : DRhadTHbdeta:     -0.012619        1.2372   [       -5.2589        5.5315 ]
                         : DRhadTWbdeta:    -0.0096741        1.2005   [       -5.0983        6.4140 ]
                         : DRhadTHbdphi:     0.0085763        1.2102   [       -3.1415        3.1413 ]
                         : DRhadTWbdphi:    0.00092897        1.3980   [       -3.1411        3.1403 ]
                         :      DRhadTm:        209.03        109.55   [        32.142        2226.2 ]
                         : -------------------------------------------------------------------------------
                         : [32m
                         : <PlotVariables> Will not produce scatter plots ==> 
                         : |  The number of 59 input variables and 0 target values would require 1711 two-dimensional
                         : |  histograms, which would occupy the computer's memory. Note that this
                         : |  suppression does not have any consequences for your analysis, other
                         : |  than not disposing of these scatter plots. You can modify the maximum
                         : |  number of input variables allowed to generate scatter plots in your
                         : |  script via the command line:
                         : |  "(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;"[0m
                         : 
                         : Some more output
                         : Ranking input variables (method unspecific)...
IdTransformation         : Ranking result (top variable is best ranked)
                         : -------------------------------------
                         : Rank : Variable     : Separation
                         : -------------------------------------
                         :    1 : DRjet12m     : 1.939e-01
                         :    2 : DRhadTm      : 6.728e-02
                         :    3 : DRjet2cvsb   : 6.426e-02
                         :    4 : DRjet12DR    : 6.101e-02
                         :    5 : DRjet2csv    : 5.256e-02
                         :    6 : DRjet1csv    : 3.123e-02
                         :    7 : DRjet31m     : 3.103e-02
                         :    8 : DRjet1cvsb   : 2.431e-02
                         :    9 : DRjet3csv    : 2.373e-02
                         :   10 : DRjet2cvsl   : 2.092e-02
                         :   11 : DRjet3cvsb   : 2.064e-02
                         :   12 : DRjet23m     : 2.049e-02
                         :   13 : DRjet3cvsl   : 1.984e-02
                         :   14 : DRhadTHbdphi : 1.719e-02
                         :   15 : DRjet12deta  : 1.697e-02
                         :   16 : DRlepTpt     : 1.690e-02
                         :   17 : DRjet12dphi  : 1.676e-02
                         :   18 : DRjet0pt     : 1.557e-02
                         :   19 : DRjet12pt    : 1.367e-02
                         :   20 : DRhadTpt     : 1.337e-02
                         :   21 : DRjet31dphi  : 1.295e-02
                         :   22 : DRhadTWbdphi : 1.291e-02
                         :   23 : DRhadTWbdeta : 1.141e-02
                         :   24 : DRjet23dphi  : 9.825e-03
                         :   25 : DRjet0m      : 8.828e-03
                         :   26 : DRjet0cvsb   : 8.814e-03
                         :   27 : DRjet23pt    : 8.657e-03
                         :   28 : DRjet31pt    : 7.695e-03
                         :   29 : DRlepTm      : 7.615e-03
                         :   30 : DRjet1cvsl   : 7.420e-03
                         :   31 : DRjet0csv    : 6.296e-03
                         :   32 : DRjet2eta    : 6.120e-03
                         :   33 : DRjet2pt     : 5.419e-03
                         :   34 : DRjet23deta  : 5.360e-03
                         :   35 : DRlepWpt     : 5.110e-03
                         :   36 : DRjet2m      : 4.335e-03
                         :   37 : DRjet31deta  : 4.098e-03
                         :   38 : DRjet3pt     : 4.063e-03
                         :   39 : DRlepTdphi   : 3.832e-03
                         :   40 : DRjet23eta   : 3.790e-03
                         :   41 : DRjet1eta    : 3.649e-03
                         :   42 : njets        : 3.302e-03
                         :   43 : DRjet1pt     : 2.956e-03
                         :   44 : DRjet0cvsl   : 2.854e-03
                         :   45 : DRhadTHbdeta : 2.778e-03
                         :   46 : DRhadTeta    : 2.751e-03
                         :   47 : nbjets_m     : 2.651e-03
                         :   48 : DRlepWdphi   : 2.509e-03
                         :   49 : DRlepWm      : 2.471e-03
                         :   50 : DRjet31eta   : 2.305e-03
                         :   51 : DRlepWdeta   : 2.113e-03
                         :   52 : DRjet12eta   : 1.950e-03
                         :   53 : DRjet3m      : 1.872e-03
                         :   54 : DRjet0eta    : 1.766e-03
                         :   55 : DRjet3eta    : 1.605e-03
                         :   56 : DRlepTdeta   : 1.540e-03
                         :   57 : DRlepWeta    : 1.391e-03
                         :   58 : DRlepTeta    : 1.295e-03
                         :   59 : DRjet1m      : 9.532e-04
                         : -------------------------------------
Factory                  : Train method: BDT for Classification
                         : 
BDT                      : #events: (reweighted) sig: 14500 bkg: 14500
                         : #events: (unweighted) sig: 14000 bkg: 15000
                         : Training 200 Decision Trees ... patience please
0%, time left: unknown
7%, time left: 11 sec
13%, time left: 10 sec
19%, time left: 9 sec
25%, time left: 8 sec
32%, time left: 7 sec
38%, time left: 7 sec
44%, time left: 6 sec
50%, time left: 5 sec
57%, time left: 5 sec
63%, time left: 4 sec
69%, time left: 3 sec
75%, time left: 2 sec
82%, time left: 2 sec
88%, time left: 1 sec
94%, time left: 0 sec
                         : Elapsed time for training with 29000 events: 12.5 sec         
BDT                      : [keras_Hut28] : Evaluation of BDT on training sample (29000 events)
0%, time left: unknown
7%, time left: 0 sec
13%, time left: 0 sec
19%, time left: 0 sec
25%, time left: 0 sec
32%, time left: 0 sec
38%, time left: 0 sec
44%, time left: 0 sec
50%, time left: 0 sec
57%, time left: 0 sec
63%, time left: 0 sec
69%, time left: 0 sec
75%, time left: 0 sec
82%, time left: 0 sec
88%, time left: 0 sec
94%, time left: 0 sec
                         : Elapsed time for evaluation of 29000 events: 0.364 sec       
                         : Creating xml weight file: [0;36mkeras_Hut28/weights/TMVAClassification_BDT.weights.xml[0m
                         : Creating standalone class: [0;36mkeras_Hut28/weights/TMVAClassification_BDT.class.C[0m
Factory                  : Training finished
                         : 
Factory                  : Train method: Keras_TF for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ Keras_TF ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
                         : Preparing the Gaussian transformation...
                         : Preparing the Decorrelation transformation...
                         : Preparing the Principle Component (PCA) transformation...
TFHandler_Keras_TF       :     Variable            Mean            RMS    [        Min            Max ]
                         : -------------------------------------------------------------------------------
                         :        njets:      0.018969        1.0000   [       -5.4166        5.4815 ]
                         :     nbjets_m:      0.012398        1.0000   [       -9.7244        11.023 ]
                         :     DRlepWpt:     -0.013621        1.0000   [       -8.7752        8.0594 ]
                         :    DRlepWeta:     0.0023096        1.0000   [       -5.7949        4.5482 ]
                         :   DRlepWdeta:    -0.0099327        1.0000   [       -6.5516        8.1262 ]
                         :   DRlepWdphi:    -0.0018554        1.0000   [       -6.2548        7.3905 ]
                         :      DRlepWm:    -0.0080329        1.0000   [       -6.4809        9.6698 ]
                         :     DRjet0pt:     -0.022829        1.0000   [       -4.4771        5.9463 ]
                         :    DRjet0eta:    -0.0077114        1.0000   [       -6.5160        6.5293 ]
                         :      DRjet0m:     -0.014050        1.0000   [       -4.7465        6.3441 ]
                         :    DRjet0csv:     -0.012833        1.0000   [       -5.6557        6.0672 ]
                         :   DRjet0cvsl:     -0.016718        1.0000   [       -5.1963        5.5776 ]
                         :   DRjet0cvsb:    -0.0020877        1.0000   [       -4.7405        5.8277 ]
                         :     DRjet1pt:      0.010607        1.0000   [       -5.4242        4.8624 ]
                         :    DRjet1eta:    -0.0056054        1.0000   [       -4.8709        5.0098 ]
                         :      DRjet1m:     0.0013445        1.0000   [       -4.4264        4.9094 ]
                         :    DRjet1csv:    -0.0073815        1.0000   [       -6.2670        4.5645 ]
                         :   DRjet1cvsl:     0.0043662        1.0000   [       -5.2963        5.1900 ]
                         :   DRjet1cvsb:    -0.0015357        1.0000   [       -7.7479        5.7463 ]
                         :     DRjet2pt:     0.0018171        1.0000   [       -4.6929        5.6315 ]
                         :    DRjet2eta:   -0.00086416        1.0000   [       -4.7840        5.3511 ]
                         :      DRjet2m:     -0.012135        1.0000   [       -5.5635        6.4035 ]
                         :    DRjet2csv:     -0.011713        1.0000   [       -4.0563        4.4625 ]
                         :   DRjet2cvsl:    -0.0046108        1.0000   [       -4.5416        5.6506 ]
                         :   DRjet2cvsb:     -0.014822        1.0000   [       -5.5207        4.9861 ]
                         :     DRjet3pt:    -0.0096631        1.0000   [       -4.5330        5.3831 ]
                         :    DRjet3eta:    -0.0016028        1.0000   [       -5.7881        5.1072 ]
                         :      DRjet3m:     -0.011092        1.0000   [       -5.0377        5.7437 ]
                         :    DRjet3csv:    0.00024155        1.0000   [       -4.6093        4.7172 ]
                         :   DRjet3cvsl:    -0.0031074        1.0000   [       -5.1286        4.0980 ]
                         :   DRjet3cvsb:    -0.0067404        1.0000   [       -5.8363        5.1375 ]
                         :    DRjet12pt:     0.0071829        1.0000   [       -6.7721        5.0903 ]
                         :   DRjet12eta:     0.0051794        1.0000   [       -5.0367        4.7187 ]
                         :  DRjet12deta:    -0.0057918        1.0000   [       -5.2303        6.5459 ]
                         :  DRjet12dphi:      0.010541        1.0000   [       -5.2561        4.2520 ]
                         :     DRjet12m:    -0.0051811        1.0000   [       -4.9170        5.3690 ]
                         :    DRjet12DR:     0.0010687        1.0000   [       -5.6088        4.6326 ]
                         :    DRjet23pt:     0.0099640        1.0000   [       -5.1595        4.2714 ]
                         :   DRjet23eta:     0.0089651        1.0000   [       -5.4738        5.3501 ]
                         :  DRjet23deta:    -0.0055863        1.0000   [       -6.5569        5.7944 ]
                         :  DRjet23dphi:     0.0064342        1.0000   [       -3.8340        6.8842 ]
                         :     DRjet23m:     0.0013169        1.0000   [       -3.9250        4.8105 ]
                         :    DRjet31pt:      0.013312        1.0000   [       -5.0268        4.1589 ]
                         :   DRjet31eta:    0.00033071        1.0000   [       -8.3179        6.3064 ]
                         :  DRjet31deta:     0.0091328        1.0000   [       -4.2388        4.6669 ]
                         :  DRjet31dphi:     0.0080858        1.0000   [       -4.1430        4.8036 ]
                         :     DRjet31m:     0.0019113        1.0000   [       -4.2881        4.3915 ]
                         :     DRlepTpt:     0.0017277        1.0000   [       -4.3106        6.8234 ]
                         :    DRlepTeta:    -0.0034056        1.0000   [       -6.3464        5.8332 ]
                         :   DRlepTdeta:     0.0021913        1.0000   [       -5.4701        5.2306 ]
                         :   DRlepTdphi:     -0.011540        1.0000   [       -6.3418        5.1126 ]
                         :      DRlepTm:     -0.011900        1.0000   [       -4.8638        4.8516 ]
                         :     DRhadTpt:      0.017775        1.0000   [       -7.3672        5.7129 ]
                         :    DRhadTeta:     -0.010261        1.0000   [       -5.9487        6.8013 ]
                         : DRhadTHbdeta:     -0.012070        1.0000   [       -4.8090        9.8950 ]
                         : DRhadTWbdeta:    -0.0065698        1.0000   [       -14.719        3.2584 ]
                         : DRhadTHbdphi:      0.015720        1.0000   [       -3.7720        16.906 ]
                         : DRhadTWbdphi:     0.0027098        1.0000   [       -5.1615        6.9566 ]
                         :      DRhadTm:   -1.6630e-05        1.0000   [       -7.0972        4.5270 ]
                         : -------------------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
training_Hut.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  #!/usr/bin/env python
Train on 29000 samples, validate on 10654 samples
Epoch 1/60

 1000/29000 [>.............................] - ETA: 39s - loss: 1.7366 - binary_accuracy: 0.5220
 3000/29000 [==>...........................] - ETA: 12s - loss: 1.7824 - binary_accuracy: 0.5087
 5000/29000 [====>.........................] - ETA: 7s - loss: 1.7392 - binary_accuracy: 0.5252 
 7000/29000 [======>.......................] - ETA: 5s - loss: 1.7271 - binary_accuracy: 0.5236
 9000/29000 [========>.....................] - ETA: 3s - loss: 1.7068 - binary_accuracy: 0.5260
11000/29000 [==========>...................] - ETA: 2s - loss: 1.6857 - binary_accuracy: 0.5313
13000/29000 [============>.................] - ETA: 2s - loss: 1.6714 - binary_accuracy: 0.5351
15000/29000 [==============>...............] - ETA: 1s - loss: 1.6567 - binary_accuracy: 0.5415
17000/29000 [================>.............] - ETA: 1s - loss: 1.6359 - binary_accuracy: 0.5489
19000/29000 [==================>...........] - ETA: 1s - loss: 1.6260 - binary_accuracy: 0.5539
21000/29000 [====================>.........] - ETA: 0s - loss: 1.6122 - binary_accuracy: 0.5579
23000/29000 [======================>.......] - ETA: 0s - loss: 1.6005 - binary_accuracy: 0.5597
25000/29000 [========================>.....] - ETA: 0s - loss: 1.5883 - binary_accuracy: 0.5610
27000/29000 [==========================>...] - ETA: 0s - loss: 1.5805 - binary_accuracy: 0.5614Epoch 00001: val_loss improved from inf to 0.60022, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 6s 203us/step - loss: 1.5682 - binary_accuracy: 0.5639 - val_loss: 0.6002 - val_binary_accuracy: 0.6781
Epoch 2/60

 1000/29000 [>.............................] - ETA: 1s - loss: 1.3420 - binary_accuracy: 0.6200
 3000/29000 [==>...........................] - ETA: 1s - loss: 1.3416 - binary_accuracy: 0.6130
 5000/29000 [====>.........................] - ETA: 1s - loss: 1.3318 - binary_accuracy: 0.6134
 7000/29000 [======>.......................] - ETA: 0s - loss: 1.3515 - binary_accuracy: 0.6044
 9000/29000 [========>.....................] - ETA: 0s - loss: 1.3410 - binary_accuracy: 0.6061
11000/29000 [==========>...................] - ETA: 0s - loss: 1.3361 - binary_accuracy: 0.6067
13000/29000 [============>.................] - ETA: 0s - loss: 1.3166 - binary_accuracy: 0.6088
15000/29000 [==============>...............] - ETA: 0s - loss: 1.3110 - binary_accuracy: 0.6099
17000/29000 [================>.............] - ETA: 0s - loss: 1.2992 - binary_accuracy: 0.6136
19000/29000 [==================>...........] - ETA: 0s - loss: 1.2927 - binary_accuracy: 0.6139
21000/29000 [====================>.........] - ETA: 0s - loss: 1.2809 - binary_accuracy: 0.6146
23000/29000 [======================>.......] - ETA: 0s - loss: 1.2730 - binary_accuracy: 0.6153
25000/29000 [========================>.....] - ETA: 0s - loss: 1.2670 - binary_accuracy: 0.6167
27000/29000 [==========================>...] - ETA: 0s - loss: 1.2580 - binary_accuracy: 0.6192Epoch 00002: val_loss improved from 0.60022 to 0.55023, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 101us/step - loss: 1.2508 - binary_accuracy: 0.6197 - val_loss: 0.5502 - val_binary_accuracy: 0.6740
Epoch 3/60

 1000/29000 [>.............................] - ETA: 1s - loss: 1.1488 - binary_accuracy: 0.6320
 3000/29000 [==>...........................] - ETA: 1s - loss: 1.1459 - binary_accuracy: 0.6353
 5000/29000 [====>.........................] - ETA: 0s - loss: 1.1292 - binary_accuracy: 0.6450
 7000/29000 [======>.......................] - ETA: 0s - loss: 1.1224 - binary_accuracy: 0.6409
 9000/29000 [========>.....................] - ETA: 0s - loss: 1.1204 - binary_accuracy: 0.6372
11000/29000 [==========>...................] - ETA: 0s - loss: 1.1233 - binary_accuracy: 0.6348
13000/29000 [============>.................] - ETA: 0s - loss: 1.1198 - binary_accuracy: 0.6348
15000/29000 [==============>...............] - ETA: 0s - loss: 1.1126 - binary_accuracy: 0.6371
17000/29000 [================>.............] - ETA: 0s - loss: 1.1078 - binary_accuracy: 0.6396
19000/29000 [==================>...........] - ETA: 0s - loss: 1.1030 - binary_accuracy: 0.6409
21000/29000 [====================>.........] - ETA: 0s - loss: 1.0986 - binary_accuracy: 0.6417
23000/29000 [======================>.......] - ETA: 0s - loss: 1.0932 - binary_accuracy: 0.6417
25000/29000 [========================>.....] - ETA: 0s - loss: 1.0883 - binary_accuracy: 0.6423
27000/29000 [==========================>...] - ETA: 0s - loss: 1.0840 - binary_accuracy: 0.6441Epoch 00003: val_loss improved from 0.55023 to 0.46709, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 97us/step - loss: 1.0777 - binary_accuracy: 0.6462 - val_loss: 0.4671 - val_binary_accuracy: 0.6597
Epoch 4/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.9624 - binary_accuracy: 0.6880
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.9865 - binary_accuracy: 0.6833
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.9993 - binary_accuracy: 0.6710
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.9962 - binary_accuracy: 0.6707
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.9946 - binary_accuracy: 0.6713
11000/29000 [==========>...................] - ETA: 0s - loss: 0.9888 - binary_accuracy: 0.6761
13000/29000 [============>.................] - ETA: 0s - loss: 0.9847 - binary_accuracy: 0.6738
15000/29000 [==============>...............] - ETA: 0s - loss: 0.9815 - binary_accuracy: 0.6724
17000/29000 [================>.............] - ETA: 0s - loss: 0.9789 - binary_accuracy: 0.6710
19000/29000 [==================>...........] - ETA: 0s - loss: 0.9750 - binary_accuracy: 0.6721
21000/29000 [====================>.........] - ETA: 0s - loss: 0.9735 - binary_accuracy: 0.6719
23000/29000 [======================>.......] - ETA: 0s - loss: 0.9720 - binary_accuracy: 0.6705
25000/29000 [========================>.....] - ETA: 0s - loss: 0.9683 - binary_accuracy: 0.6709
27000/29000 [==========================>...] - ETA: 0s - loss: 0.9655 - binary_accuracy: 0.6716Epoch 00004: val_loss improved from 0.46709 to 0.38028, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 103us/step - loss: 0.9634 - binary_accuracy: 0.6711 - val_loss: 0.3803 - val_binary_accuracy: 0.6466
Epoch 5/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.9173 - binary_accuracy: 0.6740
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.9227 - binary_accuracy: 0.6757
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.9138 - binary_accuracy: 0.6798
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.9070 - binary_accuracy: 0.6841
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.9044 - binary_accuracy: 0.6878
11000/29000 [==========>...................] - ETA: 0s - loss: 0.8995 - binary_accuracy: 0.6893
13000/29000 [============>.................] - ETA: 0s - loss: 0.8917 - binary_accuracy: 0.6934
15000/29000 [==============>...............] - ETA: 0s - loss: 0.8870 - binary_accuracy: 0.6963
17000/29000 [================>.............] - ETA: 0s - loss: 0.8816 - binary_accuracy: 0.6994
19000/29000 [==================>...........] - ETA: 0s - loss: 0.8761 - binary_accuracy: 0.7011
21000/29000 [====================>.........] - ETA: 0s - loss: 0.8687 - binary_accuracy: 0.7038
23000/29000 [======================>.......] - ETA: 0s - loss: 0.8643 - binary_accuracy: 0.7052
25000/29000 [========================>.....] - ETA: 0s - loss: 0.8607 - binary_accuracy: 0.7067
27000/29000 [==========================>...] - ETA: 0s - loss: 0.8547 - binary_accuracy: 0.7099Epoch 00005: val_loss improved from 0.38028 to 0.30216, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 103us/step - loss: 0.8504 - binary_accuracy: 0.7109 - val_loss: 0.3022 - val_binary_accuracy: 0.7152
Epoch 6/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.7805 - binary_accuracy: 0.7160
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.7882 - binary_accuracy: 0.7203
 5000/29000 [====>.........................] - ETA: 1s - loss: 0.7807 - binary_accuracy: 0.7230
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.7794 - binary_accuracy: 0.7251
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.7808 - binary_accuracy: 0.7249
11000/29000 [==========>...................] - ETA: 0s - loss: 0.7769 - binary_accuracy: 0.7285
13000/29000 [============>.................] - ETA: 0s - loss: 0.7736 - binary_accuracy: 0.7306
15000/29000 [==============>...............] - ETA: 0s - loss: 0.7688 - binary_accuracy: 0.7332
17000/29000 [================>.............] - ETA: 0s - loss: 0.7642 - binary_accuracy: 0.7359
19000/29000 [==================>...........] - ETA: 0s - loss: 0.7619 - binary_accuracy: 0.7357
21000/29000 [====================>.........] - ETA: 0s - loss: 0.7599 - binary_accuracy: 0.7361
23000/29000 [======================>.......] - ETA: 0s - loss: 0.7577 - binary_accuracy: 0.7358
25000/29000 [========================>.....] - ETA: 0s - loss: 0.7556 - binary_accuracy: 0.7369
27000/29000 [==========================>...] - ETA: 0s - loss: 0.7541 - binary_accuracy: 0.7370Epoch 00006: val_loss improved from 0.30216 to 0.24902, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 103us/step - loss: 0.7514 - binary_accuracy: 0.7377 - val_loss: 0.2490 - val_binary_accuracy: 0.7204
Epoch 7/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.7227 - binary_accuracy: 0.7500
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.7012 - binary_accuracy: 0.7587
 5000/29000 [====>.........................] - ETA: 1s - loss: 0.7021 - binary_accuracy: 0.7570
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.6975 - binary_accuracy: 0.7566
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.7029 - binary_accuracy: 0.7502
11000/29000 [==========>...................] - ETA: 0s - loss: 0.7079 - binary_accuracy: 0.7459
13000/29000 [============>.................] - ETA: 0s - loss: 0.7096 - binary_accuracy: 0.7442
15000/29000 [==============>...............] - ETA: 0s - loss: 0.7064 - binary_accuracy: 0.7447
17000/29000 [================>.............] - ETA: 0s - loss: 0.7060 - binary_accuracy: 0.7431
19000/29000 [==================>...........] - ETA: 0s - loss: 0.7022 - binary_accuracy: 0.7454
21000/29000 [====================>.........] - ETA: 0s - loss: 0.6987 - binary_accuracy: 0.7465
23000/29000 [======================>.......] - ETA: 0s - loss: 0.6969 - binary_accuracy: 0.7469
25000/29000 [========================>.....] - ETA: 0s - loss: 0.6974 - binary_accuracy: 0.7466
27000/29000 [==========================>...] - ETA: 0s - loss: 0.6950 - binary_accuracy: 0.7474Epoch 00007: val_loss improved from 0.24902 to 0.20719, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 101us/step - loss: 0.6944 - binary_accuracy: 0.7462 - val_loss: 0.2072 - val_binary_accuracy: 0.7089
Epoch 8/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.6632 - binary_accuracy: 0.7550
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.6794 - binary_accuracy: 0.7393
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.6731 - binary_accuracy: 0.7410
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.6683 - binary_accuracy: 0.7441
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.6573 - binary_accuracy: 0.7509
11000/29000 [==========>...................] - ETA: 0s - loss: 0.6569 - binary_accuracy: 0.7505
13000/29000 [============>.................] - ETA: 0s - loss: 0.6543 - binary_accuracy: 0.7517
15000/29000 [==============>...............] - ETA: 0s - loss: 0.6572 - binary_accuracy: 0.7494
17000/29000 [================>.............] - ETA: 0s - loss: 0.6558 - binary_accuracy: 0.7500
19000/29000 [==================>...........] - ETA: 0s - loss: 0.6543 - binary_accuracy: 0.7505
21000/29000 [====================>.........] - ETA: 0s - loss: 0.6538 - binary_accuracy: 0.7495
23000/29000 [======================>.......] - ETA: 0s - loss: 0.6521 - binary_accuracy: 0.7507
25000/29000 [========================>.....] - ETA: 0s - loss: 0.6518 - binary_accuracy: 0.7502
27000/29000 [==========================>...] - ETA: 0s - loss: 0.6526 - binary_accuracy: 0.7491Epoch 00008: val_loss improved from 0.20719 to 0.17843, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 99us/step - loss: 0.6520 - binary_accuracy: 0.7503 - val_loss: 0.1784 - val_binary_accuracy: 0.6798
Epoch 9/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.6154 - binary_accuracy: 0.7710
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.6263 - binary_accuracy: 0.7567
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.6157 - binary_accuracy: 0.7636
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.6226 - binary_accuracy: 0.7561
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.6184 - binary_accuracy: 0.7536
11000/29000 [==========>...................] - ETA: 0s - loss: 0.6211 - binary_accuracy: 0.7514
13000/29000 [============>.................] - ETA: 0s - loss: 0.6199 - binary_accuracy: 0.7516
15000/29000 [==============>...............] - ETA: 0s - loss: 0.6230 - binary_accuracy: 0.7516
17000/29000 [================>.............] - ETA: 0s - loss: 0.6237 - binary_accuracy: 0.7504
19000/29000 [==================>...........] - ETA: 0s - loss: 0.6234 - binary_accuracy: 0.7495
21000/29000 [====================>.........] - ETA: 0s - loss: 0.6232 - binary_accuracy: 0.7481
23000/29000 [======================>.......] - ETA: 0s - loss: 0.6224 - binary_accuracy: 0.7468
25000/29000 [========================>.....] - ETA: 0s - loss: 0.6210 - binary_accuracy: 0.7469
27000/29000 [==========================>...] - ETA: 0s - loss: 0.6191 - binary_accuracy: 0.7479Epoch 00009: val_loss improved from 0.17843 to 0.15482, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 101us/step - loss: 0.6191 - binary_accuracy: 0.7481 - val_loss: 0.1548 - val_binary_accuracy: 0.6601
Epoch 10/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.6017 - binary_accuracy: 0.7610
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.6009 - binary_accuracy: 0.7570
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.6020 - binary_accuracy: 0.7532
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5984 - binary_accuracy: 0.7511
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.6005 - binary_accuracy: 0.7502
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5986 - binary_accuracy: 0.7520
13000/29000 [============>.................] - ETA: 0s - loss: 0.5977 - binary_accuracy: 0.7524
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5978 - binary_accuracy: 0.7527
17000/29000 [================>.............] - ETA: 0s - loss: 0.5972 - binary_accuracy: 0.7536
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5948 - binary_accuracy: 0.7542
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5940 - binary_accuracy: 0.7527
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5939 - binary_accuracy: 0.7525
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5928 - binary_accuracy: 0.7514
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5918 - binary_accuracy: 0.7512Epoch 00010: val_loss improved from 0.15482 to 0.13085, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 101us/step - loss: 0.5912 - binary_accuracy: 0.7516 - val_loss: 0.1309 - val_binary_accuracy: 0.6527
Epoch 11/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5579 - binary_accuracy: 0.7560
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5829 - binary_accuracy: 0.7530
 5000/29000 [====>.........................] - ETA: 1s - loss: 0.5781 - binary_accuracy: 0.7502
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5713 - binary_accuracy: 0.7540
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5729 - binary_accuracy: 0.7529
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5743 - binary_accuracy: 0.7515
13000/29000 [============>.................] - ETA: 0s - loss: 0.5711 - binary_accuracy: 0.7544
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5696 - binary_accuracy: 0.7546
17000/29000 [================>.............] - ETA: 0s - loss: 0.5679 - binary_accuracy: 0.7558
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5675 - binary_accuracy: 0.7552
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5665 - binary_accuracy: 0.7536
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5698 - binary_accuracy: 0.7524
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5708 - binary_accuracy: 0.7508
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5692 - binary_accuracy: 0.7507Epoch 00011: val_loss improved from 0.13085 to 0.11960, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 102us/step - loss: 0.5692 - binary_accuracy: 0.7508 - val_loss: 0.1196 - val_binary_accuracy: 0.6217
Epoch 12/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5782 - binary_accuracy: 0.7510
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5670 - binary_accuracy: 0.7430
 5000/29000 [====>.........................] - ETA: 1s - loss: 0.5505 - binary_accuracy: 0.7548
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5440 - binary_accuracy: 0.7604
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5503 - binary_accuracy: 0.7576
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5522 - binary_accuracy: 0.7561
13000/29000 [============>.................] - ETA: 0s - loss: 0.5531 - binary_accuracy: 0.7560
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5541 - binary_accuracy: 0.7565
17000/29000 [================>.............] - ETA: 0s - loss: 0.5544 - binary_accuracy: 0.7564
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5552 - binary_accuracy: 0.7559
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5559 - binary_accuracy: 0.7561
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5560 - binary_accuracy: 0.7557
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5542 - binary_accuracy: 0.7561
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5545 - binary_accuracy: 0.7550Epoch 00012: val_loss improved from 0.11960 to 0.11034, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 104us/step - loss: 0.5547 - binary_accuracy: 0.7547 - val_loss: 0.1103 - val_binary_accuracy: 0.6005
Epoch 13/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5331 - binary_accuracy: 0.7580
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5436 - binary_accuracy: 0.7620
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.5549 - binary_accuracy: 0.7524
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5488 - binary_accuracy: 0.7573
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5466 - binary_accuracy: 0.7599
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5441 - binary_accuracy: 0.7608
13000/29000 [============>.................] - ETA: 0s - loss: 0.5411 - binary_accuracy: 0.7610
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5377 - binary_accuracy: 0.7606
17000/29000 [================>.............] - ETA: 0s - loss: 0.5392 - binary_accuracy: 0.7602
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5396 - binary_accuracy: 0.7591
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5399 - binary_accuracy: 0.7576
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5413 - binary_accuracy: 0.7570
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5410 - binary_accuracy: 0.7565
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5405 - binary_accuracy: 0.7574Epoch 00013: val_loss improved from 0.11034 to 0.10010, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 101us/step - loss: 0.5404 - binary_accuracy: 0.7566 - val_loss: 0.1001 - val_binary_accuracy: 0.5971
Epoch 14/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5393 - binary_accuracy: 0.7490
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5302 - binary_accuracy: 0.7550
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.5374 - binary_accuracy: 0.7502
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5327 - binary_accuracy: 0.7516
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5309 - binary_accuracy: 0.7533
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5324 - binary_accuracy: 0.7518
13000/29000 [============>.................] - ETA: 0s - loss: 0.5314 - binary_accuracy: 0.7544
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5302 - binary_accuracy: 0.7550
17000/29000 [================>.............] - ETA: 0s - loss: 0.5292 - binary_accuracy: 0.7545
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5288 - binary_accuracy: 0.7548
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5299 - binary_accuracy: 0.7533
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5299 - binary_accuracy: 0.7536
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5308 - binary_accuracy: 0.7537
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5311 - binary_accuracy: 0.7539Epoch 00014: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.5306 - binary_accuracy: 0.7551 - val_loss: 0.1051 - val_binary_accuracy: 0.5437
Epoch 15/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5136 - binary_accuracy: 0.7710
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5319 - binary_accuracy: 0.7503
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.5221 - binary_accuracy: 0.7564
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5211 - binary_accuracy: 0.7569
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5199 - binary_accuracy: 0.7574
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5297 - binary_accuracy: 0.7532
13000/29000 [============>.................] - ETA: 0s - loss: 0.5301 - binary_accuracy: 0.7528
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5307 - binary_accuracy: 0.7528
17000/29000 [================>.............] - ETA: 0s - loss: 0.5291 - binary_accuracy: 0.7532
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5281 - binary_accuracy: 0.7545
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5283 - binary_accuracy: 0.7550
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5276 - binary_accuracy: 0.7553
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5265 - binary_accuracy: 0.7566
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5240 - binary_accuracy: 0.7573Epoch 00015: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.5245 - binary_accuracy: 0.7565 - val_loss: 0.1030 - val_binary_accuracy: 0.5571
Epoch 16/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5128 - binary_accuracy: 0.7560
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5075 - binary_accuracy: 0.7590
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.5023 - binary_accuracy: 0.7628
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5029 - binary_accuracy: 0.7619
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5087 - binary_accuracy: 0.7613
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5128 - binary_accuracy: 0.7594
13000/29000 [============>.................] - ETA: 0s - loss: 0.5138 - binary_accuracy: 0.7580
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5117 - binary_accuracy: 0.7575
17000/29000 [================>.............] - ETA: 0s - loss: 0.5136 - binary_accuracy: 0.7570
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5142 - binary_accuracy: 0.7574
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5148 - binary_accuracy: 0.7582
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5151 - binary_accuracy: 0.7573
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5165 - binary_accuracy: 0.7575
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5166 - binary_accuracy: 0.7570Epoch 00016: val_loss improved from 0.10010 to 0.09102, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 103us/step - loss: 0.5174 - binary_accuracy: 0.7566 - val_loss: 0.0910 - val_binary_accuracy: 0.5707
Epoch 17/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5373 - binary_accuracy: 0.7340
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5271 - binary_accuracy: 0.7437
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.5252 - binary_accuracy: 0.7524
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5232 - binary_accuracy: 0.7550
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5163 - binary_accuracy: 0.7623
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5139 - binary_accuracy: 0.7631
13000/29000 [============>.................] - ETA: 0s - loss: 0.5148 - binary_accuracy: 0.7598
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5146 - binary_accuracy: 0.7592
17000/29000 [================>.............] - ETA: 0s - loss: 0.5133 - binary_accuracy: 0.7592
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5135 - binary_accuracy: 0.7592
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5123 - binary_accuracy: 0.7604
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5104 - binary_accuracy: 0.7615
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5100 - binary_accuracy: 0.7609
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5104 - binary_accuracy: 0.7600Epoch 00017: val_loss improved from 0.09102 to 0.08868, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 102us/step - loss: 0.5113 - binary_accuracy: 0.7601 - val_loss: 0.0887 - val_binary_accuracy: 0.5653
Epoch 18/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5264 - binary_accuracy: 0.7540
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5069 - binary_accuracy: 0.7613
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.5007 - binary_accuracy: 0.7634
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5042 - binary_accuracy: 0.7643
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5066 - binary_accuracy: 0.7623
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5111 - binary_accuracy: 0.7595
13000/29000 [============>.................] - ETA: 0s - loss: 0.5091 - binary_accuracy: 0.7592
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5101 - binary_accuracy: 0.7594
17000/29000 [================>.............] - ETA: 0s - loss: 0.5089 - binary_accuracy: 0.7604
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5087 - binary_accuracy: 0.7606
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5125 - binary_accuracy: 0.7575
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5116 - binary_accuracy: 0.7582
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5112 - binary_accuracy: 0.7585
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5093 - binary_accuracy: 0.7586Epoch 00018: val_loss did not improve

29000/29000 [==============================] - 1s 44us/step - loss: 0.5110 - binary_accuracy: 0.7577 - val_loss: 0.0931 - val_binary_accuracy: 0.5595
Epoch 19/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5128 - binary_accuracy: 0.7650
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5129 - binary_accuracy: 0.7650
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.5093 - binary_accuracy: 0.7622
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5037 - binary_accuracy: 0.7654
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5064 - binary_accuracy: 0.7627
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5075 - binary_accuracy: 0.7617
13000/29000 [============>.................] - ETA: 0s - loss: 0.5064 - binary_accuracy: 0.7625
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5076 - binary_accuracy: 0.7609
17000/29000 [================>.............] - ETA: 0s - loss: 0.5086 - binary_accuracy: 0.7602
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5088 - binary_accuracy: 0.7605
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5086 - binary_accuracy: 0.7615
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5079 - binary_accuracy: 0.7610
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5081 - binary_accuracy: 0.7598
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5089 - binary_accuracy: 0.7595Epoch 00019: val_loss improved from 0.08868 to 0.08470, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 103us/step - loss: 0.5064 - binary_accuracy: 0.7608 - val_loss: 0.0847 - val_binary_accuracy: 0.5872
Epoch 20/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5224 - binary_accuracy: 0.7640
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4989 - binary_accuracy: 0.7740
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4899 - binary_accuracy: 0.7716
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4971 - binary_accuracy: 0.7653
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4977 - binary_accuracy: 0.7643
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5018 - binary_accuracy: 0.7615
13000/29000 [============>.................] - ETA: 0s - loss: 0.5023 - binary_accuracy: 0.7586
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5039 - binary_accuracy: 0.7579
17000/29000 [================>.............] - ETA: 0s - loss: 0.5024 - binary_accuracy: 0.7602
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5000 - binary_accuracy: 0.7621
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4981 - binary_accuracy: 0.7632
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4993 - binary_accuracy: 0.7622
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4996 - binary_accuracy: 0.7630
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5012 - binary_accuracy: 0.7620Epoch 00020: val_loss improved from 0.08470 to 0.08143, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 100us/step - loss: 0.5023 - binary_accuracy: 0.7615 - val_loss: 0.0814 - val_binary_accuracy: 0.5848
Epoch 21/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5017 - binary_accuracy: 0.7660
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4956 - binary_accuracy: 0.7680
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.5062 - binary_accuracy: 0.7570
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5042 - binary_accuracy: 0.7597
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5036 - binary_accuracy: 0.7599
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5065 - binary_accuracy: 0.7565
13000/29000 [============>.................] - ETA: 0s - loss: 0.5052 - binary_accuracy: 0.7587
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5040 - binary_accuracy: 0.7591
17000/29000 [================>.............] - ETA: 0s - loss: 0.5035 - binary_accuracy: 0.7578
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5032 - binary_accuracy: 0.7583
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5040 - binary_accuracy: 0.7583
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5034 - binary_accuracy: 0.7580
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5010 - binary_accuracy: 0.7598
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5002 - binary_accuracy: 0.7607Epoch 00021: val_loss did not improve

29000/29000 [==============================] - 1s 44us/step - loss: 0.5012 - binary_accuracy: 0.7609 - val_loss: 0.0843 - val_binary_accuracy: 0.6017
Epoch 22/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4925 - binary_accuracy: 0.7810
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4957 - binary_accuracy: 0.7660
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.5014 - binary_accuracy: 0.7680
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4942 - binary_accuracy: 0.7714
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4999 - binary_accuracy: 0.7667
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4944 - binary_accuracy: 0.7676
13000/29000 [============>.................] - ETA: 0s - loss: 0.4944 - binary_accuracy: 0.7666
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4956 - binary_accuracy: 0.7653
17000/29000 [================>.............] - ETA: 0s - loss: 0.4971 - binary_accuracy: 0.7638
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5000 - binary_accuracy: 0.7616
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5011 - binary_accuracy: 0.7609
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5017 - binary_accuracy: 0.7609
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5006 - binary_accuracy: 0.7613
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5012 - binary_accuracy: 0.7613Epoch 00022: val_loss improved from 0.08143 to 0.08027, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 100us/step - loss: 0.5019 - binary_accuracy: 0.7611 - val_loss: 0.0803 - val_binary_accuracy: 0.6069
Epoch 23/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4898 - binary_accuracy: 0.7600
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4949 - binary_accuracy: 0.7653
 5000/29000 [====>.........................] - ETA: 1s - loss: 0.5028 - binary_accuracy: 0.7594
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5073 - binary_accuracy: 0.7594
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.5077 - binary_accuracy: 0.7588
11000/29000 [==========>...................] - ETA: 0s - loss: 0.5061 - binary_accuracy: 0.7592
13000/29000 [============>.................] - ETA: 0s - loss: 0.5027 - binary_accuracy: 0.7620
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5025 - binary_accuracy: 0.7614
17000/29000 [================>.............] - ETA: 0s - loss: 0.5022 - binary_accuracy: 0.7618
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5012 - binary_accuracy: 0.7623
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5028 - binary_accuracy: 0.7612
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5042 - binary_accuracy: 0.7593
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5036 - binary_accuracy: 0.7593
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5027 - binary_accuracy: 0.7607Epoch 00023: val_loss improved from 0.08027 to 0.07979, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 99us/step - loss: 0.5016 - binary_accuracy: 0.7611 - val_loss: 0.0798 - val_binary_accuracy: 0.6237
Epoch 24/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4734 - binary_accuracy: 0.7610
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5021 - binary_accuracy: 0.7553
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4991 - binary_accuracy: 0.7598
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4989 - binary_accuracy: 0.7633
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4999 - binary_accuracy: 0.7616
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4990 - binary_accuracy: 0.7615
13000/29000 [============>.................] - ETA: 0s - loss: 0.4983 - binary_accuracy: 0.7619
15000/29000 [==============>...............] - ETA: 0s - loss: 0.5008 - binary_accuracy: 0.7610
17000/29000 [================>.............] - ETA: 0s - loss: 0.5008 - binary_accuracy: 0.7621
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5000 - binary_accuracy: 0.7639
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5011 - binary_accuracy: 0.7636
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4993 - binary_accuracy: 0.7627
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4982 - binary_accuracy: 0.7618
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4997 - binary_accuracy: 0.7611Epoch 00024: val_loss improved from 0.07979 to 0.07443, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 103us/step - loss: 0.4992 - binary_accuracy: 0.7613 - val_loss: 0.0744 - val_binary_accuracy: 0.6520
Epoch 25/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5180 - binary_accuracy: 0.7760
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5014 - binary_accuracy: 0.7650
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.5126 - binary_accuracy: 0.7598
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.5021 - binary_accuracy: 0.7660
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4980 - binary_accuracy: 0.7663
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4957 - binary_accuracy: 0.7678
13000/29000 [============>.................] - ETA: 0s - loss: 0.4989 - binary_accuracy: 0.7644
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4977 - binary_accuracy: 0.7649
17000/29000 [================>.............] - ETA: 0s - loss: 0.4972 - binary_accuracy: 0.7642
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4969 - binary_accuracy: 0.7642
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4985 - binary_accuracy: 0.7626
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4971 - binary_accuracy: 0.7625
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4982 - binary_accuracy: 0.7618
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4985 - binary_accuracy: 0.7613Epoch 00025: val_loss improved from 0.07443 to 0.07318, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 102us/step - loss: 0.4986 - binary_accuracy: 0.7613 - val_loss: 0.0732 - val_binary_accuracy: 0.6573
Epoch 26/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5260 - binary_accuracy: 0.7510
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5184 - binary_accuracy: 0.7563
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4972 - binary_accuracy: 0.7648
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4949 - binary_accuracy: 0.7687
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4929 - binary_accuracy: 0.7676
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4909 - binary_accuracy: 0.7678
13000/29000 [============>.................] - ETA: 0s - loss: 0.4967 - binary_accuracy: 0.7647
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4948 - binary_accuracy: 0.7663
17000/29000 [================>.............] - ETA: 0s - loss: 0.4943 - binary_accuracy: 0.7675
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4952 - binary_accuracy: 0.7669
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4965 - binary_accuracy: 0.7658
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4972 - binary_accuracy: 0.7657
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4975 - binary_accuracy: 0.7647
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4977 - binary_accuracy: 0.7640Epoch 00026: val_loss improved from 0.07318 to 0.06707, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 103us/step - loss: 0.4971 - binary_accuracy: 0.7644 - val_loss: 0.0671 - val_binary_accuracy: 0.6692
Epoch 27/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4807 - binary_accuracy: 0.7800
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4837 - binary_accuracy: 0.7697
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4831 - binary_accuracy: 0.7686
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4880 - binary_accuracy: 0.7681
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4867 - binary_accuracy: 0.7710
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4900 - binary_accuracy: 0.7675
13000/29000 [============>.................] - ETA: 0s - loss: 0.4918 - binary_accuracy: 0.7662
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4934 - binary_accuracy: 0.7641
17000/29000 [================>.............] - ETA: 0s - loss: 0.4936 - binary_accuracy: 0.7642
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4955 - binary_accuracy: 0.7634
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4953 - binary_accuracy: 0.7640
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4976 - binary_accuracy: 0.7626
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4980 - binary_accuracy: 0.7629
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4971 - binary_accuracy: 0.7624Epoch 00027: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4970 - binary_accuracy: 0.7620 - val_loss: 0.0703 - val_binary_accuracy: 0.6695
Epoch 28/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4658 - binary_accuracy: 0.7720
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4806 - binary_accuracy: 0.7683
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4829 - binary_accuracy: 0.7708
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4861 - binary_accuracy: 0.7701
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4922 - binary_accuracy: 0.7661
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4990 - binary_accuracy: 0.7619
13000/29000 [============>.................] - ETA: 0s - loss: 0.5015 - binary_accuracy: 0.7586
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4991 - binary_accuracy: 0.7603
17000/29000 [================>.............] - ETA: 0s - loss: 0.5010 - binary_accuracy: 0.7594
19000/29000 [==================>...........] - ETA: 0s - loss: 0.5012 - binary_accuracy: 0.7588
21000/29000 [====================>.........] - ETA: 0s - loss: 0.5011 - binary_accuracy: 0.7600
23000/29000 [======================>.......] - ETA: 0s - loss: 0.5017 - binary_accuracy: 0.7598
25000/29000 [========================>.....] - ETA: 0s - loss: 0.5025 - binary_accuracy: 0.7600
27000/29000 [==========================>...] - ETA: 0s - loss: 0.5001 - binary_accuracy: 0.7600Epoch 00028: val_loss improved from 0.06707 to 0.06373, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 98us/step - loss: 0.5000 - binary_accuracy: 0.7605 - val_loss: 0.0637 - val_binary_accuracy: 0.6934
Epoch 29/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4680 - binary_accuracy: 0.7660
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4818 - binary_accuracy: 0.7620
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4874 - binary_accuracy: 0.7604
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4962 - binary_accuracy: 0.7584
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4961 - binary_accuracy: 0.7607
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4924 - binary_accuracy: 0.7629
13000/29000 [============>.................] - ETA: 0s - loss: 0.4947 - binary_accuracy: 0.7624
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4967 - binary_accuracy: 0.7621
17000/29000 [================>.............] - ETA: 0s - loss: 0.4972 - binary_accuracy: 0.7612
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4957 - binary_accuracy: 0.7622
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4951 - binary_accuracy: 0.7632
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4974 - binary_accuracy: 0.7621
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4993 - binary_accuracy: 0.7618
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4966 - binary_accuracy: 0.7630Epoch 00029: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4951 - binary_accuracy: 0.7644 - val_loss: 0.0656 - val_binary_accuracy: 0.6878
Epoch 30/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4738 - binary_accuracy: 0.7810
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4919 - binary_accuracy: 0.7653
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4866 - binary_accuracy: 0.7636
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4922 - binary_accuracy: 0.7601
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4954 - binary_accuracy: 0.7604
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4959 - binary_accuracy: 0.7595
13000/29000 [============>.................] - ETA: 0s - loss: 0.4941 - binary_accuracy: 0.7622
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4913 - binary_accuracy: 0.7649
17000/29000 [================>.............] - ETA: 0s - loss: 0.4925 - binary_accuracy: 0.7638
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4929 - binary_accuracy: 0.7636
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4950 - binary_accuracy: 0.7621
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4963 - binary_accuracy: 0.7617
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4975 - binary_accuracy: 0.7604
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4972 - binary_accuracy: 0.7605Epoch 00030: val_loss improved from 0.06373 to 0.06005, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 99us/step - loss: 0.4977 - binary_accuracy: 0.7603 - val_loss: 0.0600 - val_binary_accuracy: 0.7027
Epoch 31/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4940 - binary_accuracy: 0.7990
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4965 - binary_accuracy: 0.7690
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4957 - binary_accuracy: 0.7648
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4989 - binary_accuracy: 0.7623
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4958 - binary_accuracy: 0.7638
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4996 - binary_accuracy: 0.7623
13000/29000 [============>.................] - ETA: 0s - loss: 0.4971 - binary_accuracy: 0.7656
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4971 - binary_accuracy: 0.7649
17000/29000 [================>.............] - ETA: 0s - loss: 0.4954 - binary_accuracy: 0.7655
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4942 - binary_accuracy: 0.7657
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4944 - binary_accuracy: 0.7660
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4945 - binary_accuracy: 0.7662
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4941 - binary_accuracy: 0.7662
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4965 - binary_accuracy: 0.7641Epoch 00031: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4965 - binary_accuracy: 0.7642 - val_loss: 0.0612 - val_binary_accuracy: 0.7052
Epoch 32/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4896 - binary_accuracy: 0.7780
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4930 - binary_accuracy: 0.7650
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4886 - binary_accuracy: 0.7640
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4909 - binary_accuracy: 0.7594
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4861 - binary_accuracy: 0.7637
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4844 - binary_accuracy: 0.7676
13000/29000 [============>.................] - ETA: 0s - loss: 0.4899 - binary_accuracy: 0.7658
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4884 - binary_accuracy: 0.7665
17000/29000 [================>.............] - ETA: 0s - loss: 0.4891 - binary_accuracy: 0.7664
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4906 - binary_accuracy: 0.7654
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4912 - binary_accuracy: 0.7652
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4925 - binary_accuracy: 0.7645
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4929 - binary_accuracy: 0.7652
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4922 - binary_accuracy: 0.7652Epoch 00032: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4921 - binary_accuracy: 0.7646 - val_loss: 0.0660 - val_binary_accuracy: 0.6908
Epoch 33/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4606 - binary_accuracy: 0.7810
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5032 - binary_accuracy: 0.7607
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4939 - binary_accuracy: 0.7660
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4916 - binary_accuracy: 0.7680
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4912 - binary_accuracy: 0.7661
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4907 - binary_accuracy: 0.7636
13000/29000 [============>.................] - ETA: 0s - loss: 0.4911 - binary_accuracy: 0.7638
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4960 - binary_accuracy: 0.7611
17000/29000 [================>.............] - ETA: 0s - loss: 0.4943 - binary_accuracy: 0.7635
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4955 - binary_accuracy: 0.7617
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4946 - binary_accuracy: 0.7618
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4945 - binary_accuracy: 0.7622
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4937 - binary_accuracy: 0.7625
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4929 - binary_accuracy: 0.7631Epoch 00033: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4919 - binary_accuracy: 0.7641 - val_loss: 0.0674 - val_binary_accuracy: 0.7025
Epoch 34/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4828 - binary_accuracy: 0.7730
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4910 - binary_accuracy: 0.7640
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4924 - binary_accuracy: 0.7596
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4905 - binary_accuracy: 0.7660
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4892 - binary_accuracy: 0.7670
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4919 - binary_accuracy: 0.7652
13000/29000 [============>.................] - ETA: 0s - loss: 0.4921 - binary_accuracy: 0.7658
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4934 - binary_accuracy: 0.7654
17000/29000 [================>.............] - ETA: 0s - loss: 0.4934 - binary_accuracy: 0.7650
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4925 - binary_accuracy: 0.7652
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4922 - binary_accuracy: 0.7650
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4927 - binary_accuracy: 0.7650
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4917 - binary_accuracy: 0.7659
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4917 - binary_accuracy: 0.7649Epoch 00034: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4924 - binary_accuracy: 0.7645 - val_loss: 0.0649 - val_binary_accuracy: 0.6949
Epoch 35/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4848 - binary_accuracy: 0.7660
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4824 - binary_accuracy: 0.7730
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4853 - binary_accuracy: 0.7698
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4902 - binary_accuracy: 0.7640
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4932 - binary_accuracy: 0.7610
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4916 - binary_accuracy: 0.7641
13000/29000 [============>.................] - ETA: 0s - loss: 0.4953 - binary_accuracy: 0.7624
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4949 - binary_accuracy: 0.7619
17000/29000 [================>.............] - ETA: 0s - loss: 0.4929 - binary_accuracy: 0.7635
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4942 - binary_accuracy: 0.7616
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4945 - binary_accuracy: 0.7620
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4927 - binary_accuracy: 0.7624
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4937 - binary_accuracy: 0.7624
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4942 - binary_accuracy: 0.7617Epoch 00035: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4939 - binary_accuracy: 0.7620 - val_loss: 0.0635 - val_binary_accuracy: 0.6936
Epoch 36/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5003 - binary_accuracy: 0.7700
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4841 - binary_accuracy: 0.7733
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4895 - binary_accuracy: 0.7656
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4858 - binary_accuracy: 0.7681
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4868 - binary_accuracy: 0.7674
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4853 - binary_accuracy: 0.7696
13000/29000 [============>.................] - ETA: 0s - loss: 0.4817 - binary_accuracy: 0.7703
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4845 - binary_accuracy: 0.7693
17000/29000 [================>.............] - ETA: 0s - loss: 0.4879 - binary_accuracy: 0.7679
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4891 - binary_accuracy: 0.7662
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4906 - binary_accuracy: 0.7641
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4912 - binary_accuracy: 0.7636
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4909 - binary_accuracy: 0.7643
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4905 - binary_accuracy: 0.7653Epoch 00036: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4901 - binary_accuracy: 0.7652 - val_loss: 0.0691 - val_binary_accuracy: 0.6861
Epoch 37/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.5283 - binary_accuracy: 0.7380
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.5021 - binary_accuracy: 0.7607
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4963 - binary_accuracy: 0.7612
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4901 - binary_accuracy: 0.7639
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4904 - binary_accuracy: 0.7643
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4940 - binary_accuracy: 0.7638
13000/29000 [============>.................] - ETA: 0s - loss: 0.4951 - binary_accuracy: 0.7631
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4941 - binary_accuracy: 0.7627
17000/29000 [================>.............] - ETA: 0s - loss: 0.4945 - binary_accuracy: 0.7640
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4935 - binary_accuracy: 0.7644
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4961 - binary_accuracy: 0.7633
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4964 - binary_accuracy: 0.7629
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4961 - binary_accuracy: 0.7634
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4936 - binary_accuracy: 0.7647Epoch 00037: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4931 - binary_accuracy: 0.7641 - val_loss: 0.0644 - val_binary_accuracy: 0.7082
Epoch 38/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4655 - binary_accuracy: 0.7750
 3000/29000 [==>...........................] - ETA: 0s - loss: 0.4740 - binary_accuracy: 0.7730
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4828 - binary_accuracy: 0.7748
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4799 - binary_accuracy: 0.7767
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4832 - binary_accuracy: 0.7770
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4845 - binary_accuracy: 0.7761
13000/29000 [============>.................] - ETA: 0s - loss: 0.4865 - binary_accuracy: 0.7729
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4890 - binary_accuracy: 0.7705
17000/29000 [================>.............] - ETA: 0s - loss: 0.4882 - binary_accuracy: 0.7708
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4882 - binary_accuracy: 0.7695
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4882 - binary_accuracy: 0.7696
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4893 - binary_accuracy: 0.7689
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4897 - binary_accuracy: 0.7682
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4893 - binary_accuracy: 0.7673Epoch 00038: val_loss improved from 0.06005 to 0.05949, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 99us/step - loss: 0.4917 - binary_accuracy: 0.7659 - val_loss: 0.0595 - val_binary_accuracy: 0.7093
Epoch 39/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4663 - binary_accuracy: 0.7900
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4826 - binary_accuracy: 0.7730
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4779 - binary_accuracy: 0.7760
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4861 - binary_accuracy: 0.7701
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4863 - binary_accuracy: 0.7708
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4856 - binary_accuracy: 0.7687
13000/29000 [============>.................] - ETA: 0s - loss: 0.4848 - binary_accuracy: 0.7681
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4822 - binary_accuracy: 0.7693
17000/29000 [================>.............] - ETA: 0s - loss: 0.4837 - binary_accuracy: 0.7705
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4847 - binary_accuracy: 0.7700
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4867 - binary_accuracy: 0.7700
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4880 - binary_accuracy: 0.7690
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4882 - binary_accuracy: 0.7690
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4887 - binary_accuracy: 0.7677Epoch 00039: val_loss improved from 0.05949 to 0.05925, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 97us/step - loss: 0.4896 - binary_accuracy: 0.7672 - val_loss: 0.0592 - val_binary_accuracy: 0.7133
Epoch 40/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4907 - binary_accuracy: 0.7670
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4856 - binary_accuracy: 0.7657
 5000/29000 [====>.........................] - ETA: 1s - loss: 0.4833 - binary_accuracy: 0.7668
 6000/29000 [=====>........................] - ETA: 1s - loss: 0.4816 - binary_accuracy: 0.7685
 8000/29000 [=======>......................] - ETA: 0s - loss: 0.4838 - binary_accuracy: 0.7694
10000/29000 [=========>....................] - ETA: 0s - loss: 0.4847 - binary_accuracy: 0.7663
12000/29000 [===========>..................] - ETA: 0s - loss: 0.4842 - binary_accuracy: 0.7678
14000/29000 [=============>................] - ETA: 0s - loss: 0.4871 - binary_accuracy: 0.7659
16000/29000 [===============>..............] - ETA: 0s - loss: 0.4892 - binary_accuracy: 0.7646
18000/29000 [=================>............] - ETA: 0s - loss: 0.4893 - binary_accuracy: 0.7655
20000/29000 [===================>..........] - ETA: 0s - loss: 0.4867 - binary_accuracy: 0.7668
22000/29000 [=====================>........] - ETA: 0s - loss: 0.4865 - binary_accuracy: 0.7660
24000/29000 [=======================>......] - ETA: 0s - loss: 0.4877 - binary_accuracy: 0.7646
26000/29000 [=========================>....] - ETA: 0s - loss: 0.4894 - binary_accuracy: 0.7635
28000/29000 [===========================>..] - ETA: 0s - loss: 0.4884 - binary_accuracy: 0.7645Epoch 00040: val_loss did not improve

29000/29000 [==============================] - 1s 45us/step - loss: 0.4885 - binary_accuracy: 0.7647 - val_loss: 0.0610 - val_binary_accuracy: 0.7130
Epoch 41/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4903 - binary_accuracy: 0.7630
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4750 - binary_accuracy: 0.7670
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4738 - binary_accuracy: 0.7676
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4801 - binary_accuracy: 0.7640
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4800 - binary_accuracy: 0.7666
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4805 - binary_accuracy: 0.7673
13000/29000 [============>.................] - ETA: 0s - loss: 0.4804 - binary_accuracy: 0.7685
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4836 - binary_accuracy: 0.7679
17000/29000 [================>.............] - ETA: 0s - loss: 0.4840 - binary_accuracy: 0.7678
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4848 - binary_accuracy: 0.7678
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4841 - binary_accuracy: 0.7679
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4860 - binary_accuracy: 0.7654
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4864 - binary_accuracy: 0.7654
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4868 - binary_accuracy: 0.7655Epoch 00041: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4867 - binary_accuracy: 0.7659 - val_loss: 0.0659 - val_binary_accuracy: 0.6939
Epoch 42/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4606 - binary_accuracy: 0.7940
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4792 - binary_accuracy: 0.7713
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4734 - binary_accuracy: 0.7772
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4761 - binary_accuracy: 0.7787
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4775 - binary_accuracy: 0.7769
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4773 - binary_accuracy: 0.7768
13000/29000 [============>.................] - ETA: 0s - loss: 0.4784 - binary_accuracy: 0.7758
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4798 - binary_accuracy: 0.7740
17000/29000 [================>.............] - ETA: 0s - loss: 0.4814 - binary_accuracy: 0.7724
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4829 - binary_accuracy: 0.7708
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4856 - binary_accuracy: 0.7691
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4855 - binary_accuracy: 0.7685
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4848 - binary_accuracy: 0.7692
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4863 - binary_accuracy: 0.7679Epoch 00042: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4867 - binary_accuracy: 0.7680 - val_loss: 0.0618 - val_binary_accuracy: 0.7065
Epoch 43/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4673 - binary_accuracy: 0.7680
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4707 - binary_accuracy: 0.7780
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4756 - binary_accuracy: 0.7736
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4791 - binary_accuracy: 0.7714
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4825 - binary_accuracy: 0.7719
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4821 - binary_accuracy: 0.7705
13000/29000 [============>.................] - ETA: 0s - loss: 0.4818 - binary_accuracy: 0.7713
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4836 - binary_accuracy: 0.7691
17000/29000 [================>.............] - ETA: 0s - loss: 0.4845 - binary_accuracy: 0.7682
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4843 - binary_accuracy: 0.7682
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4832 - binary_accuracy: 0.7679
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4832 - binary_accuracy: 0.7683
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4847 - binary_accuracy: 0.7683
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4849 - binary_accuracy: 0.7679Epoch 00043: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4851 - binary_accuracy: 0.7675 - val_loss: 0.0645 - val_binary_accuracy: 0.6984
Epoch 44/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4853 - binary_accuracy: 0.7490
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4827 - binary_accuracy: 0.7677
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4760 - binary_accuracy: 0.7732
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4773 - binary_accuracy: 0.7731
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4781 - binary_accuracy: 0.7733
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4777 - binary_accuracy: 0.7745
13000/29000 [============>.................] - ETA: 0s - loss: 0.4756 - binary_accuracy: 0.7769
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4800 - binary_accuracy: 0.7737
17000/29000 [================>.............] - ETA: 0s - loss: 0.4810 - binary_accuracy: 0.7726
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4826 - binary_accuracy: 0.7725
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4832 - binary_accuracy: 0.7725
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4821 - binary_accuracy: 0.7723
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4832 - binary_accuracy: 0.7723
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4845 - binary_accuracy: 0.7707Epoch 00044: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4848 - binary_accuracy: 0.7703 - val_loss: 0.0666 - val_binary_accuracy: 0.6856
Epoch 45/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4939 - binary_accuracy: 0.7740
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4851 - binary_accuracy: 0.7757
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4835 - binary_accuracy: 0.7790
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4815 - binary_accuracy: 0.7787
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4833 - binary_accuracy: 0.7747
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4795 - binary_accuracy: 0.7757
13000/29000 [============>.................] - ETA: 0s - loss: 0.4819 - binary_accuracy: 0.7738
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4800 - binary_accuracy: 0.7730
17000/29000 [================>.............] - ETA: 0s - loss: 0.4780 - binary_accuracy: 0.7742
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4788 - binary_accuracy: 0.7731
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4819 - binary_accuracy: 0.7724
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4816 - binary_accuracy: 0.7722
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4816 - binary_accuracy: 0.7720
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4810 - binary_accuracy: 0.7720Epoch 00045: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4831 - binary_accuracy: 0.7710 - val_loss: 0.0618 - val_binary_accuracy: 0.7023
Epoch 46/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4716 - binary_accuracy: 0.7790
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4699 - binary_accuracy: 0.7820
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4750 - binary_accuracy: 0.7778
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4720 - binary_accuracy: 0.7791
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4725 - binary_accuracy: 0.7762
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4756 - binary_accuracy: 0.7755
13000/29000 [============>.................] - ETA: 0s - loss: 0.4746 - binary_accuracy: 0.7758
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4775 - binary_accuracy: 0.7747
17000/29000 [================>.............] - ETA: 0s - loss: 0.4809 - binary_accuracy: 0.7725
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4825 - binary_accuracy: 0.7716
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4801 - binary_accuracy: 0.7717
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4811 - binary_accuracy: 0.7715
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4800 - binary_accuracy: 0.7714
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4825 - binary_accuracy: 0.7697Epoch 00046: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4832 - binary_accuracy: 0.7704 - val_loss: 0.0645 - val_binary_accuracy: 0.6992
Epoch 47/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4651 - binary_accuracy: 0.7910
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4857 - binary_accuracy: 0.7733
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4828 - binary_accuracy: 0.7760
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4809 - binary_accuracy: 0.7729
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4813 - binary_accuracy: 0.7712
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4823 - binary_accuracy: 0.7717
13000/29000 [============>.................] - ETA: 0s - loss: 0.4805 - binary_accuracy: 0.7735
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4816 - binary_accuracy: 0.7727
17000/29000 [================>.............] - ETA: 0s - loss: 0.4816 - binary_accuracy: 0.7731
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4823 - binary_accuracy: 0.7728
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4828 - binary_accuracy: 0.7727
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4824 - binary_accuracy: 0.7718
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4827 - binary_accuracy: 0.7719
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4819 - binary_accuracy: 0.7726Epoch 00047: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4829 - binary_accuracy: 0.7715 - val_loss: 0.0645 - val_binary_accuracy: 0.7026
Epoch 48/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4994 - binary_accuracy: 0.7450
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4790 - binary_accuracy: 0.7697
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4816 - binary_accuracy: 0.7670
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4843 - binary_accuracy: 0.7641
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4870 - binary_accuracy: 0.7651
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4849 - binary_accuracy: 0.7675
13000/29000 [============>.................] - ETA: 0s - loss: 0.4818 - binary_accuracy: 0.7686
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4829 - binary_accuracy: 0.7685
17000/29000 [================>.............] - ETA: 0s - loss: 0.4838 - binary_accuracy: 0.7680
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4814 - binary_accuracy: 0.7687
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4811 - binary_accuracy: 0.7690
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4812 - binary_accuracy: 0.7694
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4806 - binary_accuracy: 0.7695
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4800 - binary_accuracy: 0.7704Epoch 00048: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4799 - binary_accuracy: 0.7698 - val_loss: 0.0604 - val_binary_accuracy: 0.7121
Epoch 49/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4785 - binary_accuracy: 0.7700
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4767 - binary_accuracy: 0.7707
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4680 - binary_accuracy: 0.7766
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4752 - binary_accuracy: 0.7756
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4753 - binary_accuracy: 0.7736
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4773 - binary_accuracy: 0.7733
13000/29000 [============>.................] - ETA: 0s - loss: 0.4756 - binary_accuracy: 0.7742
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4749 - binary_accuracy: 0.7749
17000/29000 [================>.............] - ETA: 0s - loss: 0.4752 - binary_accuracy: 0.7743
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4761 - binary_accuracy: 0.7740
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4781 - binary_accuracy: 0.7730
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4753 - binary_accuracy: 0.7738
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4751 - binary_accuracy: 0.7746
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4763 - binary_accuracy: 0.7731Epoch 00049: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4783 - binary_accuracy: 0.7720 - val_loss: 0.0608 - val_binary_accuracy: 0.7110
Epoch 50/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4748 - binary_accuracy: 0.7850
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4546 - binary_accuracy: 0.7857
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4631 - binary_accuracy: 0.7780
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4680 - binary_accuracy: 0.7767
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4641 - binary_accuracy: 0.7814
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4646 - binary_accuracy: 0.7788
13000/29000 [============>.................] - ETA: 0s - loss: 0.4662 - binary_accuracy: 0.7792
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4707 - binary_accuracy: 0.7785
17000/29000 [================>.............] - ETA: 0s - loss: 0.4721 - binary_accuracy: 0.7784
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4714 - binary_accuracy: 0.7775
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4733 - binary_accuracy: 0.7777
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4757 - binary_accuracy: 0.7757
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4752 - binary_accuracy: 0.7758
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4770 - binary_accuracy: 0.7744Epoch 00050: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4769 - binary_accuracy: 0.7749 - val_loss: 0.0600 - val_binary_accuracy: 0.7143
Epoch 51/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4612 - binary_accuracy: 0.7760
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4683 - binary_accuracy: 0.7797
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4785 - binary_accuracy: 0.7740
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4766 - binary_accuracy: 0.7759
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4737 - binary_accuracy: 0.7771
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4748 - binary_accuracy: 0.7755
13000/29000 [============>.................] - ETA: 0s - loss: 0.4767 - binary_accuracy: 0.7743
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4741 - binary_accuracy: 0.7747
17000/29000 [================>.............] - ETA: 0s - loss: 0.4756 - binary_accuracy: 0.7739
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4765 - binary_accuracy: 0.7737
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4747 - binary_accuracy: 0.7740
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4758 - binary_accuracy: 0.7730
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4766 - binary_accuracy: 0.7735
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4777 - binary_accuracy: 0.7735Epoch 00051: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4780 - binary_accuracy: 0.7739 - val_loss: 0.0599 - val_binary_accuracy: 0.7107
Epoch 52/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4757 - binary_accuracy: 0.7680
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4997 - binary_accuracy: 0.7627
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4894 - binary_accuracy: 0.7652
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4837 - binary_accuracy: 0.7654
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4832 - binary_accuracy: 0.7677
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4816 - binary_accuracy: 0.7699
13000/29000 [============>.................] - ETA: 0s - loss: 0.4785 - binary_accuracy: 0.7704
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4763 - binary_accuracy: 0.7726
17000/29000 [================>.............] - ETA: 0s - loss: 0.4769 - binary_accuracy: 0.7725
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4753 - binary_accuracy: 0.7737
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4766 - binary_accuracy: 0.7736
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4771 - binary_accuracy: 0.7744
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4766 - binary_accuracy: 0.7736
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4783 - binary_accuracy: 0.7719Epoch 00052: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4774 - binary_accuracy: 0.7730 - val_loss: 0.0609 - val_binary_accuracy: 0.7068
Epoch 53/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4655 - binary_accuracy: 0.7740
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4731 - binary_accuracy: 0.7703
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4689 - binary_accuracy: 0.7740
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4733 - binary_accuracy: 0.7723
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4708 - binary_accuracy: 0.7742
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4751 - binary_accuracy: 0.7747
13000/29000 [============>.................] - ETA: 0s - loss: 0.4746 - binary_accuracy: 0.7748
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4761 - binary_accuracy: 0.7727
17000/29000 [================>.............] - ETA: 0s - loss: 0.4763 - binary_accuracy: 0.7740
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4760 - binary_accuracy: 0.7737
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4771 - binary_accuracy: 0.7726
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4770 - binary_accuracy: 0.7723
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4781 - binary_accuracy: 0.7715
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4770 - binary_accuracy: 0.7722Epoch 00053: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4776 - binary_accuracy: 0.7722 - val_loss: 0.0633 - val_binary_accuracy: 0.7147
Epoch 54/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4967 - binary_accuracy: 0.7630
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4950 - binary_accuracy: 0.7633
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4897 - binary_accuracy: 0.7664
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4850 - binary_accuracy: 0.7663
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4808 - binary_accuracy: 0.7661
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4809 - binary_accuracy: 0.7670
13000/29000 [============>.................] - ETA: 0s - loss: 0.4795 - binary_accuracy: 0.7691
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4766 - binary_accuracy: 0.7701
17000/29000 [================>.............] - ETA: 0s - loss: 0.4791 - binary_accuracy: 0.7712
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4794 - binary_accuracy: 0.7702
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4801 - binary_accuracy: 0.7701
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4792 - binary_accuracy: 0.7705
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4768 - binary_accuracy: 0.7720
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4771 - binary_accuracy: 0.7716Epoch 00054: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4752 - binary_accuracy: 0.7722 - val_loss: 0.0599 - val_binary_accuracy: 0.7215
Epoch 55/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4613 - binary_accuracy: 0.7750
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4682 - binary_accuracy: 0.7767
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4626 - binary_accuracy: 0.7820
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4695 - binary_accuracy: 0.7790
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4683 - binary_accuracy: 0.7782
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4673 - binary_accuracy: 0.7793
13000/29000 [============>.................] - ETA: 0s - loss: 0.4676 - binary_accuracy: 0.7805
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4681 - binary_accuracy: 0.7780
17000/29000 [================>.............] - ETA: 0s - loss: 0.4678 - binary_accuracy: 0.7776
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4676 - binary_accuracy: 0.7786
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4705 - binary_accuracy: 0.7774
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4693 - binary_accuracy: 0.7783
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4714 - binary_accuracy: 0.7767
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4723 - binary_accuracy: 0.7764Epoch 00055: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4735 - binary_accuracy: 0.7763 - val_loss: 0.0597 - val_binary_accuracy: 0.7151
Epoch 56/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4686 - binary_accuracy: 0.7770
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4671 - binary_accuracy: 0.7770
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4682 - binary_accuracy: 0.7802
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4723 - binary_accuracy: 0.7773
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4755 - binary_accuracy: 0.7778
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4748 - binary_accuracy: 0.7776
13000/29000 [============>.................] - ETA: 0s - loss: 0.4747 - binary_accuracy: 0.7777
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4748 - binary_accuracy: 0.7767
17000/29000 [================>.............] - ETA: 0s - loss: 0.4752 - binary_accuracy: 0.7755
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4735 - binary_accuracy: 0.7759
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4741 - binary_accuracy: 0.7753
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4729 - binary_accuracy: 0.7759
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4712 - binary_accuracy: 0.7764
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4731 - binary_accuracy: 0.7759Epoch 00056: val_loss improved from 0.05925 to 0.05747, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 99us/step - loss: 0.4735 - binary_accuracy: 0.7759 - val_loss: 0.0575 - val_binary_accuracy: 0.7315
Epoch 57/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4537 - binary_accuracy: 0.7900
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4588 - binary_accuracy: 0.7817
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4638 - binary_accuracy: 0.7804
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4626 - binary_accuracy: 0.7780
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4601 - binary_accuracy: 0.7789
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4640 - binary_accuracy: 0.7774
13000/29000 [============>.................] - ETA: 0s - loss: 0.4651 - binary_accuracy: 0.7768
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4661 - binary_accuracy: 0.7745
17000/29000 [================>.............] - ETA: 0s - loss: 0.4684 - binary_accuracy: 0.7745
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4694 - binary_accuracy: 0.7743
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4692 - binary_accuracy: 0.7746
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4695 - binary_accuracy: 0.7744
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4704 - binary_accuracy: 0.7751
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4719 - binary_accuracy: 0.7742Epoch 00057: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4726 - binary_accuracy: 0.7747 - val_loss: 0.0584 - val_binary_accuracy: 0.7266
Epoch 58/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4723 - binary_accuracy: 0.7850
 3000/29000 [==>...........................] - ETA: 0s - loss: 0.4713 - binary_accuracy: 0.7840
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4709 - binary_accuracy: 0.7846
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4689 - binary_accuracy: 0.7823
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4696 - binary_accuracy: 0.7803
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4727 - binary_accuracy: 0.7771
13000/29000 [============>.................] - ETA: 0s - loss: 0.4715 - binary_accuracy: 0.7775
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4703 - binary_accuracy: 0.7785
17000/29000 [================>.............] - ETA: 0s - loss: 0.4692 - binary_accuracy: 0.7791
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4701 - binary_accuracy: 0.7785
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4692 - binary_accuracy: 0.7785
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4690 - binary_accuracy: 0.7788
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4689 - binary_accuracy: 0.7787
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4694 - binary_accuracy: 0.7779Epoch 00058: val_loss did not improve

29000/29000 [==============================] - 1s 42us/step - loss: 0.4704 - binary_accuracy: 0.7778 - val_loss: 0.0586 - val_binary_accuracy: 0.7245
Epoch 59/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4687 - binary_accuracy: 0.7860
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4713 - binary_accuracy: 0.7733
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4740 - binary_accuracy: 0.7690
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4713 - binary_accuracy: 0.7720
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4716 - binary_accuracy: 0.7743
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4724 - binary_accuracy: 0.7735
13000/29000 [============>.................] - ETA: 0s - loss: 0.4736 - binary_accuracy: 0.7725
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4738 - binary_accuracy: 0.7736
17000/29000 [================>.............] - ETA: 0s - loss: 0.4722 - binary_accuracy: 0.7734
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4722 - binary_accuracy: 0.7737
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4724 - binary_accuracy: 0.7753
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4722 - binary_accuracy: 0.7752
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4718 - binary_accuracy: 0.7759
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4725 - binary_accuracy: 0.7767Epoch 00059: val_loss improved from 0.05747 to 0.05665, saving model to keras_Hut28/weights/TrainedModel_Keras_TF.h5

29000/29000 [==============================] - 3s 97us/step - loss: 0.4719 - binary_accuracy: 0.7772 - val_loss: 0.0567 - val_binary_accuracy: 0.7346
Epoch 60/60

 1000/29000 [>.............................] - ETA: 1s - loss: 0.4498 - binary_accuracy: 0.7990
 3000/29000 [==>...........................] - ETA: 1s - loss: 0.4611 - binary_accuracy: 0.7907
 5000/29000 [====>.........................] - ETA: 0s - loss: 0.4540 - binary_accuracy: 0.7916
 7000/29000 [======>.......................] - ETA: 0s - loss: 0.4595 - binary_accuracy: 0.7867
 9000/29000 [========>.....................] - ETA: 0s - loss: 0.4636 - binary_accuracy: 0.7833
11000/29000 [==========>...................] - ETA: 0s - loss: 0.4643 - binary_accuracy: 0.7825
13000/29000 [============>.................] - ETA: 0s - loss: 0.4641 - binary_accuracy: 0.7801
15000/29000 [==============>...............] - ETA: 0s - loss: 0.4653 - binary_accuracy: 0.7795
17000/29000 [================>.............] - ETA: 0s - loss: 0.4661 - binary_accuracy: 0.7803
19000/29000 [==================>...........] - ETA: 0s - loss: 0.4688 - binary_accuracy: 0.7792
21000/29000 [====================>.........] - ETA: 0s - loss: 0.4682 - binary_accuracy: 0.7797
23000/29000 [======================>.......] - ETA: 0s - loss: 0.4701 - binary_accuracy: 0.7788
25000/29000 [========================>.....] - ETA: 0s - loss: 0.4705 - binary_accuracy: 0.7768
27000/29000 [==========================>...] - ETA: 0s - loss: 0.4701 - binary_accuracy: 0.7769Epoch 00060: val_loss did not improve

29000/29000 [==============================] - 1s 43us/step - loss: 0.4686 - binary_accuracy: 0.7779 - val_loss: 0.0629 - val_binary_accuracy: 0.7205
                         : Elapsed time for training with 29000 events: 131 sec         
                         : Creating xml weight file: [0;36mkeras_Hut28/weights/TMVAClassification_Keras_TF.weights.xml[0m
                         : Creating standalone class: [0;36mkeras_Hut28/weights/TMVAClassification_Keras_TF.class.C[0m
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
BDT                      : Ranking result (top variable is best ranked)
                         : ----------------------------------------------
                         : Rank : Variable     : Variable Importance
                         : ----------------------------------------------
                         :    1 : DRjet12m     : 5.767e-02
                         :    2 : DRhadTm      : 4.575e-02
                         :    3 : DRjet12DR    : 4.316e-02
                         :    4 : DRjet2cvsb   : 4.016e-02
                         :    5 : DRjet23m     : 3.663e-02
                         :    6 : DRjet31m     : 3.175e-02
                         :    7 : DRjet12pt    : 2.619e-02
                         :    8 : DRjet2csv    : 2.593e-02
                         :    9 : DRjet3cvsl   : 2.497e-02
                         :   10 : DRjet2cvsl   : 2.023e-02
                         :   11 : DRjet0pt     : 1.973e-02
                         :   12 : DRjet23dphi  : 1.880e-02
                         :   13 : DRjet3cvsb   : 1.864e-02
                         :   14 : DRjet1cvsb   : 1.863e-02
                         :   15 : DRjet0cvsb   : 1.839e-02
                         :   16 : DRlepWdphi   : 1.829e-02
                         :   17 : DRjet2m      : 1.811e-02
                         :   18 : DRjet12deta  : 1.740e-02
                         :   19 : DRjet1csv    : 1.722e-02
                         :   20 : DRlepTpt     : 1.708e-02
                         :   21 : DRjet1m      : 1.705e-02
                         :   22 : DRlepTdphi   : 1.673e-02
                         :   23 : njets        : 1.600e-02
                         :   24 : DRjet31deta  : 1.568e-02
                         :   25 : DRjet1eta    : 1.544e-02
                         :   26 : DRhadTWbdeta : 1.538e-02
                         :   27 : DRjet1cvsl   : 1.496e-02
                         :   28 : DRjet3eta    : 1.490e-02
                         :   29 : DRhadTWbdphi : 1.485e-02
                         :   30 : DRjet12eta   : 1.443e-02
                         :   31 : DRhadTpt     : 1.428e-02
                         :   32 : DRjet0csv    : 1.423e-02
                         :   33 : DRjet31dphi  : 1.414e-02
                         :   34 : DRjet3pt     : 1.411e-02
                         :   35 : DRlepWeta    : 1.408e-02
                         :   36 : DRjet12dphi  : 1.392e-02
                         :   37 : DRjet0cvsl   : 1.380e-02
                         :   38 : DRlepTm      : 1.361e-02
                         :   39 : DRjet2eta    : 1.312e-02
                         :   40 : DRjet0eta    : 1.299e-02
                         :   41 : DRjet3m      : 1.279e-02
                         :   42 : DRlepTdeta   : 1.160e-02
                         :   43 : DRjet2pt     : 1.158e-02
                         :   44 : DRlepTeta    : 1.114e-02
                         :   45 : DRhadTHbdphi : 1.097e-02
                         :   46 : DRjet23deta  : 1.037e-02
                         :   47 : DRjet0m      : 9.928e-03
                         :   48 : DRjet3csv    : 9.792e-03
                         :   49 : DRlepWpt     : 9.629e-03
                         :   50 : DRhadTHbdeta : 9.338e-03
                         :   51 : DRlepWm      : 9.236e-03
                         :   52 : DRjet31eta   : 8.951e-03
                         :   53 : DRhadTeta    : 8.923e-03
                         :   54 : DRjet23pt    : 8.457e-03
                         :   55 : DRjet1pt     : 8.016e-03
                         :   56 : DRlepWdeta   : 7.927e-03
                         :   57 : DRjet31pt    : 7.107e-03
                         :   58 : DRjet23eta   : 5.837e-03
                         :   59 : nbjets_m     : 0.000e+00
                         : ----------------------------------------------
                         : No variable ranking supplied by classifier: Keras_TF
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: BDT for Classification performance
                         : 
BDT                      : [keras_Hut28] : Evaluation of BDT on testing sample (10654 events)
0%, time left: unknown
6%, time left: 0 sec
12%, time left: 0 sec
18%, time left: 0 sec
25%, time left: 0 sec
31%, time left: 0 sec
37%, time left: 0 sec
43%, time left: 0 sec
50%, time left: 0 sec
56%, time left: 0 sec
62%, time left: 0 sec
69%, time left: 0 sec
75%, time left: 0 sec
81%, time left: 0 sec
87%, time left: 0 sec
94%, time left: 0 sec
                         : Elapsed time for evaluation of 10654 events: 0.145 sec       
Factory                  : Test method: Keras_TF for Classification performance
                         : 
                         : Load model from file: keras_Hut28/weights/TrainedModel_Keras_TF.h5
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: BDT
                         : 
BDT                      : [keras_Hut28] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_BDT            :     Variable            Mean            RMS    [        Min            Max ]
                         : -------------------------------------------------------------------------------
                         :        njets:        5.0015        1.1286   [        4.0000        13.000 ]
                         :     nbjets_m:        3.0405       0.20846   [        3.0000        7.0000 ]
                         :     DRlepWpt:        119.44        75.811   [        1.0744        905.04 ]
                         :    DRlepWeta:      0.010474       0.86349   [       -4.2310        4.1339 ]
                         :   DRlepWdeta:     0.0024836       0.98629   [       -5.3066        5.0025 ]
                         :   DRlepWdphi:      0.025656        1.5729   [       -3.1410        3.1411 ]
                         :      DRlepWm:        95.378        49.604   [       0.24674        525.05 ]
                         :     DRjet0pt:        88.881        54.973   [        30.008        946.41 ]
                         :    DRjet0eta:     0.0071175        1.0027   [       -2.3953        2.3990 ]
                         :      DRjet0m:        12.157        6.2043   [        2.9754        174.83 ]
                         :    DRjet0csv:       0.95296      0.045609   [       0.84841       0.99959 ]
                         :   DRjet0cvsl:       0.84205       0.20539   [      -0.49692       0.99663 ]
                         :   DRjet0cvsb:      -0.57590       0.32916   [      -0.98363       0.72811 ]
                         :     DRjet1pt:        84.119        56.853   [        30.003        757.89 ]
                         :    DRjet1eta:    0.00072211        1.0329   [       -2.3996        2.3973 ]
                         :      DRjet1m:        12.120        7.2420   [        2.7879        127.54 ]
                         :    DRjet1csv:       0.97728      0.028917   [       0.84946       0.99963 ]
                         :   DRjet1cvsl:       0.87376       0.17112   [      -0.60397       0.99640 ]
                         :   DRjet1cvsb:      -0.71126       0.25767   [      -0.98713       0.72091 ]
                         :     DRjet2pt:        86.593        65.438   [        30.005        882.91 ]
                         :    DRjet2eta:    -0.0069347        1.1072   [       -2.3949        2.3987 ]
                         :      DRjet2m:        12.552        8.7825   [        2.5105        123.19 ]
                         :    DRjet2csv:       0.92801      0.045464   [       0.84840       0.99912 ]
                         :   DRjet2cvsl:       0.79990       0.23979   [      -0.61970       0.99689 ]
                         :   DRjet2cvsb:      -0.40976       0.34403   [      -0.98098       0.72223 ]
                         :     DRjet3pt:        74.622        51.974   [        30.004        627.50 ]
                         :    DRjet3eta:     -0.014573        1.1011   [       -2.3998        2.3990 ]
                         :      DRjet3m:        11.130        6.8316   [       0.42524        95.953 ]
                         :    DRjet3csv:       0.26516        1.1741   [       -10.000       0.99856 ]
                         :   DRjet3cvsl:      0.045247       0.45112   [      -0.78522       0.99490 ]
                         :   DRjet3cvsb:       0.25587       0.36391   [      -0.96818       0.84179 ]
                         :    DRjet12pt:        132.51        85.835   [       0.87750        921.92 ]
                         :   DRjet12eta:    -0.0039562        1.2861   [       -5.5123        4.7178 ]
                         :  DRjet12deta:      0.016690        1.1827   [       -5.1587        5.9742 ]
                         :  DRjet12dphi:     0.0091880        1.6182   [       -3.1414        3.1416 ]
                         :     DRjet12m:        134.27        93.041   [        19.895        1631.9 ]
                         :    DRjet12DR:        1.8342       0.79674   [       0.38762        5.3692 ]
                         :    DRjet23pt:        132.68        84.591   [       0.26229        896.25 ]
                         :   DRjet23eta:     -0.013151        1.2813   [       -5.0648        5.9712 ]
                         :  DRjet23deta:     0.0028959        1.2222   [       -4.6195        5.2373 ]
                         :  DRjet23dphi:      0.018266        1.4342   [       -3.1399        3.1414 ]
                         :     DRjet23m:        112.83        77.087   [        15.156        954.12 ]
                         :    DRjet31pt:        129.70        77.268   [       0.65270        903.70 ]
                         :   DRjet31eta:    -0.0041834        1.2588   [       -6.0111        5.6253 ]
                         :  DRjet31deta:      0.023016        1.1784   [       -5.4502        4.8467 ]
                         :  DRjet31dphi:    -0.0050903        1.4454   [       -3.1412        3.1414 ]
                         :     DRjet31m:        110.66        72.292   [        18.890        1076.1 ]
                         :     DRlepTpt:        177.85        98.439   [       0.75293        989.61 ]
                         :    DRlepTeta:     0.0053379        1.0140   [       -5.8112        4.9409 ]
                         :   DRlepTdeta:     0.0017317       0.94598   [       -4.5094        5.4021 ]
                         :   DRlepTdphi:     -0.012869        1.3583   [       -3.1410        3.1415 ]
                         :      DRlepTm:        185.13        69.434   [        33.799        939.25 ]
                         :     DRhadTpt:        180.54        97.590   [       0.72026        1028.0 ]
                         :    DRhadTeta:    -0.0025994        1.2764   [       -3.7505        6.3475 ]
                         : DRhadTHbdeta:     0.0086347        1.2515   [       -6.1393        5.0539 ]
                         : DRhadTWbdeta:     -0.014367        1.2286   [       -6.2961        4.8849 ]
                         : DRhadTHbdphi:    -0.0027688        1.2408   [       -3.1406        3.1378 ]
                         : DRhadTWbdphi:    -0.0083355        1.4237   [       -3.1414        3.1400 ]
                         :      DRhadTm:        217.41        122.31   [        48.839        1797.6 ]
                         : -------------------------------------------------------------------------------
                         : [32m
                         : <PlotVariables> Will not produce scatter plots ==> 
                         : |  The number of 59 input variables and 0 target values would require 1711 two-dimensional
                         : |  histograms, which would occupy the computer's memory. Note that this
                         : |  suppression does not have any consequences for your analysis, other
                         : |  than not disposing of these scatter plots. You can modify the maximum
                         : |  number of input variables allowed to generate scatter plots in your
                         : |  script via the command line:
                         : |  "(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;"[0m
                         : 
                         : Some more output
Factory                  : Evaluate classifier: Keras_TF
                         : 
TFHandler_Keras_TF       :     Variable            Mean            RMS    [        Min            Max ]
                         : -------------------------------------------------------------------------------
                         :        njets:    -0.0054784        1.0374   [       -4.3397        4.1162 ]
                         :     nbjets_m:      0.010797        1.0394   [       -6.8608        7.8553 ]
                         :     DRlepWpt:      0.012516        1.0536   [       -7.3518        7.2739 ]
                         :    DRlepWeta:     -0.037806        1.0174   [       -5.9605        3.8869 ]
                         :   DRlepWdeta:      0.010209        1.0334   [       -5.9464        8.7599 ]
                         :   DRlepWdphi:     0.0014280        1.0214   [       -5.5099        6.7303 ]
                         :      DRlepWm:    -0.0074679        1.0247   [       -5.6495        6.3235 ]
                         :     DRjet0pt:    -0.0067888        1.0205   [       -4.1578        5.0467 ]
                         :    DRjet0eta:     -0.018898        1.0307   [       -5.8475        5.8166 ]
                         :      DRjet0m:     -0.028111        1.0227   [       -4.4866        5.3651 ]
                         :    DRjet0csv:    -0.0090838        1.0211   [       -6.4918        4.9469 ]
                         :   DRjet0cvsl:     -0.043885        1.0244   [       -4.6229        5.6256 ]
                         :   DRjet0cvsb:     0.0025850        1.0380   [       -4.0385        4.4351 ]
                         :     DRjet1pt:      0.017736        1.0133   [       -6.9645        4.5832 ]
                         :    DRjet1eta:     -0.039068        1.0477   [       -4.0701        5.3972 ]
                         :      DRjet1m:      0.025355        1.0377   [       -5.1297        7.1512 ]
                         :    DRjet1csv:     0.0070322        1.0186   [       -5.4802        4.2141 ]
                         :   DRjet1cvsl:     -0.011344        1.0284   [       -4.9164        6.0584 ]
                         :   DRjet1cvsb:     -0.034099        1.0200   [       -4.7586        4.7312 ]
                         :     DRjet2pt:    -0.0050679        1.0129   [       -4.2004        5.1750 ]
                         :    DRjet2eta:     -0.012403        1.0136   [       -5.0616        4.7501 ]
                         :      DRjet2m:     -0.024880        1.0225   [       -6.1799        5.5073 ]
                         :    DRjet2csv:     0.0015187        1.0164   [       -4.1579        4.6734 ]
                         :   DRjet2cvsl:     -0.028087        1.0010   [       -4.1995        3.8439 ]
                         :   DRjet2cvsb:     -0.020031        1.0303   [       -6.3950        5.2281 ]
                         :     DRjet3pt:     0.0067084        1.0008   [       -3.7619        4.5283 ]
                         :    DRjet3eta:    -0.0033330        1.0218   [       -5.9866        4.4624 ]
                         :      DRjet3m:    -0.0080945        1.0201   [       -5.2308        5.0434 ]
                         :    DRjet3csv:      0.042154        1.0135   [       -3.5438        4.6517 ]
                         :   DRjet3cvsl:    0.00070909        1.0244   [       -6.2544        4.1880 ]
                         :   DRjet3cvsb:      0.016227        1.0241   [       -4.6984        6.4700 ]
                         :    DRjet12pt:      0.036201        1.0285   [       -5.6667        5.0934 ]
                         :   DRjet12eta:      0.011181        1.0144   [       -7.3014        5.3865 ]
                         :  DRjet12deta:     -0.012494        1.0282   [       -4.0363        4.7369 ]
                         :  DRjet12dphi:     0.0045888       0.99487   [       -5.1623        4.8460 ]
                         :     DRjet12m:     -0.044495        1.0145   [       -5.2151        7.6144 ]
                         :    DRjet12DR:      0.010232        1.0094   [       -4.7456        4.4860 ]
                         :    DRjet23pt:    0.00018654        1.0104   [       -5.3201        4.8553 ]
                         :   DRjet23eta:     -0.012122        1.0183   [       -5.4576        5.1725 ]
                         :  DRjet23deta:      0.023644        1.0168   [       -6.4075        5.0562 ]
                         :  DRjet23dphi:      0.013111        1.0029   [       -4.1834        4.8745 ]
                         :     DRjet23m:      0.029944        1.0214   [       -3.3745        5.4736 ]
                         :    DRjet31pt:      0.018743        1.0147   [       -5.0382        5.3456 ]
                         :   DRjet31eta:    -0.0088457        1.0330   [       -5.4832        5.5973 ]
                         :  DRjet31deta:      0.019876        1.0148   [       -4.5208        4.3043 ]
                         :  DRjet31dphi:     0.0013656        1.0098   [       -3.7863        4.8303 ]
                         :     DRjet31m:    -0.0045671       0.99211   [       -4.8107        4.4787 ]
                         :     DRlepTpt:     0.0033401        1.0129   [       -4.4467        7.7062 ]
                         :    DRlepTeta:      0.028504        1.0234   [       -5.4897        4.7857 ]
                         :   DRlepTdeta:     -0.010832        1.0404   [       -5.4796        6.7310 ]
                         :   DRlepTdphi:     -0.038841        1.0283   [       -8.3398        4.8121 ]
                         :      DRlepTm:    -0.0032010       0.98669   [       -4.4073        4.5573 ]
                         :     DRhadTpt:      0.048518       0.99650   [       -7.3864        4.9882 ]
                         :    DRhadTeta:      0.014082        1.0248   [       -6.2711        5.3367 ]
                         : DRhadTHbdeta:     -0.048135        1.0080   [       -5.9811        10.177 ]
                         : DRhadTWbdeta:     -0.041417        1.0207   [       -15.404        4.3104 ]
                         : DRhadTHbdphi:    -0.0070592        1.0203   [       -3.0077        17.272 ]
                         : DRhadTWbdphi:     -0.013675        1.0191   [       -5.1286        5.1477 ]
                         :      DRhadTm:    -0.0030886        1.0045   [       -7.0246        4.3744 ]
                         : -------------------------------------------------------------------------------
Keras_TF                 : [keras_Hut28] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_Keras_TF       :     Variable            Mean            RMS    [        Min            Max ]
                         : -------------------------------------------------------------------------------
                         :        njets:    -0.0054784        1.0374   [       -4.3397        4.1162 ]
                         :     nbjets_m:      0.010797        1.0394   [       -6.8608        7.8553 ]
                         :     DRlepWpt:      0.012516        1.0536   [       -7.3518        7.2739 ]
                         :    DRlepWeta:     -0.037806        1.0174   [       -5.9605        3.8869 ]
                         :   DRlepWdeta:      0.010209        1.0334   [       -5.9464        8.7599 ]
                         :   DRlepWdphi:     0.0014280        1.0214   [       -5.5099        6.7303 ]
                         :      DRlepWm:    -0.0074679        1.0247   [       -5.6495        6.3235 ]
                         :     DRjet0pt:    -0.0067888        1.0205   [       -4.1578        5.0467 ]
                         :    DRjet0eta:     -0.018898        1.0307   [       -5.8475        5.8166 ]
                         :      DRjet0m:     -0.028111        1.0227   [       -4.4866        5.3651 ]
                         :    DRjet0csv:    -0.0090838        1.0211   [       -6.4918        4.9469 ]
                         :   DRjet0cvsl:     -0.043885        1.0244   [       -4.6229        5.6256 ]
                         :   DRjet0cvsb:     0.0025850        1.0380   [       -4.0385        4.4351 ]
                         :     DRjet1pt:      0.017736        1.0133   [       -6.9645        4.5832 ]
                         :    DRjet1eta:     -0.039068        1.0477   [       -4.0701        5.3972 ]
                         :      DRjet1m:      0.025355        1.0377   [       -5.1297        7.1512 ]
                         :    DRjet1csv:     0.0070322        1.0186   [       -5.4802        4.2141 ]
                         :   DRjet1cvsl:     -0.011344        1.0284   [       -4.9164        6.0584 ]
                         :   DRjet1cvsb:     -0.034099        1.0200   [       -4.7586        4.7312 ]
                         :     DRjet2pt:    -0.0050679        1.0129   [       -4.2004        5.1750 ]
                         :    DRjet2eta:     -0.012403        1.0136   [       -5.0616        4.7501 ]
                         :      DRjet2m:     -0.024880        1.0225   [       -6.1799        5.5073 ]
                         :    DRjet2csv:     0.0015187        1.0164   [       -4.1579        4.6734 ]
                         :   DRjet2cvsl:     -0.028087        1.0010   [       -4.1995        3.8439 ]
                         :   DRjet2cvsb:     -0.020031        1.0303   [       -6.3950        5.2281 ]
                         :     DRjet3pt:     0.0067084        1.0008   [       -3.7619        4.5283 ]
                         :    DRjet3eta:    -0.0033330        1.0218   [       -5.9866        4.4624 ]
                         :      DRjet3m:    -0.0080945        1.0201   [       -5.2308        5.0434 ]
                         :    DRjet3csv:      0.042154        1.0135   [       -3.5438        4.6517 ]
                         :   DRjet3cvsl:    0.00070909        1.0244   [       -6.2544        4.1880 ]
                         :   DRjet3cvsb:      0.016227        1.0241   [       -4.6984        6.4700 ]
                         :    DRjet12pt:      0.036201        1.0285   [       -5.6667        5.0934 ]
                         :   DRjet12eta:      0.011181        1.0144   [       -7.3014        5.3865 ]
                         :  DRjet12deta:     -0.012494        1.0282   [       -4.0363        4.7369 ]
                         :  DRjet12dphi:     0.0045888       0.99487   [       -5.1623        4.8460 ]
                         :     DRjet12m:     -0.044495        1.0145   [       -5.2151        7.6144 ]
                         :    DRjet12DR:      0.010232        1.0094   [       -4.7456        4.4860 ]
                         :    DRjet23pt:    0.00018654        1.0104   [       -5.3201        4.8553 ]
                         :   DRjet23eta:     -0.012122        1.0183   [       -5.4576        5.1725 ]
                         :  DRjet23deta:      0.023644        1.0168   [       -6.4075        5.0562 ]
                         :  DRjet23dphi:      0.013111        1.0029   [       -4.1834        4.8745 ]
                         :     DRjet23m:      0.029944        1.0214   [       -3.3745        5.4736 ]
                         :    DRjet31pt:      0.018743        1.0147   [       -5.0382        5.3456 ]
                         :   DRjet31eta:    -0.0088457        1.0330   [       -5.4832        5.5973 ]
                         :  DRjet31deta:      0.019876        1.0148   [       -4.5208        4.3043 ]
                         :  DRjet31dphi:     0.0013656        1.0098   [       -3.7863        4.8303 ]
                         :     DRjet31m:    -0.0045671       0.99211   [       -4.8107        4.4787 ]
                         :     DRlepTpt:     0.0033401        1.0129   [       -4.4467        7.7062 ]
                         :    DRlepTeta:      0.028504        1.0234   [       -5.4897        4.7857 ]
                         :   DRlepTdeta:     -0.010832        1.0404   [       -5.4796        6.7310 ]
                         :   DRlepTdphi:     -0.038841        1.0283   [       -8.3398        4.8121 ]
                         :      DRlepTm:    -0.0032010       0.98669   [       -4.4073        4.5573 ]
                         :     DRhadTpt:      0.048518       0.99650   [       -7.3864        4.9882 ]
                         :    DRhadTeta:      0.014082        1.0248   [       -6.2711        5.3367 ]
                         : DRhadTHbdeta:     -0.048135        1.0080   [       -5.9811        10.177 ]
                         : DRhadTWbdeta:     -0.041417        1.0207   [       -15.404        4.3104 ]
                         : DRhadTHbdphi:    -0.0070592        1.0203   [       -3.0077        17.272 ]
                         : DRhadTWbdphi:     -0.013675        1.0191   [       -5.1286        5.1477 ]
                         :      DRhadTm:    -0.0030886        1.0045   [       -7.0246        4.3744 ]
                         : -------------------------------------------------------------------------------
                         : [32m
                         : <PlotVariables> Will not produce scatter plots ==> 
                         : |  The number of 59 input variables and 0 target values would require 1711 two-dimensional
                         : |  histograms, which would occupy the computer's memory. Note that this
                         : |  suppression does not have any consequences for your analysis, other
                         : |  than not disposing of these scatter plots. You can modify the maximum
                         : |  number of input variables allowed to generate scatter plots in your
                         : |  script via the command line:
                         : |  "(TMVA::gConfig().GetVariablePlotting()).fMaxNumOfAllowedVariablesForScatterPlots = <some int>;"[0m
                         : 
                         : Some more output
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : keras_Hut28   Keras_TF       : 0.854
                         : keras_Hut28   BDT            : 0.845
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : keras_Hut28          Keras_TF       : 0.159 (0.209)       0.540 (0.571)      0.840 (0.849)
                         : keras_Hut28          BDT            : 0.169 (0.206)       0.513 (0.555)      0.824 (0.838)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:keras_Hut28      : Created tree 'TestTree' with 10654 events
                         : 
Dataset:keras_Hut28      : Created tree 'TrainTree' with 29000 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
